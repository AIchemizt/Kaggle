2024-12-09 04:15:57,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 04:15:57,581:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 04:15:57,581:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 04:15:57,581:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 04:16:12,679:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-09 04:18:09,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 04:18:09,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 04:18:09,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 04:18:09,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 04:18:09,491:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-09 04:44:32,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 04:44:32,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 04:44:32,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 04:44:32,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-09 04:44:33,148:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-09 18:29:46,410:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_10609/3021286958.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
  data2[data2.isna().sum()>0]

2024-12-09 18:30:12,046:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_10609/3021286958.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
  data2[data2.isna().sum()>0]

2024-12-11 05:08:25,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 05:08:25,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 05:08:25,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 05:08:25,829:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 05:08:26,282:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-11 05:19:00,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 05:19:00,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 05:19:00,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 05:19:00,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 05:19:00,811:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-11 05:24:58,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 05:24:58,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 05:24:58,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 05:24:58,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 05:24:59,319:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-11 20:41:47,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 20:41:47,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 20:41:47,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 20:41:47,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 20:41:47,624:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-11 20:42:16,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 20:42:16,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 20:42:16,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 20:42:16,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-11 20:42:17,246:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-12 01:34:13,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:34:13,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:34:13,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:34:13,323:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:34:13,857:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-12 01:34:31,761:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:34:31,761:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:34:31,761:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:34:31,761:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:34:32,122:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-12 01:35:05,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:35:05,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:35:05,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:35:05,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:35:05,574:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-12 01:35:50,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:35:50,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:35:50,967:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:35:50,967:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:35:51,440:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-12 01:41:04,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:41:04,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:41:04,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:41:04,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-12 01:41:05,356:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-13 03:14:57,440:INFO:PyCaret RegressionExperiment
2024-12-13 03:14:57,441:INFO:Logging name: reg-default-name
2024-12-13 03:14:57,441:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-13 03:14:57,441:INFO:version 3.0.0
2024-12-13 03:14:57,441:INFO:Initializing setup()
2024-12-13 03:14:57,441:INFO:self.USI: 43a9
2024-12-13 03:14:57,441:INFO:self._variable_keys: {'_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'data', 'y', 'fold_shuffle_param', 'seed', 'gpu_param', 'fold_generator', 'html_param', 'exp_id', 'y_test', 'X_test', 'X_train', 'target_param', 'pipeline', 'y_train', 'log_plots_param', 'transform_target_param', 'USI', 'logging_param', 'X', '_available_plots', 'memory', 'exp_name_log', 'n_jobs_param', 'idx'}
2024-12-13 03:14:57,441:INFO:Checking environment
2024-12-13 03:14:57,441:INFO:python_version: 3.9.20
2024-12-13 03:14:57,441:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-13 03:14:57,441:INFO:machine: arm64
2024-12-13 03:14:57,441:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:14:57,443:INFO:Memory: svmem(total=8589934592, available=1817411584, percent=78.8, used=3142664192, free=64143360, active=1768521728, inactive=1750745088, wired=1374142464)
2024-12-13 03:14:57,443:INFO:Physical Core: 8
2024-12-13 03:14:57,443:INFO:Logical Core: 8
2024-12-13 03:14:57,443:INFO:Checking libraries
2024-12-13 03:14:57,443:INFO:System:
2024-12-13 03:14:57,443:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-13 03:14:57,443:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-13 03:14:57,443:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:14:57,443:INFO:PyCaret required dependencies:
2024-12-13 03:14:57,444:INFO:                 pip: 24.3.1
2024-12-13 03:14:57,444:INFO:          setuptools: 75.1.0
2024-12-13 03:14:57,444:INFO:             pycaret: 3.0.0
2024-12-13 03:14:57,444:INFO:             IPython: 8.12.3
2024-12-13 03:14:57,444:INFO:          ipywidgets: 8.1.5
2024-12-13 03:14:57,444:INFO:                tqdm: 4.66.5
2024-12-13 03:14:57,444:INFO:               numpy: 1.24.4
2024-12-13 03:14:57,444:INFO:              pandas: 1.5.3
2024-12-13 03:14:57,444:INFO:              jinja2: 3.1.4
2024-12-13 03:14:57,444:INFO:               scipy: 1.11.4
2024-12-13 03:14:57,444:INFO:              joblib: 1.3.2
2024-12-13 03:14:57,444:INFO:             sklearn: 1.0.2
2024-12-13 03:14:57,444:INFO:                pyod: 2.0.2
2024-12-13 03:14:57,444:INFO:            imblearn: 0.12.4
2024-12-13 03:14:57,444:INFO:   category_encoders: 2.6.4
2024-12-13 03:14:57,444:INFO:            lightgbm: 4.5.0
2024-12-13 03:14:57,444:INFO:               numba: 0.60.0
2024-12-13 03:14:57,444:INFO:            requests: 2.32.3
2024-12-13 03:14:57,444:INFO:          matplotlib: 3.7.5
2024-12-13 03:14:57,444:INFO:          scikitplot: 0.3.7
2024-12-13 03:14:57,444:INFO:         yellowbrick: 1.5
2024-12-13 03:14:57,444:INFO:              plotly: 5.24.1
2024-12-13 03:14:57,444:INFO:             kaleido: 0.2.1
2024-12-13 03:14:57,444:INFO:         statsmodels: 0.14.3
2024-12-13 03:14:57,444:INFO:              sktime: 0.26.0
2024-12-13 03:14:57,444:INFO:               tbats: 1.1.3
2024-12-13 03:14:57,444:INFO:            pmdarima: 2.0.4
2024-12-13 03:14:57,444:INFO:              psutil: 6.0.0
2024-12-13 03:14:57,444:INFO:PyCaret optional dependencies:
2024-12-13 03:14:58,392:INFO:                shap: Not installed
2024-12-13 03:14:58,392:INFO:           interpret: Not installed
2024-12-13 03:14:58,392:INFO:                umap: Not installed
2024-12-13 03:14:58,392:INFO:    pandas_profiling: Not installed
2024-12-13 03:14:58,392:INFO:  explainerdashboard: Not installed
2024-12-13 03:14:58,392:INFO:             autoviz: Not installed
2024-12-13 03:14:58,392:INFO:           fairlearn: Not installed
2024-12-13 03:14:58,392:INFO:             xgboost: 2.1.2
2024-12-13 03:14:58,392:INFO:            catboost: 1.2.7
2024-12-13 03:14:58,392:INFO:              kmodes: Not installed
2024-12-13 03:14:58,392:INFO:             mlxtend: Not installed
2024-12-13 03:14:58,392:INFO:       statsforecast: Not installed
2024-12-13 03:14:58,392:INFO:        tune_sklearn: Not installed
2024-12-13 03:14:58,393:INFO:                 ray: Not installed
2024-12-13 03:14:58,393:INFO:            hyperopt: Not installed
2024-12-13 03:14:58,393:INFO:              optuna: 4.1.0
2024-12-13 03:14:58,393:INFO:               skopt: Not installed
2024-12-13 03:14:58,393:INFO:              mlflow: Not installed
2024-12-13 03:14:58,393:INFO:              gradio: Not installed
2024-12-13 03:14:58,393:INFO:             fastapi: 0.115.2
2024-12-13 03:14:58,393:INFO:             uvicorn: 0.32.0
2024-12-13 03:14:58,393:INFO:              m2cgen: Not installed
2024-12-13 03:14:58,393:INFO:           evidently: Not installed
2024-12-13 03:14:58,393:INFO:               fugue: Not installed
2024-12-13 03:14:58,393:INFO:           streamlit: 1.39.0
2024-12-13 03:14:58,393:INFO:             prophet: Not installed
2024-12-13 03:14:58,393:INFO:None
2024-12-13 03:14:58,393:INFO:Set up data.
2024-12-13 03:14:58,453:INFO:Set up train/test split.
2024-12-13 03:14:58,461:INFO:Set up index.
2024-12-13 03:14:58,462:INFO:Set up folding strategy.
2024-12-13 03:14:58,462:INFO:Assigning column types.
2024-12-13 03:14:58,466:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-13 03:14:58,467:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,470:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,473:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,515:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,557:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:58,567:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:58,569:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,584:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,588:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,634:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,663:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,664:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:58,665:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:58,666:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-13 03:14:58,669:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,672:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,715:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,749:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,749:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:58,753:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:58,756:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,759:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,839:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,839:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:58,841:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:58,842:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-13 03:14:58,849:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,920:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:58,922:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:58,928:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,967:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,996:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:14:58,996:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:58,998:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:58,998:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-13 03:14:59,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:14:59,072:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:14:59,072:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:59,074:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:59,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:14:59,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:14:59,147:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:59,148:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:59,149:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-13 03:14:59,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:14:59,223:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:59,225:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:59,274:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:14:59,306:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:59,307:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:59,308:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-13 03:14:59,382:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:59,383:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:59,457:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:59,458:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:59,463:INFO:Preparing preprocessing pipeline...
2024-12-13 03:14:59,463:INFO:Set up simple imputation.
2024-12-13 03:14:59,464:INFO:Set up column name cleaning.
2024-12-13 03:14:59,499:INFO:Finished creating preprocessing pipeline.
2024-12-13 03:14:59,505:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-13 03:14:59,505:INFO:Creating final display dataframe.
2024-12-13 03:14:59,628:INFO:Setup _display_container:                     Description             Value
0                    Session id              3340
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              43a9
2024-12-13 03:14:59,714:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:59,716:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:59,839:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:14:59,840:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:14:59,843:INFO:setup() successfully completed in 2.42s...............
2024-12-13 03:15:37,474:INFO:PyCaret RegressionExperiment
2024-12-13 03:15:37,474:INFO:Logging name: reg-default-name
2024-12-13 03:15:37,474:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-13 03:15:37,474:INFO:version 3.0.0
2024-12-13 03:15:37,474:INFO:Initializing setup()
2024-12-13 03:15:37,474:INFO:self.USI: 9153
2024-12-13 03:15:37,474:INFO:self._variable_keys: {'_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'data', 'y', 'fold_shuffle_param', 'seed', 'gpu_param', 'fold_generator', 'html_param', 'exp_id', 'y_test', 'X_test', 'X_train', 'target_param', 'pipeline', 'y_train', 'log_plots_param', 'transform_target_param', 'USI', 'logging_param', 'X', '_available_plots', 'memory', 'exp_name_log', 'n_jobs_param', 'idx'}
2024-12-13 03:15:37,474:INFO:Checking environment
2024-12-13 03:15:37,474:INFO:python_version: 3.9.20
2024-12-13 03:15:37,475:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-13 03:15:37,475:INFO:machine: arm64
2024-12-13 03:15:37,475:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:15:37,475:INFO:Memory: svmem(total=8589934592, available=1804386304, percent=79.0, used=3167354880, free=58425344, active=1762312192, inactive=1740767232, wired=1405042688)
2024-12-13 03:15:37,475:INFO:Physical Core: 8
2024-12-13 03:15:37,475:INFO:Logical Core: 8
2024-12-13 03:15:37,475:INFO:Checking libraries
2024-12-13 03:15:37,475:INFO:System:
2024-12-13 03:15:37,475:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-13 03:15:37,475:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-13 03:15:37,475:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:15:37,475:INFO:PyCaret required dependencies:
2024-12-13 03:15:37,475:INFO:                 pip: 24.3.1
2024-12-13 03:15:37,475:INFO:          setuptools: 75.1.0
2024-12-13 03:15:37,475:INFO:             pycaret: 3.0.0
2024-12-13 03:15:37,475:INFO:             IPython: 8.12.3
2024-12-13 03:15:37,475:INFO:          ipywidgets: 8.1.5
2024-12-13 03:15:37,475:INFO:                tqdm: 4.66.5
2024-12-13 03:15:37,475:INFO:               numpy: 1.24.4
2024-12-13 03:15:37,475:INFO:              pandas: 1.5.3
2024-12-13 03:15:37,475:INFO:              jinja2: 3.1.4
2024-12-13 03:15:37,475:INFO:               scipy: 1.11.4
2024-12-13 03:15:37,475:INFO:              joblib: 1.3.2
2024-12-13 03:15:37,475:INFO:             sklearn: 1.0.2
2024-12-13 03:15:37,475:INFO:                pyod: 2.0.2
2024-12-13 03:15:37,475:INFO:            imblearn: 0.12.4
2024-12-13 03:15:37,475:INFO:   category_encoders: 2.6.4
2024-12-13 03:15:37,475:INFO:            lightgbm: 4.5.0
2024-12-13 03:15:37,475:INFO:               numba: 0.60.0
2024-12-13 03:15:37,475:INFO:            requests: 2.32.3
2024-12-13 03:15:37,475:INFO:          matplotlib: 3.7.5
2024-12-13 03:15:37,475:INFO:          scikitplot: 0.3.7
2024-12-13 03:15:37,475:INFO:         yellowbrick: 1.5
2024-12-13 03:15:37,475:INFO:              plotly: 5.24.1
2024-12-13 03:15:37,475:INFO:             kaleido: 0.2.1
2024-12-13 03:15:37,475:INFO:         statsmodels: 0.14.3
2024-12-13 03:15:37,475:INFO:              sktime: 0.26.0
2024-12-13 03:15:37,476:INFO:               tbats: 1.1.3
2024-12-13 03:15:37,476:INFO:            pmdarima: 2.0.4
2024-12-13 03:15:37,476:INFO:              psutil: 6.0.0
2024-12-13 03:15:37,476:INFO:PyCaret optional dependencies:
2024-12-13 03:15:37,476:INFO:                shap: Not installed
2024-12-13 03:15:37,476:INFO:           interpret: Not installed
2024-12-13 03:15:37,476:INFO:                umap: Not installed
2024-12-13 03:15:37,476:INFO:    pandas_profiling: Not installed
2024-12-13 03:15:37,476:INFO:  explainerdashboard: Not installed
2024-12-13 03:15:37,476:INFO:             autoviz: Not installed
2024-12-13 03:15:37,476:INFO:           fairlearn: Not installed
2024-12-13 03:15:37,476:INFO:             xgboost: 2.1.2
2024-12-13 03:15:37,476:INFO:            catboost: 1.2.7
2024-12-13 03:15:37,476:INFO:              kmodes: Not installed
2024-12-13 03:15:37,476:INFO:             mlxtend: Not installed
2024-12-13 03:15:37,476:INFO:       statsforecast: Not installed
2024-12-13 03:15:37,476:INFO:        tune_sklearn: Not installed
2024-12-13 03:15:37,476:INFO:                 ray: Not installed
2024-12-13 03:15:37,476:INFO:            hyperopt: Not installed
2024-12-13 03:15:37,476:INFO:              optuna: 4.1.0
2024-12-13 03:15:37,476:INFO:               skopt: Not installed
2024-12-13 03:15:37,476:INFO:              mlflow: Not installed
2024-12-13 03:15:37,476:INFO:              gradio: Not installed
2024-12-13 03:15:37,476:INFO:             fastapi: 0.115.2
2024-12-13 03:15:37,476:INFO:             uvicorn: 0.32.0
2024-12-13 03:15:37,476:INFO:              m2cgen: Not installed
2024-12-13 03:15:37,476:INFO:           evidently: Not installed
2024-12-13 03:15:37,476:INFO:               fugue: Not installed
2024-12-13 03:15:37,476:INFO:           streamlit: 1.39.0
2024-12-13 03:15:37,476:INFO:             prophet: Not installed
2024-12-13 03:15:37,476:INFO:None
2024-12-13 03:15:37,476:INFO:Set up data.
2024-12-13 03:15:37,552:INFO:Set up train/test split.
2024-12-13 03:15:37,565:INFO:Set up index.
2024-12-13 03:15:37,565:INFO:Set up folding strategy.
2024-12-13 03:15:37,565:INFO:Assigning column types.
2024-12-13 03:15:37,573:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-13 03:15:37,574:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,578:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,582:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,634:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,663:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,663:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:37,665:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:37,666:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,669:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,672:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,711:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,740:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,740:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:37,742:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:37,742:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-13 03:15:37,745:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,748:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,787:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,816:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,816:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:37,818:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:37,821:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,824:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,863:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,891:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,892:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:37,893:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:37,894:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-13 03:15:37,900:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,938:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:37,967:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:37,969:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:37,975:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:15:38,014:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:38,043:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:38,043:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:38,045:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:38,045:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-13 03:15:38,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:38,119:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:38,120:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:38,121:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:38,166:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:38,196:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:38,196:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:38,198:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:38,198:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-13 03:15:38,243:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:38,272:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:38,274:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:38,322:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:38,352:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:38,354:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:38,354:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-13 03:15:38,431:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:38,433:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:38,548:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:38,552:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:38,554:INFO:Preparing preprocessing pipeline...
2024-12-13 03:15:38,554:INFO:Set up simple imputation.
2024-12-13 03:15:38,555:INFO:Set up column name cleaning.
2024-12-13 03:15:38,592:INFO:Finished creating preprocessing pipeline.
2024-12-13 03:15:38,597:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-13 03:15:38,597:INFO:Creating final display dataframe.
2024-12-13 03:15:38,729:INFO:Setup _display_container:                     Description             Value
0                    Session id              6264
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              9153
2024-12-13 03:15:38,815:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:38,817:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:38,893:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:38,894:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:38,895:INFO:setup() successfully completed in 1.43s...............
2024-12-13 03:15:55,567:INFO:PyCaret RegressionExperiment
2024-12-13 03:15:55,579:INFO:Logging name: reg-default-name
2024-12-13 03:15:55,580:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-13 03:15:55,580:INFO:version 3.0.0
2024-12-13 03:15:55,580:INFO:Initializing setup()
2024-12-13 03:15:55,580:INFO:self.USI: b846
2024-12-13 03:15:55,580:INFO:self._variable_keys: {'_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'data', 'y', 'fold_shuffle_param', 'seed', 'gpu_param', 'fold_generator', 'html_param', 'exp_id', 'y_test', 'X_test', 'X_train', 'target_param', 'pipeline', 'y_train', 'log_plots_param', 'transform_target_param', 'USI', 'logging_param', 'X', '_available_plots', 'memory', 'exp_name_log', 'n_jobs_param', 'idx'}
2024-12-13 03:15:55,580:INFO:Checking environment
2024-12-13 03:15:55,581:INFO:python_version: 3.9.20
2024-12-13 03:15:55,581:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-13 03:15:55,582:INFO:machine: arm64
2024-12-13 03:15:55,583:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:15:55,586:INFO:Memory: svmem(total=8589934592, available=1724219392, percent=79.9, used=3083517952, free=62357504, active=1677901824, inactive=1658814464, wired=1405616128)
2024-12-13 03:15:55,587:INFO:Physical Core: 8
2024-12-13 03:15:55,587:INFO:Logical Core: 8
2024-12-13 03:15:55,587:INFO:Checking libraries
2024-12-13 03:15:55,587:INFO:System:
2024-12-13 03:15:55,587:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-13 03:15:55,587:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-13 03:15:55,587:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:15:55,587:INFO:PyCaret required dependencies:
2024-12-13 03:15:55,588:INFO:                 pip: 24.3.1
2024-12-13 03:15:55,588:INFO:          setuptools: 75.1.0
2024-12-13 03:15:55,588:INFO:             pycaret: 3.0.0
2024-12-13 03:15:55,588:INFO:             IPython: 8.12.3
2024-12-13 03:15:55,588:INFO:          ipywidgets: 8.1.5
2024-12-13 03:15:55,589:INFO:                tqdm: 4.66.5
2024-12-13 03:15:55,589:INFO:               numpy: 1.24.4
2024-12-13 03:15:55,589:INFO:              pandas: 1.5.3
2024-12-13 03:15:55,589:INFO:              jinja2: 3.1.4
2024-12-13 03:15:55,589:INFO:               scipy: 1.11.4
2024-12-13 03:15:55,589:INFO:              joblib: 1.3.2
2024-12-13 03:15:55,589:INFO:             sklearn: 1.0.2
2024-12-13 03:15:55,589:INFO:                pyod: 2.0.2
2024-12-13 03:15:55,589:INFO:            imblearn: 0.12.4
2024-12-13 03:15:55,589:INFO:   category_encoders: 2.6.4
2024-12-13 03:15:55,589:INFO:            lightgbm: 4.5.0
2024-12-13 03:15:55,589:INFO:               numba: 0.60.0
2024-12-13 03:15:55,589:INFO:            requests: 2.32.3
2024-12-13 03:15:55,589:INFO:          matplotlib: 3.7.5
2024-12-13 03:15:55,589:INFO:          scikitplot: 0.3.7
2024-12-13 03:15:55,589:INFO:         yellowbrick: 1.5
2024-12-13 03:15:55,589:INFO:              plotly: 5.24.1
2024-12-13 03:15:55,589:INFO:             kaleido: 0.2.1
2024-12-13 03:15:55,589:INFO:         statsmodels: 0.14.3
2024-12-13 03:15:55,589:INFO:              sktime: 0.26.0
2024-12-13 03:15:55,589:INFO:               tbats: 1.1.3
2024-12-13 03:15:55,589:INFO:            pmdarima: 2.0.4
2024-12-13 03:15:55,589:INFO:              psutil: 6.0.0
2024-12-13 03:15:55,589:INFO:PyCaret optional dependencies:
2024-12-13 03:15:55,589:INFO:                shap: Not installed
2024-12-13 03:15:55,589:INFO:           interpret: Not installed
2024-12-13 03:15:55,589:INFO:                umap: Not installed
2024-12-13 03:15:55,589:INFO:    pandas_profiling: Not installed
2024-12-13 03:15:55,589:INFO:  explainerdashboard: Not installed
2024-12-13 03:15:55,589:INFO:             autoviz: Not installed
2024-12-13 03:15:55,589:INFO:           fairlearn: Not installed
2024-12-13 03:15:55,589:INFO:             xgboost: 2.1.2
2024-12-13 03:15:55,589:INFO:            catboost: 1.2.7
2024-12-13 03:15:55,589:INFO:              kmodes: Not installed
2024-12-13 03:15:55,589:INFO:             mlxtend: Not installed
2024-12-13 03:15:55,589:INFO:       statsforecast: Not installed
2024-12-13 03:15:55,589:INFO:        tune_sklearn: Not installed
2024-12-13 03:15:55,589:INFO:                 ray: Not installed
2024-12-13 03:15:55,589:INFO:            hyperopt: Not installed
2024-12-13 03:15:55,590:INFO:              optuna: 4.1.0
2024-12-13 03:15:55,590:INFO:               skopt: Not installed
2024-12-13 03:15:55,590:INFO:              mlflow: Not installed
2024-12-13 03:15:55,590:INFO:              gradio: Not installed
2024-12-13 03:15:55,590:INFO:             fastapi: 0.115.2
2024-12-13 03:15:55,590:INFO:             uvicorn: 0.32.0
2024-12-13 03:15:55,590:INFO:              m2cgen: Not installed
2024-12-13 03:15:55,590:INFO:           evidently: Not installed
2024-12-13 03:15:55,590:INFO:               fugue: Not installed
2024-12-13 03:15:55,590:INFO:           streamlit: 1.39.0
2024-12-13 03:15:55,590:INFO:             prophet: Not installed
2024-12-13 03:15:55,590:INFO:None
2024-12-13 03:15:55,590:INFO:Set up data.
2024-12-13 03:15:55,650:INFO:Set up train/test split.
2024-12-13 03:15:55,656:INFO:Set up index.
2024-12-13 03:15:55,656:INFO:Set up folding strategy.
2024-12-13 03:15:55,657:INFO:Assigning column types.
2024-12-13 03:15:55,661:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-13 03:15:55,661:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,664:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,667:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,705:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,735:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,735:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:55,737:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:55,737:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,740:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,782:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,812:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,813:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:55,815:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:55,815:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-13 03:15:55,819:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,822:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,867:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,901:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,902:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:55,904:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:55,908:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,911:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,958:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:55,991:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:55,993:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:55,994:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-13 03:15:56,001:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:15:56,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:56,076:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:56,076:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:56,078:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:56,084:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:15:56,123:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:56,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:56,152:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:56,154:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:56,154:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-13 03:15:56,199:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:56,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:56,229:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:56,231:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:56,275:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:56,304:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:15:56,304:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:56,306:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:56,306:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-13 03:15:56,350:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:56,379:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:56,381:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:56,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:15:56,454:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:56,456:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:56,456:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-13 03:15:56,530:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:56,532:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:56,639:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:56,641:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:56,642:INFO:Preparing preprocessing pipeline...
2024-12-13 03:15:56,642:INFO:Set up simple imputation.
2024-12-13 03:15:56,643:INFO:Set up column name cleaning.
2024-12-13 03:15:56,672:INFO:Finished creating preprocessing pipeline.
2024-12-13 03:15:56,677:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-13 03:15:56,677:INFO:Creating final display dataframe.
2024-12-13 03:15:56,800:INFO:Setup _display_container:                     Description             Value
0                    Session id              1680
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              b846
2024-12-13 03:15:56,884:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:56,886:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:56,959:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:15:56,961:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:15:56,962:INFO:setup() successfully completed in 1.42s...............
2024-12-13 03:16:09,725:INFO:PyCaret RegressionExperiment
2024-12-13 03:16:09,725:INFO:Logging name: reg-default-name
2024-12-13 03:16:09,725:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-13 03:16:09,725:INFO:version 3.0.0
2024-12-13 03:16:09,725:INFO:Initializing setup()
2024-12-13 03:16:09,725:INFO:self.USI: e285
2024-12-13 03:16:09,725:INFO:self._variable_keys: {'_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'data', 'y', 'fold_shuffle_param', 'seed', 'gpu_param', 'fold_generator', 'html_param', 'exp_id', 'y_test', 'X_test', 'X_train', 'target_param', 'pipeline', 'y_train', 'log_plots_param', 'transform_target_param', 'USI', 'logging_param', 'X', '_available_plots', 'memory', 'exp_name_log', 'n_jobs_param', 'idx'}
2024-12-13 03:16:09,725:INFO:Checking environment
2024-12-13 03:16:09,725:INFO:python_version: 3.9.20
2024-12-13 03:16:09,725:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-13 03:16:09,725:INFO:machine: arm64
2024-12-13 03:16:09,725:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:16:09,726:INFO:Memory: svmem(total=8589934592, available=1831174144, percent=78.7, used=3048390656, free=57409536, active=1790328832, inactive=1769750528, wired=1258061824)
2024-12-13 03:16:09,726:INFO:Physical Core: 8
2024-12-13 03:16:09,726:INFO:Logical Core: 8
2024-12-13 03:16:09,726:INFO:Checking libraries
2024-12-13 03:16:09,726:INFO:System:
2024-12-13 03:16:09,726:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-13 03:16:09,726:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-13 03:16:09,726:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:16:09,726:INFO:PyCaret required dependencies:
2024-12-13 03:16:09,726:INFO:                 pip: 24.3.1
2024-12-13 03:16:09,726:INFO:          setuptools: 75.1.0
2024-12-13 03:16:09,726:INFO:             pycaret: 3.0.0
2024-12-13 03:16:09,726:INFO:             IPython: 8.12.3
2024-12-13 03:16:09,726:INFO:          ipywidgets: 8.1.5
2024-12-13 03:16:09,726:INFO:                tqdm: 4.66.5
2024-12-13 03:16:09,726:INFO:               numpy: 1.24.4
2024-12-13 03:16:09,726:INFO:              pandas: 1.5.3
2024-12-13 03:16:09,726:INFO:              jinja2: 3.1.4
2024-12-13 03:16:09,726:INFO:               scipy: 1.11.4
2024-12-13 03:16:09,726:INFO:              joblib: 1.3.2
2024-12-13 03:16:09,726:INFO:             sklearn: 1.0.2
2024-12-13 03:16:09,726:INFO:                pyod: 2.0.2
2024-12-13 03:16:09,726:INFO:            imblearn: 0.12.4
2024-12-13 03:16:09,726:INFO:   category_encoders: 2.6.4
2024-12-13 03:16:09,726:INFO:            lightgbm: 4.5.0
2024-12-13 03:16:09,726:INFO:               numba: 0.60.0
2024-12-13 03:16:09,726:INFO:            requests: 2.32.3
2024-12-13 03:16:09,726:INFO:          matplotlib: 3.7.5
2024-12-13 03:16:09,726:INFO:          scikitplot: 0.3.7
2024-12-13 03:16:09,726:INFO:         yellowbrick: 1.5
2024-12-13 03:16:09,726:INFO:              plotly: 5.24.1
2024-12-13 03:16:09,726:INFO:             kaleido: 0.2.1
2024-12-13 03:16:09,726:INFO:         statsmodels: 0.14.3
2024-12-13 03:16:09,726:INFO:              sktime: 0.26.0
2024-12-13 03:16:09,726:INFO:               tbats: 1.1.3
2024-12-13 03:16:09,726:INFO:            pmdarima: 2.0.4
2024-12-13 03:16:09,726:INFO:              psutil: 6.0.0
2024-12-13 03:16:09,726:INFO:PyCaret optional dependencies:
2024-12-13 03:16:09,727:INFO:                shap: Not installed
2024-12-13 03:16:09,727:INFO:           interpret: Not installed
2024-12-13 03:16:09,727:INFO:                umap: Not installed
2024-12-13 03:16:09,727:INFO:    pandas_profiling: Not installed
2024-12-13 03:16:09,727:INFO:  explainerdashboard: Not installed
2024-12-13 03:16:09,727:INFO:             autoviz: Not installed
2024-12-13 03:16:09,727:INFO:           fairlearn: Not installed
2024-12-13 03:16:09,727:INFO:             xgboost: 2.1.2
2024-12-13 03:16:09,727:INFO:            catboost: 1.2.7
2024-12-13 03:16:09,727:INFO:              kmodes: Not installed
2024-12-13 03:16:09,727:INFO:             mlxtend: Not installed
2024-12-13 03:16:09,727:INFO:       statsforecast: Not installed
2024-12-13 03:16:09,727:INFO:        tune_sklearn: Not installed
2024-12-13 03:16:09,727:INFO:                 ray: Not installed
2024-12-13 03:16:09,727:INFO:            hyperopt: Not installed
2024-12-13 03:16:09,727:INFO:              optuna: 4.1.0
2024-12-13 03:16:09,727:INFO:               skopt: Not installed
2024-12-13 03:16:09,727:INFO:              mlflow: Not installed
2024-12-13 03:16:09,727:INFO:              gradio: Not installed
2024-12-13 03:16:09,727:INFO:             fastapi: 0.115.2
2024-12-13 03:16:09,727:INFO:             uvicorn: 0.32.0
2024-12-13 03:16:09,727:INFO:              m2cgen: Not installed
2024-12-13 03:16:09,727:INFO:           evidently: Not installed
2024-12-13 03:16:09,727:INFO:               fugue: Not installed
2024-12-13 03:16:09,727:INFO:           streamlit: 1.39.0
2024-12-13 03:16:09,727:INFO:             prophet: Not installed
2024-12-13 03:16:09,727:INFO:None
2024-12-13 03:16:09,727:INFO:Set up data.
2024-12-13 03:16:09,783:INFO:Set up train/test split.
2024-12-13 03:16:09,792:INFO:Set up index.
2024-12-13 03:16:09,792:INFO:Set up folding strategy.
2024-12-13 03:16:09,792:INFO:Assigning column types.
2024-12-13 03:16:09,796:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-13 03:16:09,796:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:16:09,799:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:16:09,802:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:16:09,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:16:09,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:16:09,870:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:09,871:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:09,872:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:16:09,875:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:16:09,878:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:16:09,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:16:09,944:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:16:09,944:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:09,946:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:09,946:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-13 03:16:09,949:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:16:09,952:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:16:09,991:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,019:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,019:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:10,021:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:10,024:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,027:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,065:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,093:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,093:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:10,095:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:10,095:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-13 03:16:10,101:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,169:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:10,171:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:10,177:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,214:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,243:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:10,245:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:10,245:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-13 03:16:10,288:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,317:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,317:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:10,319:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:10,366:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,395:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,395:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:10,397:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:10,398:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-13 03:16:10,441:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,470:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:10,472:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:10,516:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:16:10,545:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:10,547:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:10,547:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-13 03:16:10,620:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:10,621:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:10,695:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:10,697:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:10,698:INFO:Preparing preprocessing pipeline...
2024-12-13 03:16:10,698:INFO:Set up simple imputation.
2024-12-13 03:16:10,699:INFO:Set up column name cleaning.
2024-12-13 03:16:10,727:INFO:Finished creating preprocessing pipeline.
2024-12-13 03:16:10,732:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-13 03:16:10,733:INFO:Creating final display dataframe.
2024-12-13 03:16:10,913:INFO:Setup _display_container:                     Description             Value
0                    Session id               908
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              e285
2024-12-13 03:16:11,034:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:11,036:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:11,116:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:16:11,118:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:16:11,119:INFO:setup() successfully completed in 1.4s...............
2024-12-13 03:23:09,629:INFO:PyCaret RegressionExperiment
2024-12-13 03:23:09,630:INFO:Logging name: reg-default-name
2024-12-13 03:23:09,630:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-13 03:23:09,630:INFO:version 3.0.0
2024-12-13 03:23:09,630:INFO:Initializing setup()
2024-12-13 03:23:09,631:INFO:self.USI: 000e
2024-12-13 03:23:09,631:INFO:self._variable_keys: {'_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'data', 'y', 'fold_shuffle_param', 'seed', 'gpu_param', 'fold_generator', 'html_param', 'exp_id', 'y_test', 'X_test', 'X_train', 'target_param', 'pipeline', 'y_train', 'log_plots_param', 'transform_target_param', 'USI', 'logging_param', 'X', '_available_plots', 'memory', 'exp_name_log', 'n_jobs_param', 'idx'}
2024-12-13 03:23:09,631:INFO:Checking environment
2024-12-13 03:23:09,631:INFO:python_version: 3.9.20
2024-12-13 03:23:09,631:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-13 03:23:09,631:INFO:machine: arm64
2024-12-13 03:23:09,631:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:23:09,631:INFO:Memory: svmem(total=8589934592, available=1671593984, percent=80.5, used=3053518848, free=60538880, active=1623883776, inactive=1514979328, wired=1429635072)
2024-12-13 03:23:09,632:INFO:Physical Core: 8
2024-12-13 03:23:09,632:INFO:Logical Core: 8
2024-12-13 03:23:09,632:INFO:Checking libraries
2024-12-13 03:23:09,632:INFO:System:
2024-12-13 03:23:09,632:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-13 03:23:09,635:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-13 03:23:09,635:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:23:09,635:INFO:PyCaret required dependencies:
2024-12-13 03:23:09,635:INFO:                 pip: 24.3.1
2024-12-13 03:23:09,635:INFO:          setuptools: 75.1.0
2024-12-13 03:23:09,635:INFO:             pycaret: 3.0.0
2024-12-13 03:23:09,635:INFO:             IPython: 8.12.3
2024-12-13 03:23:09,635:INFO:          ipywidgets: 8.1.5
2024-12-13 03:23:09,635:INFO:                tqdm: 4.66.5
2024-12-13 03:23:09,635:INFO:               numpy: 1.24.4
2024-12-13 03:23:09,635:INFO:              pandas: 1.5.3
2024-12-13 03:23:09,635:INFO:              jinja2: 3.1.4
2024-12-13 03:23:09,635:INFO:               scipy: 1.11.4
2024-12-13 03:23:09,635:INFO:              joblib: 1.3.2
2024-12-13 03:23:09,635:INFO:             sklearn: 1.0.2
2024-12-13 03:23:09,635:INFO:                pyod: 2.0.2
2024-12-13 03:23:09,635:INFO:            imblearn: 0.12.4
2024-12-13 03:23:09,635:INFO:   category_encoders: 2.6.4
2024-12-13 03:23:09,635:INFO:            lightgbm: 4.5.0
2024-12-13 03:23:09,635:INFO:               numba: 0.60.0
2024-12-13 03:23:09,635:INFO:            requests: 2.32.3
2024-12-13 03:23:09,635:INFO:          matplotlib: 3.7.5
2024-12-13 03:23:09,635:INFO:          scikitplot: 0.3.7
2024-12-13 03:23:09,635:INFO:         yellowbrick: 1.5
2024-12-13 03:23:09,635:INFO:              plotly: 5.24.1
2024-12-13 03:23:09,635:INFO:             kaleido: 0.2.1
2024-12-13 03:23:09,635:INFO:         statsmodels: 0.14.3
2024-12-13 03:23:09,635:INFO:              sktime: 0.26.0
2024-12-13 03:23:09,635:INFO:               tbats: 1.1.3
2024-12-13 03:23:09,636:INFO:            pmdarima: 2.0.4
2024-12-13 03:23:09,636:INFO:              psutil: 6.0.0
2024-12-13 03:23:09,636:INFO:PyCaret optional dependencies:
2024-12-13 03:23:09,636:INFO:                shap: Not installed
2024-12-13 03:23:09,636:INFO:           interpret: Not installed
2024-12-13 03:23:09,636:INFO:                umap: Not installed
2024-12-13 03:23:09,636:INFO:    pandas_profiling: Not installed
2024-12-13 03:23:09,636:INFO:  explainerdashboard: Not installed
2024-12-13 03:23:09,636:INFO:             autoviz: Not installed
2024-12-13 03:23:09,636:INFO:           fairlearn: Not installed
2024-12-13 03:23:09,636:INFO:             xgboost: 2.1.2
2024-12-13 03:23:09,636:INFO:            catboost: 1.2.7
2024-12-13 03:23:09,636:INFO:              kmodes: Not installed
2024-12-13 03:23:09,636:INFO:             mlxtend: Not installed
2024-12-13 03:23:09,636:INFO:       statsforecast: Not installed
2024-12-13 03:23:09,636:INFO:        tune_sklearn: Not installed
2024-12-13 03:23:09,636:INFO:                 ray: Not installed
2024-12-13 03:23:09,636:INFO:            hyperopt: Not installed
2024-12-13 03:23:09,637:INFO:              optuna: 4.1.0
2024-12-13 03:23:09,637:INFO:               skopt: Not installed
2024-12-13 03:23:09,637:INFO:              mlflow: Not installed
2024-12-13 03:23:09,637:INFO:              gradio: Not installed
2024-12-13 03:23:09,637:INFO:             fastapi: 0.115.2
2024-12-13 03:23:09,637:INFO:             uvicorn: 0.32.0
2024-12-13 03:23:09,637:INFO:              m2cgen: Not installed
2024-12-13 03:23:09,637:INFO:           evidently: Not installed
2024-12-13 03:23:09,637:INFO:               fugue: Not installed
2024-12-13 03:23:09,637:INFO:           streamlit: 1.39.0
2024-12-13 03:23:09,637:INFO:             prophet: Not installed
2024-12-13 03:23:09,637:INFO:None
2024-12-13 03:23:09,637:INFO:Set up data.
2024-12-13 03:23:09,698:INFO:Set up train/test split.
2024-12-13 03:23:09,703:INFO:Set up index.
2024-12-13 03:23:09,704:INFO:Set up folding strategy.
2024-12-13 03:23:09,704:INFO:Assigning column types.
2024-12-13 03:23:09,707:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-13 03:23:09,707:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,710:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,713:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,751:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,779:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,780:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:09,781:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:09,782:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,785:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,788:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,826:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,855:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,855:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:09,857:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:09,857:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-13 03:23:09,860:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,863:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,902:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,930:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,931:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:09,932:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:09,936:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,939:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:09,976:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,005:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:10,006:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:10,006:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-13 03:23:10,012:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,050:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,079:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,079:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:10,081:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:10,087:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,152:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,153:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:10,155:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:10,155:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-13 03:23:10,199:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,227:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:10,229:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:10,272:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,302:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:10,304:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:10,307:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-13 03:23:10,351:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,380:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:10,381:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:10,425:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:10,454:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:10,455:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:10,456:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-13 03:23:10,530:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:10,532:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:10,604:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:10,606:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:10,607:INFO:Preparing preprocessing pipeline...
2024-12-13 03:23:10,607:INFO:Set up simple imputation.
2024-12-13 03:23:10,608:INFO:Set up column name cleaning.
2024-12-13 03:23:10,636:INFO:Finished creating preprocessing pipeline.
2024-12-13 03:23:10,641:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-13 03:23:10,641:INFO:Creating final display dataframe.
2024-12-13 03:23:10,765:INFO:Setup _display_container:                     Description             Value
0                    Session id              6150
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              000e
2024-12-13 03:23:10,890:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:10,892:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:10,965:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:10,967:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:10,968:INFO:setup() successfully completed in 1.34s...............
2024-12-13 03:23:18,784:INFO:PyCaret RegressionExperiment
2024-12-13 03:23:18,784:INFO:Logging name: reg-default-name
2024-12-13 03:23:18,784:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-13 03:23:18,784:INFO:version 3.0.0
2024-12-13 03:23:18,784:INFO:Initializing setup()
2024-12-13 03:23:18,784:INFO:self.USI: 106e
2024-12-13 03:23:18,784:INFO:self._variable_keys: {'_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'data', 'y', 'fold_shuffle_param', 'seed', 'gpu_param', 'fold_generator', 'html_param', 'exp_id', 'y_test', 'X_test', 'X_train', 'target_param', 'pipeline', 'y_train', 'log_plots_param', 'transform_target_param', 'USI', 'logging_param', 'X', '_available_plots', 'memory', 'exp_name_log', 'n_jobs_param', 'idx'}
2024-12-13 03:23:18,784:INFO:Checking environment
2024-12-13 03:23:18,784:INFO:python_version: 3.9.20
2024-12-13 03:23:18,785:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-13 03:23:18,785:INFO:machine: arm64
2024-12-13 03:23:18,785:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:23:18,785:INFO:Memory: svmem(total=8589934592, available=1714929664, percent=80.0, used=3051896832, free=65683456, active=1657913344, inactive=1613185024, wired=1393983488)
2024-12-13 03:23:18,785:INFO:Physical Core: 8
2024-12-13 03:23:18,785:INFO:Logical Core: 8
2024-12-13 03:23:18,785:INFO:Checking libraries
2024-12-13 03:23:18,785:INFO:System:
2024-12-13 03:23:18,785:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-13 03:23:18,785:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-13 03:23:18,785:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:23:18,785:INFO:PyCaret required dependencies:
2024-12-13 03:23:18,785:INFO:                 pip: 24.3.1
2024-12-13 03:23:18,785:INFO:          setuptools: 75.1.0
2024-12-13 03:23:18,785:INFO:             pycaret: 3.0.0
2024-12-13 03:23:18,785:INFO:             IPython: 8.12.3
2024-12-13 03:23:18,785:INFO:          ipywidgets: 8.1.5
2024-12-13 03:23:18,785:INFO:                tqdm: 4.66.5
2024-12-13 03:23:18,785:INFO:               numpy: 1.24.4
2024-12-13 03:23:18,785:INFO:              pandas: 1.5.3
2024-12-13 03:23:18,785:INFO:              jinja2: 3.1.4
2024-12-13 03:23:18,785:INFO:               scipy: 1.11.4
2024-12-13 03:23:18,785:INFO:              joblib: 1.3.2
2024-12-13 03:23:18,785:INFO:             sklearn: 1.0.2
2024-12-13 03:23:18,785:INFO:                pyod: 2.0.2
2024-12-13 03:23:18,785:INFO:            imblearn: 0.12.4
2024-12-13 03:23:18,785:INFO:   category_encoders: 2.6.4
2024-12-13 03:23:18,786:INFO:            lightgbm: 4.5.0
2024-12-13 03:23:18,786:INFO:               numba: 0.60.0
2024-12-13 03:23:18,786:INFO:            requests: 2.32.3
2024-12-13 03:23:18,786:INFO:          matplotlib: 3.7.5
2024-12-13 03:23:18,786:INFO:          scikitplot: 0.3.7
2024-12-13 03:23:18,786:INFO:         yellowbrick: 1.5
2024-12-13 03:23:18,786:INFO:              plotly: 5.24.1
2024-12-13 03:23:18,786:INFO:             kaleido: 0.2.1
2024-12-13 03:23:18,786:INFO:         statsmodels: 0.14.3
2024-12-13 03:23:18,786:INFO:              sktime: 0.26.0
2024-12-13 03:23:18,786:INFO:               tbats: 1.1.3
2024-12-13 03:23:18,786:INFO:            pmdarima: 2.0.4
2024-12-13 03:23:18,786:INFO:              psutil: 6.0.0
2024-12-13 03:23:18,786:INFO:PyCaret optional dependencies:
2024-12-13 03:23:18,786:INFO:                shap: Not installed
2024-12-13 03:23:18,786:INFO:           interpret: Not installed
2024-12-13 03:23:18,786:INFO:                umap: Not installed
2024-12-13 03:23:18,786:INFO:    pandas_profiling: Not installed
2024-12-13 03:23:18,786:INFO:  explainerdashboard: Not installed
2024-12-13 03:23:18,786:INFO:             autoviz: Not installed
2024-12-13 03:23:18,786:INFO:           fairlearn: Not installed
2024-12-13 03:23:18,786:INFO:             xgboost: 2.1.2
2024-12-13 03:23:18,786:INFO:            catboost: 1.2.7
2024-12-13 03:23:18,786:INFO:              kmodes: Not installed
2024-12-13 03:23:18,786:INFO:             mlxtend: Not installed
2024-12-13 03:23:18,786:INFO:       statsforecast: Not installed
2024-12-13 03:23:18,786:INFO:        tune_sklearn: Not installed
2024-12-13 03:23:18,786:INFO:                 ray: Not installed
2024-12-13 03:23:18,786:INFO:            hyperopt: Not installed
2024-12-13 03:23:18,786:INFO:              optuna: 4.1.0
2024-12-13 03:23:18,786:INFO:               skopt: Not installed
2024-12-13 03:23:18,786:INFO:              mlflow: Not installed
2024-12-13 03:23:18,786:INFO:              gradio: Not installed
2024-12-13 03:23:18,786:INFO:             fastapi: 0.115.2
2024-12-13 03:23:18,786:INFO:             uvicorn: 0.32.0
2024-12-13 03:23:18,786:INFO:              m2cgen: Not installed
2024-12-13 03:23:18,787:INFO:           evidently: Not installed
2024-12-13 03:23:18,787:INFO:               fugue: Not installed
2024-12-13 03:23:18,787:INFO:           streamlit: 1.39.0
2024-12-13 03:23:18,787:INFO:             prophet: Not installed
2024-12-13 03:23:18,787:INFO:None
2024-12-13 03:23:18,787:INFO:Set up data.
2024-12-13 03:23:18,841:INFO:Set up train/test split.
2024-12-13 03:23:18,846:INFO:Set up index.
2024-12-13 03:23:18,846:INFO:Set up folding strategy.
2024-12-13 03:23:18,846:INFO:Assigning column types.
2024-12-13 03:23:18,849:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-13 03:23:18,849:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:23:18,852:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:18,855:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:18,893:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:18,922:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:18,922:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:18,924:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:18,924:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:23:18,927:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:18,930:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:18,969:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:18,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:18,998:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:19,000:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:19,000:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-13 03:23:19,003:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,006:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,072:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,072:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:19,074:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:19,077:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,080:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,147:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:19,148:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:19,148:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-13 03:23:19,154:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,191:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,220:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:19,222:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:19,228:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,266:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,294:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,295:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:19,296:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:19,297:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-13 03:23:19,340:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,368:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,368:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:19,370:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:19,413:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,441:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,442:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:19,443:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:19,444:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-13 03:23:19,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,515:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:19,517:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:19,561:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:19,590:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:19,592:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:19,592:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-13 03:23:19,664:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:19,666:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:19,738:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:19,740:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:19,741:INFO:Preparing preprocessing pipeline...
2024-12-13 03:23:19,741:INFO:Set up simple imputation.
2024-12-13 03:23:19,742:INFO:Set up column name cleaning.
2024-12-13 03:23:19,768:INFO:Finished creating preprocessing pipeline.
2024-12-13 03:23:19,773:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-13 03:23:19,773:INFO:Creating final display dataframe.
2024-12-13 03:23:19,939:INFO:Setup _display_container:                     Description             Value
0                    Session id              8606
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              106e
2024-12-13 03:23:20,019:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:20,021:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:20,095:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:20,097:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:20,097:INFO:setup() successfully completed in 1.32s...............
2024-12-13 03:23:23,731:INFO:PyCaret RegressionExperiment
2024-12-13 03:23:23,731:INFO:Logging name: reg-default-name
2024-12-13 03:23:23,731:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-13 03:23:23,731:INFO:version 3.0.0
2024-12-13 03:23:23,732:INFO:Initializing setup()
2024-12-13 03:23:23,732:INFO:self.USI: 62f4
2024-12-13 03:23:23,732:INFO:self._variable_keys: {'_ml_usecase', 'gpu_n_jobs_param', 'fold_groups_param', 'data', 'y', 'fold_shuffle_param', 'seed', 'gpu_param', 'fold_generator', 'html_param', 'exp_id', 'y_test', 'X_test', 'X_train', 'target_param', 'pipeline', 'y_train', 'log_plots_param', 'transform_target_param', 'USI', 'logging_param', 'X', '_available_plots', 'memory', 'exp_name_log', 'n_jobs_param', 'idx'}
2024-12-13 03:23:23,732:INFO:Checking environment
2024-12-13 03:23:23,732:INFO:python_version: 3.9.20
2024-12-13 03:23:23,732:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-13 03:23:23,732:INFO:machine: arm64
2024-12-13 03:23:23,732:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:23:23,732:INFO:Memory: svmem(total=8589934592, available=1702461440, percent=80.2, used=3016753152, free=115392512, active=1605550080, inactive=1555726336, wired=1411203072)
2024-12-13 03:23:23,732:INFO:Physical Core: 8
2024-12-13 03:23:23,732:INFO:Logical Core: 8
2024-12-13 03:23:23,732:INFO:Checking libraries
2024-12-13 03:23:23,732:INFO:System:
2024-12-13 03:23:23,732:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-13 03:23:23,732:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-13 03:23:23,732:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:23:23,732:INFO:PyCaret required dependencies:
2024-12-13 03:23:23,732:INFO:                 pip: 24.3.1
2024-12-13 03:23:23,733:INFO:          setuptools: 75.1.0
2024-12-13 03:23:23,733:INFO:             pycaret: 3.0.0
2024-12-13 03:23:23,733:INFO:             IPython: 8.12.3
2024-12-13 03:23:23,733:INFO:          ipywidgets: 8.1.5
2024-12-13 03:23:23,733:INFO:                tqdm: 4.66.5
2024-12-13 03:23:23,733:INFO:               numpy: 1.24.4
2024-12-13 03:23:23,733:INFO:              pandas: 1.5.3
2024-12-13 03:23:23,733:INFO:              jinja2: 3.1.4
2024-12-13 03:23:23,733:INFO:               scipy: 1.11.4
2024-12-13 03:23:23,733:INFO:              joblib: 1.3.2
2024-12-13 03:23:23,733:INFO:             sklearn: 1.0.2
2024-12-13 03:23:23,733:INFO:                pyod: 2.0.2
2024-12-13 03:23:23,733:INFO:            imblearn: 0.12.4
2024-12-13 03:23:23,733:INFO:   category_encoders: 2.6.4
2024-12-13 03:23:23,733:INFO:            lightgbm: 4.5.0
2024-12-13 03:23:23,733:INFO:               numba: 0.60.0
2024-12-13 03:23:23,733:INFO:            requests: 2.32.3
2024-12-13 03:23:23,733:INFO:          matplotlib: 3.7.5
2024-12-13 03:23:23,733:INFO:          scikitplot: 0.3.7
2024-12-13 03:23:23,733:INFO:         yellowbrick: 1.5
2024-12-13 03:23:23,733:INFO:              plotly: 5.24.1
2024-12-13 03:23:23,733:INFO:             kaleido: 0.2.1
2024-12-13 03:23:23,733:INFO:         statsmodels: 0.14.3
2024-12-13 03:23:23,734:INFO:              sktime: 0.26.0
2024-12-13 03:23:23,734:INFO:               tbats: 1.1.3
2024-12-13 03:23:23,734:INFO:            pmdarima: 2.0.4
2024-12-13 03:23:23,734:INFO:              psutil: 6.0.0
2024-12-13 03:23:23,734:INFO:PyCaret optional dependencies:
2024-12-13 03:23:23,734:INFO:                shap: Not installed
2024-12-13 03:23:23,734:INFO:           interpret: Not installed
2024-12-13 03:23:23,734:INFO:                umap: Not installed
2024-12-13 03:23:23,734:INFO:    pandas_profiling: Not installed
2024-12-13 03:23:23,734:INFO:  explainerdashboard: Not installed
2024-12-13 03:23:23,734:INFO:             autoviz: Not installed
2024-12-13 03:23:23,734:INFO:           fairlearn: Not installed
2024-12-13 03:23:23,734:INFO:             xgboost: 2.1.2
2024-12-13 03:23:23,734:INFO:            catboost: 1.2.7
2024-12-13 03:23:23,734:INFO:              kmodes: Not installed
2024-12-13 03:23:23,734:INFO:             mlxtend: Not installed
2024-12-13 03:23:23,734:INFO:       statsforecast: Not installed
2024-12-13 03:23:23,734:INFO:        tune_sklearn: Not installed
2024-12-13 03:23:23,734:INFO:                 ray: Not installed
2024-12-13 03:23:23,734:INFO:            hyperopt: Not installed
2024-12-13 03:23:23,734:INFO:              optuna: 4.1.0
2024-12-13 03:23:23,734:INFO:               skopt: Not installed
2024-12-13 03:23:23,734:INFO:              mlflow: Not installed
2024-12-13 03:23:23,734:INFO:              gradio: Not installed
2024-12-13 03:23:23,734:INFO:             fastapi: 0.115.2
2024-12-13 03:23:23,734:INFO:             uvicorn: 0.32.0
2024-12-13 03:23:23,734:INFO:              m2cgen: Not installed
2024-12-13 03:23:23,735:INFO:           evidently: Not installed
2024-12-13 03:23:23,735:INFO:               fugue: Not installed
2024-12-13 03:23:23,735:INFO:           streamlit: 1.39.0
2024-12-13 03:23:23,735:INFO:             prophet: Not installed
2024-12-13 03:23:23,735:INFO:None
2024-12-13 03:23:23,735:INFO:Set up data.
2024-12-13 03:23:23,791:INFO:Set up train/test split.
2024-12-13 03:23:23,796:INFO:Set up index.
2024-12-13 03:23:23,796:INFO:Set up folding strategy.
2024-12-13 03:23:23,796:INFO:Assigning column types.
2024-12-13 03:23:23,799:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-13 03:23:23,799:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:23:23,802:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:23,805:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:23,860:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:23,890:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:23,890:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:23,892:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:23,892:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:23:23,895:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:23,898:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,522:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,552:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,552:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:24,554:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:24,554:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-13 03:23:24,557:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,560:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,629:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,629:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:24,631:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:24,634:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,637:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,705:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:24,707:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:24,707:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-13 03:23:24,713:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,751:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,780:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,780:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:24,782:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:24,788:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,826:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,855:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,855:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:24,857:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:24,857:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-13 03:23:24,902:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,930:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:24,931:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:24,932:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:25,016:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:25,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:25,045:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:25,046:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:25,047:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-13 03:23:25,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:25,119:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:25,120:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:25,163:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:25,192:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:25,194:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:25,194:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-13 03:23:25,267:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:25,268:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:25,341:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:25,343:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:25,344:INFO:Preparing preprocessing pipeline...
2024-12-13 03:23:25,344:INFO:Set up simple imputation.
2024-12-13 03:23:25,345:INFO:Set up column name cleaning.
2024-12-13 03:23:25,372:INFO:Finished creating preprocessing pipeline.
2024-12-13 03:23:25,377:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-13 03:23:25,377:INFO:Creating final display dataframe.
2024-12-13 03:23:25,496:INFO:Setup _display_container:                     Description             Value
0                    Session id              8007
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              62f4
2024-12-13 03:23:25,576:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:25,578:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:25,655:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:25,657:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:25,658:INFO:setup() successfully completed in 1.93s...............
2024-12-13 03:23:31,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:23:31,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:23:31,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:23:31,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:23:32,219:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-13 03:23:34,974:INFO:PyCaret RegressionExperiment
2024-12-13 03:23:34,974:INFO:Logging name: reg-default-name
2024-12-13 03:23:34,975:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-13 03:23:34,975:INFO:version 3.0.0
2024-12-13 03:23:34,975:INFO:Initializing setup()
2024-12-13 03:23:34,975:INFO:self.USI: 2e82
2024-12-13 03:23:34,975:INFO:self._variable_keys: {'exp_id', 'html_param', 'logging_param', 'pipeline', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'X_train', 'transform_target_param', 'exp_name_log', 'log_plots_param', 'fold_shuffle_param', 'y', 'fold_groups_param', 'memory', 'target_param', 'X', '_available_plots', 'idx', 'y_train', 'gpu_param', 'USI', 'y_test', '_ml_usecase', 'data', 'seed', 'X_test'}
2024-12-13 03:23:34,975:INFO:Checking environment
2024-12-13 03:23:34,975:INFO:python_version: 3.9.20
2024-12-13 03:23:34,975:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-13 03:23:34,975:INFO:machine: arm64
2024-12-13 03:23:34,975:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:23:34,975:INFO:Memory: svmem(total=8589934592, available=1666629632, percent=80.6, used=2999828480, free=58998784, active=1622360064, inactive=1511243776, wired=1377468416)
2024-12-13 03:23:34,975:INFO:Physical Core: 8
2024-12-13 03:23:34,975:INFO:Logical Core: 8
2024-12-13 03:23:34,975:INFO:Checking libraries
2024-12-13 03:23:34,975:INFO:System:
2024-12-13 03:23:34,975:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-13 03:23:34,975:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-13 03:23:34,975:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:23:34,975:INFO:PyCaret required dependencies:
2024-12-13 03:23:34,975:INFO:                 pip: 24.3.1
2024-12-13 03:23:34,975:INFO:          setuptools: 75.1.0
2024-12-13 03:23:34,975:INFO:             pycaret: 3.0.0
2024-12-13 03:23:34,975:INFO:             IPython: 8.12.3
2024-12-13 03:23:34,975:INFO:          ipywidgets: 8.1.5
2024-12-13 03:23:34,975:INFO:                tqdm: 4.66.5
2024-12-13 03:23:34,976:INFO:               numpy: 1.24.4
2024-12-13 03:23:34,976:INFO:              pandas: 1.5.3
2024-12-13 03:23:34,976:INFO:              jinja2: 3.1.4
2024-12-13 03:23:34,976:INFO:               scipy: 1.11.4
2024-12-13 03:23:34,976:INFO:              joblib: 1.3.2
2024-12-13 03:23:34,976:INFO:             sklearn: 1.0.2
2024-12-13 03:23:34,976:INFO:                pyod: 2.0.2
2024-12-13 03:23:34,976:INFO:            imblearn: 0.12.4
2024-12-13 03:23:34,976:INFO:   category_encoders: 2.6.4
2024-12-13 03:23:34,976:INFO:            lightgbm: 4.5.0
2024-12-13 03:23:34,976:INFO:               numba: 0.60.0
2024-12-13 03:23:34,976:INFO:            requests: 2.32.3
2024-12-13 03:23:34,976:INFO:          matplotlib: 3.7.5
2024-12-13 03:23:34,976:INFO:          scikitplot: 0.3.7
2024-12-13 03:23:34,976:INFO:         yellowbrick: 1.5
2024-12-13 03:23:34,976:INFO:              plotly: 5.24.1
2024-12-13 03:23:34,976:INFO:             kaleido: 0.2.1
2024-12-13 03:23:34,976:INFO:         statsmodels: 0.14.3
2024-12-13 03:23:34,976:INFO:              sktime: 0.26.0
2024-12-13 03:23:34,976:INFO:               tbats: 1.1.3
2024-12-13 03:23:34,976:INFO:            pmdarima: 2.0.4
2024-12-13 03:23:34,976:INFO:              psutil: 6.0.0
2024-12-13 03:23:34,976:INFO:PyCaret optional dependencies:
2024-12-13 03:23:35,418:INFO:                shap: Not installed
2024-12-13 03:23:35,418:INFO:           interpret: Not installed
2024-12-13 03:23:35,418:INFO:                umap: Not installed
2024-12-13 03:23:35,418:INFO:    pandas_profiling: Not installed
2024-12-13 03:23:35,418:INFO:  explainerdashboard: Not installed
2024-12-13 03:23:35,418:INFO:             autoviz: Not installed
2024-12-13 03:23:35,418:INFO:           fairlearn: Not installed
2024-12-13 03:23:35,418:INFO:             xgboost: 2.1.2
2024-12-13 03:23:35,418:INFO:            catboost: 1.2.7
2024-12-13 03:23:35,418:INFO:              kmodes: Not installed
2024-12-13 03:23:35,418:INFO:             mlxtend: Not installed
2024-12-13 03:23:35,418:INFO:       statsforecast: Not installed
2024-12-13 03:23:35,418:INFO:        tune_sklearn: Not installed
2024-12-13 03:23:35,418:INFO:                 ray: Not installed
2024-12-13 03:23:35,418:INFO:            hyperopt: Not installed
2024-12-13 03:23:35,418:INFO:              optuna: 4.1.0
2024-12-13 03:23:35,418:INFO:               skopt: Not installed
2024-12-13 03:23:35,418:INFO:              mlflow: Not installed
2024-12-13 03:23:35,418:INFO:              gradio: Not installed
2024-12-13 03:23:35,418:INFO:             fastapi: 0.115.2
2024-12-13 03:23:35,418:INFO:             uvicorn: 0.32.0
2024-12-13 03:23:35,418:INFO:              m2cgen: Not installed
2024-12-13 03:23:35,418:INFO:           evidently: Not installed
2024-12-13 03:23:35,418:INFO:               fugue: Not installed
2024-12-13 03:23:35,419:INFO:           streamlit: 1.39.0
2024-12-13 03:23:35,419:INFO:             prophet: Not installed
2024-12-13 03:23:35,419:INFO:None
2024-12-13 03:23:35,419:INFO:Set up data.
2024-12-13 03:23:35,466:INFO:Set up train/test split.
2024-12-13 03:23:35,471:INFO:Set up index.
2024-12-13 03:23:35,471:INFO:Set up folding strategy.
2024-12-13 03:23:35,471:INFO:Assigning column types.
2024-12-13 03:23:35,474:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-13 03:23:35,474:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,477:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,480:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,551:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,552:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:35,553:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:35,554:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,557:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,560:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,627:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,628:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:35,630:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:35,630:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-13 03:23:35,633:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,636:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,674:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,703:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:35,705:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:35,708:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,711:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,750:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,779:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,779:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:35,781:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:35,781:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-13 03:23:35,787:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,825:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,854:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,855:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:35,856:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:35,862:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,901:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,929:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:35,930:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:35,931:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:35,932:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-13 03:23:35,976:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:36,005:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:36,005:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:36,007:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:36,081:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:36,110:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:23:36,111:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:36,112:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:36,113:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-13 03:23:36,157:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:36,187:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:36,188:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:36,233:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:23:36,264:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:36,266:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:36,266:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-13 03:23:36,340:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:36,342:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:36,415:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:36,417:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:36,419:INFO:Preparing preprocessing pipeline...
2024-12-13 03:23:36,419:INFO:Set up simple imputation.
2024-12-13 03:23:36,420:INFO:Set up column name cleaning.
2024-12-13 03:23:36,449:INFO:Finished creating preprocessing pipeline.
2024-12-13 03:23:36,455:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-13 03:23:36,455:INFO:Creating final display dataframe.
2024-12-13 03:23:36,576:INFO:Setup _display_container:                     Description             Value
0                    Session id              4548
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              2e82
2024-12-13 03:23:36,669:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:36,671:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:36,755:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:23:36,757:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:23:36,757:INFO:setup() successfully completed in 1.78s...............
2024-12-13 03:24:27,393:INFO:PyCaret RegressionExperiment
2024-12-13 03:24:27,394:INFO:Logging name: reg-default-name
2024-12-13 03:24:27,394:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-13 03:24:27,394:INFO:version 3.0.0
2024-12-13 03:24:27,394:INFO:Initializing setup()
2024-12-13 03:24:27,394:INFO:self.USI: d9f0
2024-12-13 03:24:27,394:INFO:self._variable_keys: {'exp_id', 'html_param', 'logging_param', 'pipeline', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'X_train', 'transform_target_param', 'exp_name_log', 'log_plots_param', 'fold_shuffle_param', 'y', 'fold_groups_param', 'memory', 'target_param', 'X', '_available_plots', 'idx', 'y_train', 'gpu_param', 'USI', 'y_test', '_ml_usecase', 'data', 'seed', 'X_test'}
2024-12-13 03:24:27,394:INFO:Checking environment
2024-12-13 03:24:27,394:INFO:python_version: 3.9.20
2024-12-13 03:24:27,394:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-13 03:24:27,394:INFO:machine: arm64
2024-12-13 03:24:27,394:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:24:27,394:INFO:Memory: svmem(total=8589934592, available=1788575744, percent=79.2, used=3031744512, free=66519040, active=1740832768, inactive=1704624128, wired=1290911744)
2024-12-13 03:24:27,394:INFO:Physical Core: 8
2024-12-13 03:24:27,394:INFO:Logical Core: 8
2024-12-13 03:24:27,394:INFO:Checking libraries
2024-12-13 03:24:27,394:INFO:System:
2024-12-13 03:24:27,394:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-13 03:24:27,394:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-13 03:24:27,394:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:24:27,394:INFO:PyCaret required dependencies:
2024-12-13 03:24:27,395:INFO:                 pip: 24.3.1
2024-12-13 03:24:27,395:INFO:          setuptools: 75.1.0
2024-12-13 03:24:27,395:INFO:             pycaret: 3.0.0
2024-12-13 03:24:27,395:INFO:             IPython: 8.12.3
2024-12-13 03:24:27,395:INFO:          ipywidgets: 8.1.5
2024-12-13 03:24:27,395:INFO:                tqdm: 4.66.5
2024-12-13 03:24:27,395:INFO:               numpy: 1.24.4
2024-12-13 03:24:27,395:INFO:              pandas: 1.5.3
2024-12-13 03:24:27,395:INFO:              jinja2: 3.1.4
2024-12-13 03:24:27,395:INFO:               scipy: 1.11.4
2024-12-13 03:24:27,395:INFO:              joblib: 1.3.2
2024-12-13 03:24:27,395:INFO:             sklearn: 1.0.2
2024-12-13 03:24:27,395:INFO:                pyod: 2.0.2
2024-12-13 03:24:27,395:INFO:            imblearn: 0.12.4
2024-12-13 03:24:27,395:INFO:   category_encoders: 2.6.4
2024-12-13 03:24:27,395:INFO:            lightgbm: 4.5.0
2024-12-13 03:24:27,395:INFO:               numba: 0.60.0
2024-12-13 03:24:27,395:INFO:            requests: 2.32.3
2024-12-13 03:24:27,395:INFO:          matplotlib: 3.7.5
2024-12-13 03:24:27,395:INFO:          scikitplot: 0.3.7
2024-12-13 03:24:27,395:INFO:         yellowbrick: 1.5
2024-12-13 03:24:27,395:INFO:              plotly: 5.24.1
2024-12-13 03:24:27,395:INFO:             kaleido: 0.2.1
2024-12-13 03:24:27,395:INFO:         statsmodels: 0.14.3
2024-12-13 03:24:27,395:INFO:              sktime: 0.26.0
2024-12-13 03:24:27,395:INFO:               tbats: 1.1.3
2024-12-13 03:24:27,395:INFO:            pmdarima: 2.0.4
2024-12-13 03:24:27,395:INFO:              psutil: 6.0.0
2024-12-13 03:24:27,395:INFO:PyCaret optional dependencies:
2024-12-13 03:24:27,395:INFO:                shap: Not installed
2024-12-13 03:24:27,395:INFO:           interpret: Not installed
2024-12-13 03:24:27,395:INFO:                umap: Not installed
2024-12-13 03:24:27,395:INFO:    pandas_profiling: Not installed
2024-12-13 03:24:27,395:INFO:  explainerdashboard: Not installed
2024-12-13 03:24:27,395:INFO:             autoviz: Not installed
2024-12-13 03:24:27,395:INFO:           fairlearn: Not installed
2024-12-13 03:24:27,395:INFO:             xgboost: 2.1.2
2024-12-13 03:24:27,395:INFO:            catboost: 1.2.7
2024-12-13 03:24:27,395:INFO:              kmodes: Not installed
2024-12-13 03:24:27,395:INFO:             mlxtend: Not installed
2024-12-13 03:24:27,395:INFO:       statsforecast: Not installed
2024-12-13 03:24:27,395:INFO:        tune_sklearn: Not installed
2024-12-13 03:24:27,395:INFO:                 ray: Not installed
2024-12-13 03:24:27,395:INFO:            hyperopt: Not installed
2024-12-13 03:24:27,395:INFO:              optuna: 4.1.0
2024-12-13 03:24:27,395:INFO:               skopt: Not installed
2024-12-13 03:24:27,396:INFO:              mlflow: Not installed
2024-12-13 03:24:27,396:INFO:              gradio: Not installed
2024-12-13 03:24:27,396:INFO:             fastapi: 0.115.2
2024-12-13 03:24:27,396:INFO:             uvicorn: 0.32.0
2024-12-13 03:24:27,396:INFO:              m2cgen: Not installed
2024-12-13 03:24:27,396:INFO:           evidently: Not installed
2024-12-13 03:24:27,396:INFO:               fugue: Not installed
2024-12-13 03:24:27,396:INFO:           streamlit: 1.39.0
2024-12-13 03:24:27,396:INFO:             prophet: Not installed
2024-12-13 03:24:27,396:INFO:None
2024-12-13 03:24:27,396:INFO:Set up data.
2024-12-13 03:24:27,494:INFO:Set up train/test split.
2024-12-13 03:24:27,499:INFO:Set up index.
2024-12-13 03:24:27,500:INFO:Set up folding strategy.
2024-12-13 03:24:27,500:INFO:Assigning column types.
2024-12-13 03:24:27,503:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-13 03:24:27,503:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,506:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,509:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,547:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,576:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,577:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:27,579:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:27,579:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,582:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,585:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,624:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,653:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:27,655:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:27,655:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-13 03:24:27,658:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,661:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,700:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,729:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:27,731:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:27,734:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,737:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,775:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,804:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,804:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:27,806:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:27,806:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-13 03:24:27,812:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,850:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,880:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:27,882:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:27,888:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,958:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:27,958:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:27,960:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:27,960:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-13 03:24:28,004:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:28,034:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:28,034:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:28,036:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:28,081:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:28,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:28,115:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:28,117:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:28,118:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-13 03:24:28,163:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:28,193:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:28,195:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:28,241:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:28,271:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:28,272:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:28,273:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-13 03:24:28,349:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:28,351:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:28,433:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:28,436:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:28,454:INFO:Preparing preprocessing pipeline...
2024-12-13 03:24:28,462:INFO:Set up simple imputation.
2024-12-13 03:24:28,471:INFO:Set up column name cleaning.
2024-12-13 03:24:28,519:INFO:Finished creating preprocessing pipeline.
2024-12-13 03:24:28,526:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-13 03:24:28,526:INFO:Creating final display dataframe.
2024-12-13 03:24:28,657:INFO:Setup _display_container:                     Description             Value
0                    Session id              1075
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              d9f0
2024-12-13 03:24:28,741:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:28,743:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:28,819:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:28,820:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:28,821:INFO:setup() successfully completed in 1.43s...............
2024-12-13 03:24:38,621:INFO:PyCaret RegressionExperiment
2024-12-13 03:24:38,621:INFO:Logging name: reg-default-name
2024-12-13 03:24:38,622:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-13 03:24:38,622:INFO:version 3.0.0
2024-12-13 03:24:38,622:INFO:Initializing setup()
2024-12-13 03:24:38,622:INFO:self.USI: 772b
2024-12-13 03:24:38,622:INFO:self._variable_keys: {'exp_id', 'html_param', 'logging_param', 'pipeline', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'X_train', 'transform_target_param', 'exp_name_log', 'log_plots_param', 'fold_shuffle_param', 'y', 'fold_groups_param', 'memory', 'target_param', 'X', '_available_plots', 'idx', 'y_train', 'gpu_param', 'USI', 'y_test', '_ml_usecase', 'data', 'seed', 'X_test'}
2024-12-13 03:24:38,622:INFO:Checking environment
2024-12-13 03:24:38,622:INFO:python_version: 3.9.20
2024-12-13 03:24:38,622:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-13 03:24:38,622:INFO:machine: arm64
2024-12-13 03:24:38,622:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:24:38,622:INFO:Memory: svmem(total=8589934592, available=1775321088, percent=79.3, used=3043442688, free=57917440, active=1731543040, inactive=1707393024, wired=1311899648)
2024-12-13 03:24:38,622:INFO:Physical Core: 8
2024-12-13 03:24:38,622:INFO:Logical Core: 8
2024-12-13 03:24:38,622:INFO:Checking libraries
2024-12-13 03:24:38,622:INFO:System:
2024-12-13 03:24:38,622:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-13 03:24:38,622:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-13 03:24:38,622:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:24:38,622:INFO:PyCaret required dependencies:
2024-12-13 03:24:38,622:INFO:                 pip: 24.3.1
2024-12-13 03:24:38,622:INFO:          setuptools: 75.1.0
2024-12-13 03:24:38,622:INFO:             pycaret: 3.0.0
2024-12-13 03:24:38,622:INFO:             IPython: 8.12.3
2024-12-13 03:24:38,622:INFO:          ipywidgets: 8.1.5
2024-12-13 03:24:38,622:INFO:                tqdm: 4.66.5
2024-12-13 03:24:38,622:INFO:               numpy: 1.24.4
2024-12-13 03:24:38,622:INFO:              pandas: 1.5.3
2024-12-13 03:24:38,622:INFO:              jinja2: 3.1.4
2024-12-13 03:24:38,622:INFO:               scipy: 1.11.4
2024-12-13 03:24:38,622:INFO:              joblib: 1.3.2
2024-12-13 03:24:38,622:INFO:             sklearn: 1.0.2
2024-12-13 03:24:38,622:INFO:                pyod: 2.0.2
2024-12-13 03:24:38,622:INFO:            imblearn: 0.12.4
2024-12-13 03:24:38,622:INFO:   category_encoders: 2.6.4
2024-12-13 03:24:38,622:INFO:            lightgbm: 4.5.0
2024-12-13 03:24:38,622:INFO:               numba: 0.60.0
2024-12-13 03:24:38,623:INFO:            requests: 2.32.3
2024-12-13 03:24:38,623:INFO:          matplotlib: 3.7.5
2024-12-13 03:24:38,623:INFO:          scikitplot: 0.3.7
2024-12-13 03:24:38,623:INFO:         yellowbrick: 1.5
2024-12-13 03:24:38,623:INFO:              plotly: 5.24.1
2024-12-13 03:24:38,623:INFO:             kaleido: 0.2.1
2024-12-13 03:24:38,623:INFO:         statsmodels: 0.14.3
2024-12-13 03:24:38,623:INFO:              sktime: 0.26.0
2024-12-13 03:24:38,623:INFO:               tbats: 1.1.3
2024-12-13 03:24:38,623:INFO:            pmdarima: 2.0.4
2024-12-13 03:24:38,623:INFO:              psutil: 6.0.0
2024-12-13 03:24:38,623:INFO:PyCaret optional dependencies:
2024-12-13 03:24:38,623:INFO:                shap: Not installed
2024-12-13 03:24:38,623:INFO:           interpret: Not installed
2024-12-13 03:24:38,623:INFO:                umap: Not installed
2024-12-13 03:24:38,623:INFO:    pandas_profiling: Not installed
2024-12-13 03:24:38,623:INFO:  explainerdashboard: Not installed
2024-12-13 03:24:38,623:INFO:             autoviz: Not installed
2024-12-13 03:24:38,623:INFO:           fairlearn: Not installed
2024-12-13 03:24:38,623:INFO:             xgboost: 2.1.2
2024-12-13 03:24:38,623:INFO:            catboost: 1.2.7
2024-12-13 03:24:38,623:INFO:              kmodes: Not installed
2024-12-13 03:24:38,623:INFO:             mlxtend: Not installed
2024-12-13 03:24:38,623:INFO:       statsforecast: Not installed
2024-12-13 03:24:38,623:INFO:        tune_sklearn: Not installed
2024-12-13 03:24:38,624:INFO:                 ray: Not installed
2024-12-13 03:24:38,624:INFO:            hyperopt: Not installed
2024-12-13 03:24:38,624:INFO:              optuna: 4.1.0
2024-12-13 03:24:38,624:INFO:               skopt: Not installed
2024-12-13 03:24:38,624:INFO:              mlflow: Not installed
2024-12-13 03:24:38,624:INFO:              gradio: Not installed
2024-12-13 03:24:38,624:INFO:             fastapi: 0.115.2
2024-12-13 03:24:38,624:INFO:             uvicorn: 0.32.0
2024-12-13 03:24:38,624:INFO:              m2cgen: Not installed
2024-12-13 03:24:38,624:INFO:           evidently: Not installed
2024-12-13 03:24:38,624:INFO:               fugue: Not installed
2024-12-13 03:24:38,624:INFO:           streamlit: 1.39.0
2024-12-13 03:24:38,624:INFO:             prophet: Not installed
2024-12-13 03:24:38,624:INFO:None
2024-12-13 03:24:38,624:INFO:Set up data.
2024-12-13 03:24:38,679:INFO:Set up train/test split.
2024-12-13 03:24:38,684:INFO:Set up index.
2024-12-13 03:24:38,684:INFO:Set up folding strategy.
2024-12-13 03:24:38,684:INFO:Assigning column types.
2024-12-13 03:24:38,688:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-13 03:24:38,688:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,691:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,694:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,732:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,761:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,761:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:38,763:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:38,763:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,766:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,769:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,807:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,836:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,836:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:38,837:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:38,838:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-13 03:24:38,841:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,844:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,882:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,911:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:38,913:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:38,916:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,919:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,958:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,986:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:38,986:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:38,988:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:38,988:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-13 03:24:38,994:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:39,032:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:39,061:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:39,061:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:39,063:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:39,069:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:39,106:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:39,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:39,135:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:39,136:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:39,138:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-13 03:24:39,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:39,209:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:39,210:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:39,211:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:39,255:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:39,284:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:39,284:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:39,286:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:39,286:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-13 03:24:39,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:39,359:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:39,360:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:39,404:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:39,433:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:39,434:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:39,435:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-13 03:24:39,506:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:39,508:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:39,581:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:39,583:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:39,584:INFO:Preparing preprocessing pipeline...
2024-12-13 03:24:39,584:INFO:Set up simple imputation.
2024-12-13 03:24:39,585:INFO:Set up column name cleaning.
2024-12-13 03:24:39,615:INFO:Finished creating preprocessing pipeline.
2024-12-13 03:24:39,621:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-13 03:24:39,621:INFO:Creating final display dataframe.
2024-12-13 03:24:39,778:INFO:Setup _display_container:                     Description             Value
0                    Session id              2418
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              772b
2024-12-13 03:24:39,859:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:39,860:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:39,936:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:39,938:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:39,939:INFO:setup() successfully completed in 1.32s...............
2024-12-13 03:24:44,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:24:44,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:24:44,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:24:44,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:24:44,422:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-13 03:24:47,066:INFO:PyCaret RegressionExperiment
2024-12-13 03:24:47,066:INFO:Logging name: reg-default-name
2024-12-13 03:24:47,066:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-13 03:24:47,066:INFO:version 3.0.0
2024-12-13 03:24:47,066:INFO:Initializing setup()
2024-12-13 03:24:47,066:INFO:self.USI: fdad
2024-12-13 03:24:47,066:INFO:self._variable_keys: {'exp_id', 'X_test', 'idx', '_available_plots', 'log_plots_param', 'fold_groups_param', 'pipeline', 'target_param', 'y_train', 'fold_generator', 'n_jobs_param', 'fold_shuffle_param', 'X_train', 'logging_param', 'gpu_param', 'y', 'X', 'memory', 'USI', 'gpu_n_jobs_param', 'data', 'transform_target_param', 'y_test', 'seed', '_ml_usecase', 'exp_name_log', 'html_param'}
2024-12-13 03:24:47,066:INFO:Checking environment
2024-12-13 03:24:47,066:INFO:python_version: 3.9.20
2024-12-13 03:24:47,066:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-13 03:24:47,066:INFO:machine: arm64
2024-12-13 03:24:47,066:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:24:47,066:INFO:Memory: svmem(total=8589934592, available=1816346624, percent=78.9, used=2994339840, free=66371584, active=1760919552, inactive=1629110272, wired=1233420288)
2024-12-13 03:24:47,066:INFO:Physical Core: 8
2024-12-13 03:24:47,066:INFO:Logical Core: 8
2024-12-13 03:24:47,066:INFO:Checking libraries
2024-12-13 03:24:47,066:INFO:System:
2024-12-13 03:24:47,066:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-13 03:24:47,066:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-13 03:24:47,066:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:24:47,066:INFO:PyCaret required dependencies:
2024-12-13 03:24:47,067:INFO:                 pip: 24.3.1
2024-12-13 03:24:47,067:INFO:          setuptools: 75.1.0
2024-12-13 03:24:47,067:INFO:             pycaret: 3.0.0
2024-12-13 03:24:47,067:INFO:             IPython: 8.12.3
2024-12-13 03:24:47,067:INFO:          ipywidgets: 8.1.5
2024-12-13 03:24:47,067:INFO:                tqdm: 4.66.5
2024-12-13 03:24:47,067:INFO:               numpy: 1.24.4
2024-12-13 03:24:47,067:INFO:              pandas: 1.5.3
2024-12-13 03:24:47,067:INFO:              jinja2: 3.1.4
2024-12-13 03:24:47,067:INFO:               scipy: 1.11.4
2024-12-13 03:24:47,067:INFO:              joblib: 1.3.2
2024-12-13 03:24:47,067:INFO:             sklearn: 1.0.2
2024-12-13 03:24:47,067:INFO:                pyod: 2.0.2
2024-12-13 03:24:47,067:INFO:            imblearn: 0.12.4
2024-12-13 03:24:47,067:INFO:   category_encoders: 2.6.4
2024-12-13 03:24:47,067:INFO:            lightgbm: 4.5.0
2024-12-13 03:24:47,067:INFO:               numba: 0.60.0
2024-12-13 03:24:47,067:INFO:            requests: 2.32.3
2024-12-13 03:24:47,067:INFO:          matplotlib: 3.7.5
2024-12-13 03:24:47,067:INFO:          scikitplot: 0.3.7
2024-12-13 03:24:47,067:INFO:         yellowbrick: 1.5
2024-12-13 03:24:47,067:INFO:              plotly: 5.24.1
2024-12-13 03:24:47,067:INFO:             kaleido: 0.2.1
2024-12-13 03:24:47,067:INFO:         statsmodels: 0.14.3
2024-12-13 03:24:47,067:INFO:              sktime: 0.26.0
2024-12-13 03:24:47,067:INFO:               tbats: 1.1.3
2024-12-13 03:24:47,067:INFO:            pmdarima: 2.0.4
2024-12-13 03:24:47,067:INFO:              psutil: 6.0.0
2024-12-13 03:24:47,067:INFO:PyCaret optional dependencies:
2024-12-13 03:24:47,480:INFO:                shap: Not installed
2024-12-13 03:24:47,480:INFO:           interpret: Not installed
2024-12-13 03:24:47,480:INFO:                umap: Not installed
2024-12-13 03:24:47,480:INFO:    pandas_profiling: Not installed
2024-12-13 03:24:47,480:INFO:  explainerdashboard: Not installed
2024-12-13 03:24:47,480:INFO:             autoviz: Not installed
2024-12-13 03:24:47,480:INFO:           fairlearn: Not installed
2024-12-13 03:24:47,480:INFO:             xgboost: 2.1.2
2024-12-13 03:24:47,480:INFO:            catboost: 1.2.7
2024-12-13 03:24:47,480:INFO:              kmodes: Not installed
2024-12-13 03:24:47,480:INFO:             mlxtend: Not installed
2024-12-13 03:24:47,480:INFO:       statsforecast: Not installed
2024-12-13 03:24:47,480:INFO:        tune_sklearn: Not installed
2024-12-13 03:24:47,480:INFO:                 ray: Not installed
2024-12-13 03:24:47,480:INFO:            hyperopt: Not installed
2024-12-13 03:24:47,480:INFO:              optuna: 4.1.0
2024-12-13 03:24:47,480:INFO:               skopt: Not installed
2024-12-13 03:24:47,480:INFO:              mlflow: Not installed
2024-12-13 03:24:47,480:INFO:              gradio: Not installed
2024-12-13 03:24:47,480:INFO:             fastapi: 0.115.2
2024-12-13 03:24:47,480:INFO:             uvicorn: 0.32.0
2024-12-13 03:24:47,480:INFO:              m2cgen: Not installed
2024-12-13 03:24:47,480:INFO:           evidently: Not installed
2024-12-13 03:24:47,480:INFO:               fugue: Not installed
2024-12-13 03:24:47,480:INFO:           streamlit: 1.39.0
2024-12-13 03:24:47,481:INFO:             prophet: Not installed
2024-12-13 03:24:47,481:INFO:None
2024-12-13 03:24:47,481:INFO:Set up data.
2024-12-13 03:24:47,530:INFO:Set up train/test split.
2024-12-13 03:24:47,537:INFO:Set up index.
2024-12-13 03:24:47,537:INFO:Set up folding strategy.
2024-12-13 03:24:47,537:INFO:Assigning column types.
2024-12-13 03:24:47,541:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-13 03:24:47,541:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,544:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,547:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,617:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:47,619:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:47,619:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,622:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,625:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,663:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,692:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,693:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:47,694:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:47,695:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-13 03:24:47,698:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,701:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,739:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,768:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:47,770:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:47,773:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,776:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,844:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,845:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:47,846:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:47,847:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-13 03:24:47,853:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,920:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:47,921:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:47,927:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,966:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,995:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:47,995:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:47,997:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:47,997:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-13 03:24:48,042:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:48,071:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:48,071:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:48,072:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:48,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:48,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:24:48,147:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:48,149:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:48,149:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-13 03:24:48,224:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:48,253:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:48,255:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:48,299:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:24:48,331:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:48,333:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:48,333:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-13 03:24:48,407:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:48,409:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:48,483:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:48,484:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:48,486:INFO:Preparing preprocessing pipeline...
2024-12-13 03:24:48,486:INFO:Set up simple imputation.
2024-12-13 03:24:48,487:INFO:Set up column name cleaning.
2024-12-13 03:24:48,517:INFO:Finished creating preprocessing pipeline.
2024-12-13 03:24:48,523:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-13 03:24:48,523:INFO:Creating final display dataframe.
2024-12-13 03:24:48,658:INFO:Setup _display_container:                     Description             Value
0                    Session id              7759
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              fdad
2024-12-13 03:24:48,750:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:48,752:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:48,839:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:24:48,841:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:24:48,842:INFO:setup() successfully completed in 1.78s...............
2024-12-13 03:25:24,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:25:24,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:25:24,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:25:24,611:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:25:25,009:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-13 03:25:55,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:25:55,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:25:55,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:25:55,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-13 03:25:56,031:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-13 03:26:05,501:INFO:PyCaret RegressionExperiment
2024-12-13 03:26:05,501:INFO:Logging name: reg-default-name
2024-12-13 03:26:05,501:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-13 03:26:05,502:INFO:version 3.0.0
2024-12-13 03:26:05,502:INFO:Initializing setup()
2024-12-13 03:26:05,502:INFO:self.USI: 76ba
2024-12-13 03:26:05,502:INFO:self._variable_keys: {'fold_shuffle_param', 'exp_name_log', 'gpu_n_jobs_param', 'seed', '_available_plots', 'transform_target_param', 'memory', 'USI', 'y', 'y_test', '_ml_usecase', 'data', 'exp_id', 'pipeline', 'X_test', 'n_jobs_param', 'html_param', 'target_param', 'fold_generator', 'X', 'X_train', 'gpu_param', 'fold_groups_param', 'idx', 'y_train', 'log_plots_param', 'logging_param'}
2024-12-13 03:26:05,502:INFO:Checking environment
2024-12-13 03:26:05,502:INFO:python_version: 3.9.20
2024-12-13 03:26:05,502:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-13 03:26:05,502:INFO:machine: arm64
2024-12-13 03:26:05,502:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:26:05,503:INFO:Memory: svmem(total=8589934592, available=1572896768, percent=81.7, used=2876489728, free=50413568, active=1539309568, inactive=1516503040, wired=1337180160)
2024-12-13 03:26:05,503:INFO:Physical Core: 8
2024-12-13 03:26:05,503:INFO:Logical Core: 8
2024-12-13 03:26:05,503:INFO:Checking libraries
2024-12-13 03:26:05,503:INFO:System:
2024-12-13 03:26:05,503:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-13 03:26:05,503:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-13 03:26:05,503:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-13 03:26:05,503:INFO:PyCaret required dependencies:
2024-12-13 03:26:05,503:INFO:                 pip: 24.3.1
2024-12-13 03:26:05,503:INFO:          setuptools: 75.1.0
2024-12-13 03:26:05,503:INFO:             pycaret: 3.0.0
2024-12-13 03:26:05,503:INFO:             IPython: 8.12.3
2024-12-13 03:26:05,503:INFO:          ipywidgets: 8.1.5
2024-12-13 03:26:05,503:INFO:                tqdm: 4.66.5
2024-12-13 03:26:05,503:INFO:               numpy: 1.24.4
2024-12-13 03:26:05,503:INFO:              pandas: 1.5.3
2024-12-13 03:26:05,503:INFO:              jinja2: 3.1.4
2024-12-13 03:26:05,503:INFO:               scipy: 1.11.4
2024-12-13 03:26:05,503:INFO:              joblib: 1.3.2
2024-12-13 03:26:05,503:INFO:             sklearn: 1.0.2
2024-12-13 03:26:05,503:INFO:                pyod: 2.0.2
2024-12-13 03:26:05,504:INFO:            imblearn: 0.12.4
2024-12-13 03:26:05,504:INFO:   category_encoders: 2.6.4
2024-12-13 03:26:05,504:INFO:            lightgbm: 4.5.0
2024-12-13 03:26:05,504:INFO:               numba: 0.60.0
2024-12-13 03:26:05,504:INFO:            requests: 2.32.3
2024-12-13 03:26:05,504:INFO:          matplotlib: 3.7.5
2024-12-13 03:26:05,504:INFO:          scikitplot: 0.3.7
2024-12-13 03:26:05,504:INFO:         yellowbrick: 1.5
2024-12-13 03:26:05,504:INFO:              plotly: 5.24.1
2024-12-13 03:26:05,504:INFO:             kaleido: 0.2.1
2024-12-13 03:26:05,504:INFO:         statsmodels: 0.14.3
2024-12-13 03:26:05,504:INFO:              sktime: 0.26.0
2024-12-13 03:26:05,504:INFO:               tbats: 1.1.3
2024-12-13 03:26:05,504:INFO:            pmdarima: 2.0.4
2024-12-13 03:26:05,504:INFO:              psutil: 6.0.0
2024-12-13 03:26:05,504:INFO:PyCaret optional dependencies:
2024-12-13 03:26:05,966:INFO:                shap: Not installed
2024-12-13 03:26:05,966:INFO:           interpret: Not installed
2024-12-13 03:26:05,966:INFO:                umap: Not installed
2024-12-13 03:26:05,966:INFO:    pandas_profiling: Not installed
2024-12-13 03:26:05,966:INFO:  explainerdashboard: Not installed
2024-12-13 03:26:05,966:INFO:             autoviz: Not installed
2024-12-13 03:26:05,966:INFO:           fairlearn: Not installed
2024-12-13 03:26:05,966:INFO:             xgboost: 2.1.2
2024-12-13 03:26:05,966:INFO:            catboost: 1.2.7
2024-12-13 03:26:05,966:INFO:              kmodes: Not installed
2024-12-13 03:26:05,966:INFO:             mlxtend: Not installed
2024-12-13 03:26:05,966:INFO:       statsforecast: Not installed
2024-12-13 03:26:05,966:INFO:        tune_sklearn: Not installed
2024-12-13 03:26:05,966:INFO:                 ray: Not installed
2024-12-13 03:26:05,966:INFO:            hyperopt: Not installed
2024-12-13 03:26:05,966:INFO:              optuna: 4.1.0
2024-12-13 03:26:05,966:INFO:               skopt: Not installed
2024-12-13 03:26:05,966:INFO:              mlflow: Not installed
2024-12-13 03:26:05,966:INFO:              gradio: Not installed
2024-12-13 03:26:05,966:INFO:             fastapi: 0.115.2
2024-12-13 03:26:05,966:INFO:             uvicorn: 0.32.0
2024-12-13 03:26:05,966:INFO:              m2cgen: Not installed
2024-12-13 03:26:05,966:INFO:           evidently: Not installed
2024-12-13 03:26:05,966:INFO:               fugue: Not installed
2024-12-13 03:26:05,966:INFO:           streamlit: 1.39.0
2024-12-13 03:26:05,966:INFO:             prophet: Not installed
2024-12-13 03:26:05,966:INFO:None
2024-12-13 03:26:05,966:INFO:Set up data.
2024-12-13 03:26:06,015:INFO:Set up train/test split.
2024-12-13 03:26:06,022:INFO:Set up index.
2024-12-13 03:26:06,022:INFO:Set up folding strategy.
2024-12-13 03:26:06,022:INFO:Assigning column types.
2024-12-13 03:26:06,025:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-13 03:26:06,025:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,028:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,031:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,100:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,100:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:06,102:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:06,102:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,105:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,108:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,177:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:06,178:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:06,179:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-13 03:26:06,182:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,185:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,253:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,253:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:06,255:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:06,258:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,261:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,299:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,329:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:06,331:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:06,331:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-13 03:26:06,337:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,375:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,404:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,405:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:06,406:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:06,412:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,452:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,481:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,481:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:06,483:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:06,483:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-13 03:26:06,528:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,558:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,558:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:06,560:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:06,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,657:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,657:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:06,659:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:06,660:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-13 03:26:06,704:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,734:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:06,735:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:06,780:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-13 03:26:06,809:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:06,811:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:06,811:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-13 03:26:06,886:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:06,888:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:06,963:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:06,964:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:06,970:INFO:Preparing preprocessing pipeline...
2024-12-13 03:26:06,970:INFO:Set up simple imputation.
2024-12-13 03:26:06,971:INFO:Set up column name cleaning.
2024-12-13 03:26:07,000:INFO:Finished creating preprocessing pipeline.
2024-12-13 03:26:07,006:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-13 03:26:07,006:INFO:Creating final display dataframe.
2024-12-13 03:26:07,129:INFO:Setup _display_container:                     Description             Value
0                    Session id              5444
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 318)
4        Transformed data shape       (1460, 318)
5   Transformed train set shape       (1021, 318)
6    Transformed test set shape        (439, 318)
7              Numeric features               317
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              76ba
2024-12-13 03:26:07,213:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:07,215:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:07,292:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-13 03:26:07,293:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-13 03:26:07,294:INFO:setup() successfully completed in 1.8s...............
2024-12-13 03:26:18,568:INFO:Initializing compare_models()
2024-12-13 03:26:18,569:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-12-13 03:26:18,569:INFO:Checking exceptions
2024-12-13 03:26:18,574:INFO:Preparing display monitor
2024-12-13 03:26:18,627:INFO:Initializing Linear Regression
2024-12-13 03:26:18,627:INFO:Total runtime is 7.502237955729166e-06 minutes
2024-12-13 03:26:18,630:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:18,630:INFO:Initializing create_model()
2024-12-13 03:26:18,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:18,630:INFO:Checking exceptions
2024-12-13 03:26:18,631:INFO:Importing libraries
2024-12-13 03:26:18,631:INFO:Copying training dataset
2024-12-13 03:26:18,642:INFO:Defining folds
2024-12-13 03:26:18,642:INFO:Declaring metric variables
2024-12-13 03:26:18,646:INFO:Importing untrained model
2024-12-13 03:26:18,649:INFO:Linear Regression Imported successfully
2024-12-13 03:26:18,656:INFO:Starting cross validation
2024-12-13 03:26:18,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:26,307:INFO:Calculating mean and std
2024-12-13 03:26:26,315:INFO:Creating metrics dataframe
2024-12-13 03:26:26,324:INFO:Uploading results into container
2024-12-13 03:26:26,325:INFO:Uploading model into container now
2024-12-13 03:26:26,326:INFO:_master_model_container: 1
2024-12-13 03:26:26,326:INFO:_display_container: 2
2024-12-13 03:26:26,327:INFO:LinearRegression(n_jobs=-1)
2024-12-13 03:26:26,327:INFO:create_model() successfully completed......................................
2024-12-13 03:26:26,467:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:26,467:INFO:Creating metrics dataframe
2024-12-13 03:26:26,473:INFO:Initializing Lasso Regression
2024-12-13 03:26:26,473:INFO:Total runtime is 0.13077788750330607 minutes
2024-12-13 03:26:26,476:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:26,476:INFO:Initializing create_model()
2024-12-13 03:26:26,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:26,476:INFO:Checking exceptions
2024-12-13 03:26:26,476:INFO:Importing libraries
2024-12-13 03:26:26,476:INFO:Copying training dataset
2024-12-13 03:26:26,483:INFO:Defining folds
2024-12-13 03:26:26,483:INFO:Declaring metric variables
2024-12-13 03:26:26,486:INFO:Importing untrained model
2024-12-13 03:26:26,490:INFO:Lasso Regression Imported successfully
2024-12-13 03:26:26,494:INFO:Starting cross validation
2024-12-13 03:26:26,497:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:26,892:INFO:Calculating mean and std
2024-12-13 03:26:26,893:INFO:Creating metrics dataframe
2024-12-13 03:26:26,897:INFO:Uploading results into container
2024-12-13 03:26:26,898:INFO:Uploading model into container now
2024-12-13 03:26:26,899:INFO:_master_model_container: 2
2024-12-13 03:26:26,899:INFO:_display_container: 2
2024-12-13 03:26:26,900:INFO:Lasso(random_state=5444)
2024-12-13 03:26:26,900:INFO:create_model() successfully completed......................................
2024-12-13 03:26:27,016:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:27,016:INFO:Creating metrics dataframe
2024-12-13 03:26:27,023:INFO:Initializing Ridge Regression
2024-12-13 03:26:27,023:INFO:Total runtime is 0.13994171619415283 minutes
2024-12-13 03:26:27,026:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:27,026:INFO:Initializing create_model()
2024-12-13 03:26:27,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:27,027:INFO:Checking exceptions
2024-12-13 03:26:27,027:INFO:Importing libraries
2024-12-13 03:26:27,027:INFO:Copying training dataset
2024-12-13 03:26:27,036:INFO:Defining folds
2024-12-13 03:26:27,037:INFO:Declaring metric variables
2024-12-13 03:26:27,050:INFO:Importing untrained model
2024-12-13 03:26:27,085:INFO:Ridge Regression Imported successfully
2024-12-13 03:26:27,091:INFO:Starting cross validation
2024-12-13 03:26:27,094:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:27,394:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: 
10 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/joblib/memory.py", line 655, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 1011, in fit
    return super().fit(X, y, sample_weight=sample_weight)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 782, in fit
    self.coef_, self.n_iter_ = _ridge_regression(
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 599, in _ridge_regression
    coef = _solve_cholesky(X, y, alpha)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 157, in _solve_cholesky
    return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T
TypeError: solve() got an unexpected keyword argument 'sym_pos'

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-12-13 03:26:27,395:INFO:Calculating mean and std
2024-12-13 03:26:27,396:INFO:Creating metrics dataframe
2024-12-13 03:26:27,400:INFO:Uploading results into container
2024-12-13 03:26:27,401:INFO:Uploading model into container now
2024-12-13 03:26:27,401:INFO:_master_model_container: 3
2024-12-13 03:26:27,401:INFO:_display_container: 2
2024-12-13 03:26:27,401:INFO:Ridge(random_state=5444)
2024-12-13 03:26:27,401:INFO:create_model() successfully completed......................................
2024-12-13 03:26:27,568:WARNING:create_model() for Ridge(random_state=5444) raised an exception or returned all 0.0, trying without fit_kwargs:
2024-12-13 03:26:27,570:WARNING:Traceback (most recent call last):
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2024-12-13 03:26:27,570:INFO:Initializing create_model()
2024-12-13 03:26:27,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:27,570:INFO:Checking exceptions
2024-12-13 03:26:27,571:INFO:Importing libraries
2024-12-13 03:26:27,571:INFO:Copying training dataset
2024-12-13 03:26:27,582:INFO:Defining folds
2024-12-13 03:26:27,583:INFO:Declaring metric variables
2024-12-13 03:26:27,588:INFO:Importing untrained model
2024-12-13 03:26:27,610:INFO:Ridge Regression Imported successfully
2024-12-13 03:26:27,616:INFO:Starting cross validation
2024-12-13 03:26:27,621:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:27,951:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: 
10 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/joblib/memory.py", line 655, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 1011, in fit
    return super().fit(X, y, sample_weight=sample_weight)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 782, in fit
    self.coef_, self.n_iter_ = _ridge_regression(
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 599, in _ridge_regression
    coef = _solve_cholesky(X, y, alpha)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 157, in _solve_cholesky
    return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T
TypeError: solve() got an unexpected keyword argument 'sym_pos'

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-12-13 03:26:27,966:INFO:Calculating mean and std
2024-12-13 03:26:27,971:INFO:Creating metrics dataframe
2024-12-13 03:26:27,999:INFO:Uploading results into container
2024-12-13 03:26:28,000:INFO:Uploading model into container now
2024-12-13 03:26:28,001:INFO:_master_model_container: 4
2024-12-13 03:26:28,001:INFO:_display_container: 2
2024-12-13 03:26:28,001:INFO:Ridge(random_state=5444)
2024-12-13 03:26:28,002:INFO:create_model() successfully completed......................................
2024-12-13 03:26:28,096:ERROR:create_model() for Ridge(random_state=5444) raised an exception or returned all 0.0:
2024-12-13 03:26:28,097:ERROR:Traceback (most recent call last):
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 812, in compare_models
    assert (
AssertionError

2024-12-13 03:26:28,097:INFO:Initializing Elastic Net
2024-12-13 03:26:28,097:INFO:Total runtime is 0.1578311324119568 minutes
2024-12-13 03:26:28,099:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:28,099:INFO:Initializing create_model()
2024-12-13 03:26:28,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:28,100:INFO:Checking exceptions
2024-12-13 03:26:28,100:INFO:Importing libraries
2024-12-13 03:26:28,100:INFO:Copying training dataset
2024-12-13 03:26:28,105:INFO:Defining folds
2024-12-13 03:26:28,106:INFO:Declaring metric variables
2024-12-13 03:26:28,108:INFO:Importing untrained model
2024-12-13 03:26:28,111:INFO:Elastic Net Imported successfully
2024-12-13 03:26:28,117:INFO:Starting cross validation
2024-12-13 03:26:28,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:28,456:INFO:Calculating mean and std
2024-12-13 03:26:28,457:INFO:Creating metrics dataframe
2024-12-13 03:26:28,461:INFO:Uploading results into container
2024-12-13 03:26:28,462:INFO:Uploading model into container now
2024-12-13 03:26:28,462:INFO:_master_model_container: 5
2024-12-13 03:26:28,462:INFO:_display_container: 2
2024-12-13 03:26:28,462:INFO:ElasticNet(random_state=5444)
2024-12-13 03:26:28,462:INFO:create_model() successfully completed......................................
2024-12-13 03:26:28,530:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:28,530:INFO:Creating metrics dataframe
2024-12-13 03:26:28,537:INFO:Initializing Least Angle Regression
2024-12-13 03:26:28,538:INFO:Total runtime is 0.16517934799194336 minutes
2024-12-13 03:26:28,540:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:28,540:INFO:Initializing create_model()
2024-12-13 03:26:28,540:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:28,541:INFO:Checking exceptions
2024-12-13 03:26:28,541:INFO:Importing libraries
2024-12-13 03:26:28,541:INFO:Copying training dataset
2024-12-13 03:26:28,548:INFO:Defining folds
2024-12-13 03:26:28,548:INFO:Declaring metric variables
2024-12-13 03:26:28,550:INFO:Importing untrained model
2024-12-13 03:26:28,552:INFO:Least Angle Regression Imported successfully
2024-12-13 03:26:28,558:INFO:Starting cross validation
2024-12-13 03:26:28,560:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:28,659:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:28,670:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.460e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,672:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=7.152e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,672:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:28,673:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:28,674:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=6.934e-04, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,681:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=8.162e-04, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,684:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:28,686:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.538e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,689:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=4.863e-03, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,695:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:28,700:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:28,704:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:28,704:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.793e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,705:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.040e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,706:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:28,706:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=8.244e-04, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,707:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=8.133e-04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,707:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=8.112e-04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,710:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=6.014e-04, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,716:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=5.324e-04, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,717:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.654e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,721:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=4.699e-04, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,733:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=3.129e-04, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,734:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=2.932e-04, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,734:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=2.589e-04, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,740:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=2.190e-04, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,749:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 156 iterations, i.e. alpha=1.376e-03, with an active set of 138 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,749:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.945e-04, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,753:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=7.383e-04, with an active set of 145 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,762:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 127 iterations, i.e. alpha=1.495e-04, with an active set of 121 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,772:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2024-12-13 03:26:28,772:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: divide by zero encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2024-12-13 03:26:28,772:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-13 03:26:28,798:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 308 iterations, i.e. alpha=3.600e-01, with an active set of 236 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,805:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 241 iterations, i.e. alpha=8.988e-04, with an active set of 205 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:28,808:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2024-12-13 03:26:28,820:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2024-12-13 03:26:28,820:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:739: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2024-12-13 03:26:28,821:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: divide by zero encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2024-12-13 03:26:28,821:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-13 03:26:28,885:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2024-12-13 03:26:28,886:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: divide by zero encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2024-12-13 03:26:28,886:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-13 03:26:28,917:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2024-12-13 03:26:28,918:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: divide by zero encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2024-12-13 03:26:28,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-13 03:26:28,926:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:776: RuntimeWarning: overflow encountered in multiply
  coef[active] = prev_coef[active] + gamma_ * least_squares

2024-12-13 03:26:28,927:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2024-12-13 03:26:28,927:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:739: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2024-12-13 03:26:28,927:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:776: RuntimeWarning: overflow encountered in cast
  coef[active] = prev_coef[active] + gamma_ * least_squares

2024-12-13 03:26:29,374:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-13 03:26:29,374:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-13 03:26:29,375:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2024-12-13 03:26:29,406:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-13 03:26:29,419:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-13 03:26:29,419:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2024-12-13 03:26:29,454:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-13 03:26:29,454:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-13 03:26:29,455:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2024-12-13 03:26:29,464:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:29,483:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.879e-04, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:29,501:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:29,506:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b

2024-12-13 03:26:29,510:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 264, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 191, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 96, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/utils/validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/utils/validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float32').

  warnings.warn(

2024-12-13 03:26:29,513:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=3.623e-03, with an active set of 158 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:29,527:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.992e-04, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:29,531:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=5.054e-04, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:29,570:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=1.363e-03, with an active set of 194 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-13 03:26:29,578:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2024-12-13 03:26:29,578:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2024-12-13 03:26:29,578:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:739: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2024-12-13 03:26:29,578:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: divide by zero encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2024-12-13 03:26:29,578:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-13 03:26:29,616:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2024-12-13 03:26:29,617:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2024-12-13 03:26:29,617:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:739: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2024-12-13 03:26:29,617:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: divide by zero encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2024-12-13 03:26:29,617:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-13 03:26:29,910:INFO:Calculating mean and std
2024-12-13 03:26:29,913:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/_methods.py:236: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2024-12-13 03:26:29,915:INFO:Creating metrics dataframe
2024-12-13 03:26:29,926:INFO:Uploading results into container
2024-12-13 03:26:29,927:INFO:Uploading model into container now
2024-12-13 03:26:29,929:INFO:_master_model_container: 6
2024-12-13 03:26:29,929:INFO:_display_container: 2
2024-12-13 03:26:29,930:INFO:Lars(random_state=5444)
2024-12-13 03:26:29,930:INFO:create_model() successfully completed......................................
2024-12-13 03:26:30,012:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:30,012:INFO:Creating metrics dataframe
2024-12-13 03:26:30,019:INFO:Initializing Lasso Least Angle Regression
2024-12-13 03:26:30,019:INFO:Total runtime is 0.18986796935399375 minutes
2024-12-13 03:26:30,021:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:30,022:INFO:Initializing create_model()
2024-12-13 03:26:30,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:30,022:INFO:Checking exceptions
2024-12-13 03:26:30,022:INFO:Importing libraries
2024-12-13 03:26:30,022:INFO:Copying training dataset
2024-12-13 03:26:30,027:INFO:Defining folds
2024-12-13 03:26:30,027:INFO:Declaring metric variables
2024-12-13 03:26:30,030:INFO:Importing untrained model
2024-12-13 03:26:30,032:INFO:Lasso Least Angle Regression Imported successfully
2024-12-13 03:26:30,036:INFO:Starting cross validation
2024-12-13 03:26:30,038:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:30,104:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-13 03:26:30,109:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-13 03:26:30,127:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-13 03:26:30,128:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-13 03:26:30,130:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-13 03:26:30,145:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-13 03:26:30,155:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-13 03:26:30,163:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-13 03:26:30,198:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-13 03:26:30,209:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-13 03:26:30,348:INFO:Calculating mean and std
2024-12-13 03:26:30,349:INFO:Creating metrics dataframe
2024-12-13 03:26:30,354:INFO:Uploading results into container
2024-12-13 03:26:30,355:INFO:Uploading model into container now
2024-12-13 03:26:30,355:INFO:_master_model_container: 7
2024-12-13 03:26:30,355:INFO:_display_container: 2
2024-12-13 03:26:30,355:INFO:LassoLars(random_state=5444)
2024-12-13 03:26:30,355:INFO:create_model() successfully completed......................................
2024-12-13 03:26:30,418:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:30,418:INFO:Creating metrics dataframe
2024-12-13 03:26:30,424:INFO:Initializing Orthogonal Matching Pursuit
2024-12-13 03:26:30,424:INFO:Total runtime is 0.19662788311640422 minutes
2024-12-13 03:26:30,426:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:30,427:INFO:Initializing create_model()
2024-12-13 03:26:30,427:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:30,427:INFO:Checking exceptions
2024-12-13 03:26:30,427:INFO:Importing libraries
2024-12-13 03:26:30,427:INFO:Copying training dataset
2024-12-13 03:26:30,432:INFO:Defining folds
2024-12-13 03:26:30,432:INFO:Declaring metric variables
2024-12-13 03:26:30,434:INFO:Importing untrained model
2024-12-13 03:26:30,436:INFO:Orthogonal Matching Pursuit Imported successfully
2024-12-13 03:26:30,441:INFO:Starting cross validation
2024-12-13 03:26:30,443:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:30,520:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:30,528:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:30,565:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:30,571:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:30,574:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:30,583:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:30,590:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:30,608:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:30,646:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:30,652:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-13 03:26:30,807:INFO:Calculating mean and std
2024-12-13 03:26:30,808:INFO:Creating metrics dataframe
2024-12-13 03:26:30,814:INFO:Uploading results into container
2024-12-13 03:26:30,814:INFO:Uploading model into container now
2024-12-13 03:26:30,815:INFO:_master_model_container: 8
2024-12-13 03:26:30,815:INFO:_display_container: 2
2024-12-13 03:26:30,815:INFO:OrthogonalMatchingPursuit()
2024-12-13 03:26:30,815:INFO:create_model() successfully completed......................................
2024-12-13 03:26:30,875:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:30,875:INFO:Creating metrics dataframe
2024-12-13 03:26:30,882:INFO:Initializing Bayesian Ridge
2024-12-13 03:26:30,882:INFO:Total runtime is 0.20425685246785483 minutes
2024-12-13 03:26:30,884:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:30,885:INFO:Initializing create_model()
2024-12-13 03:26:30,885:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:30,885:INFO:Checking exceptions
2024-12-13 03:26:30,885:INFO:Importing libraries
2024-12-13 03:26:30,885:INFO:Copying training dataset
2024-12-13 03:26:30,890:INFO:Defining folds
2024-12-13 03:26:30,890:INFO:Declaring metric variables
2024-12-13 03:26:30,892:INFO:Importing untrained model
2024-12-13 03:26:30,894:INFO:Bayesian Ridge Imported successfully
2024-12-13 03:26:30,898:INFO:Starting cross validation
2024-12-13 03:26:30,900:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:31,952:INFO:Calculating mean and std
2024-12-13 03:26:31,954:INFO:Creating metrics dataframe
2024-12-13 03:26:31,970:INFO:Uploading results into container
2024-12-13 03:26:31,971:INFO:Uploading model into container now
2024-12-13 03:26:31,972:INFO:_master_model_container: 9
2024-12-13 03:26:31,972:INFO:_display_container: 2
2024-12-13 03:26:31,972:INFO:BayesianRidge()
2024-12-13 03:26:31,972:INFO:create_model() successfully completed......................................
2024-12-13 03:26:32,084:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:32,085:INFO:Creating metrics dataframe
2024-12-13 03:26:32,100:INFO:Initializing Passive Aggressive Regressor
2024-12-13 03:26:32,101:INFO:Total runtime is 0.22456403573354086 minutes
2024-12-13 03:26:32,105:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:32,106:INFO:Initializing create_model()
2024-12-13 03:26:32,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:32,106:INFO:Checking exceptions
2024-12-13 03:26:32,106:INFO:Importing libraries
2024-12-13 03:26:32,107:INFO:Copying training dataset
2024-12-13 03:26:32,116:INFO:Defining folds
2024-12-13 03:26:32,116:INFO:Declaring metric variables
2024-12-13 03:26:32,122:INFO:Importing untrained model
2024-12-13 03:26:32,128:INFO:Passive Aggressive Regressor Imported successfully
2024-12-13 03:26:32,139:INFO:Starting cross validation
2024-12-13 03:26:32,142:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:33,804:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2024-12-13 03:26:33,879:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2024-12-13 03:26:34,419:INFO:Calculating mean and std
2024-12-13 03:26:34,426:INFO:Creating metrics dataframe
2024-12-13 03:26:34,474:INFO:Uploading results into container
2024-12-13 03:26:34,475:INFO:Uploading model into container now
2024-12-13 03:26:34,481:INFO:_master_model_container: 10
2024-12-13 03:26:34,482:INFO:_display_container: 2
2024-12-13 03:26:34,488:INFO:PassiveAggressiveRegressor(random_state=5444)
2024-12-13 03:26:34,488:INFO:create_model() successfully completed......................................
2024-12-13 03:26:34,634:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:34,634:INFO:Creating metrics dataframe
2024-12-13 03:26:34,641:INFO:Initializing Huber Regressor
2024-12-13 03:26:34,641:INFO:Total runtime is 0.2669104854265849 minutes
2024-12-13 03:26:34,644:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:34,644:INFO:Initializing create_model()
2024-12-13 03:26:34,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:34,644:INFO:Checking exceptions
2024-12-13 03:26:34,645:INFO:Importing libraries
2024-12-13 03:26:34,645:INFO:Copying training dataset
2024-12-13 03:26:34,650:INFO:Defining folds
2024-12-13 03:26:34,650:INFO:Declaring metric variables
2024-12-13 03:26:34,653:INFO:Importing untrained model
2024-12-13 03:26:34,656:INFO:Huber Regressor Imported successfully
2024-12-13 03:26:34,660:INFO:Starting cross validation
2024-12-13 03:26:34,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:35,579:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-13 03:26:35,627:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-13 03:26:35,730:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-13 03:26:35,830:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-13 03:26:35,859:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-13 03:26:35,889:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-13 03:26:35,955:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-13 03:26:35,997:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-13 03:26:36,305:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-13 03:26:36,329:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-13 03:26:36,525:INFO:Calculating mean and std
2024-12-13 03:26:36,529:INFO:Creating metrics dataframe
2024-12-13 03:26:36,565:INFO:Uploading results into container
2024-12-13 03:26:36,569:INFO:Uploading model into container now
2024-12-13 03:26:36,582:INFO:_master_model_container: 11
2024-12-13 03:26:36,583:INFO:_display_container: 2
2024-12-13 03:26:36,584:INFO:HuberRegressor()
2024-12-13 03:26:36,584:INFO:create_model() successfully completed......................................
2024-12-13 03:26:36,702:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:36,703:INFO:Creating metrics dataframe
2024-12-13 03:26:36,710:INFO:Initializing K Neighbors Regressor
2024-12-13 03:26:36,710:INFO:Total runtime is 0.30139210224151614 minutes
2024-12-13 03:26:36,713:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:36,713:INFO:Initializing create_model()
2024-12-13 03:26:36,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:36,713:INFO:Checking exceptions
2024-12-13 03:26:36,714:INFO:Importing libraries
2024-12-13 03:26:36,714:INFO:Copying training dataset
2024-12-13 03:26:36,718:INFO:Defining folds
2024-12-13 03:26:36,718:INFO:Declaring metric variables
2024-12-13 03:26:36,720:INFO:Importing untrained model
2024-12-13 03:26:36,723:INFO:K Neighbors Regressor Imported successfully
2024-12-13 03:26:36,727:INFO:Starting cross validation
2024-12-13 03:26:36,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:37,197:INFO:Calculating mean and std
2024-12-13 03:26:37,198:INFO:Creating metrics dataframe
2024-12-13 03:26:37,214:INFO:Uploading results into container
2024-12-13 03:26:37,215:INFO:Uploading model into container now
2024-12-13 03:26:37,215:INFO:_master_model_container: 12
2024-12-13 03:26:37,215:INFO:_display_container: 2
2024-12-13 03:26:37,216:INFO:KNeighborsRegressor(n_jobs=-1)
2024-12-13 03:26:37,216:INFO:create_model() successfully completed......................................
2024-12-13 03:26:37,306:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:37,306:INFO:Creating metrics dataframe
2024-12-13 03:26:37,315:INFO:Initializing Decision Tree Regressor
2024-12-13 03:26:37,315:INFO:Total runtime is 0.31146733760833745 minutes
2024-12-13 03:26:37,318:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:37,318:INFO:Initializing create_model()
2024-12-13 03:26:37,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:37,318:INFO:Checking exceptions
2024-12-13 03:26:37,319:INFO:Importing libraries
2024-12-13 03:26:37,319:INFO:Copying training dataset
2024-12-13 03:26:37,324:INFO:Defining folds
2024-12-13 03:26:37,324:INFO:Declaring metric variables
2024-12-13 03:26:37,327:INFO:Importing untrained model
2024-12-13 03:26:37,330:INFO:Decision Tree Regressor Imported successfully
2024-12-13 03:26:37,334:INFO:Starting cross validation
2024-12-13 03:26:37,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:38,046:INFO:Calculating mean and std
2024-12-13 03:26:38,047:INFO:Creating metrics dataframe
2024-12-13 03:26:38,058:INFO:Uploading results into container
2024-12-13 03:26:38,059:INFO:Uploading model into container now
2024-12-13 03:26:38,059:INFO:_master_model_container: 13
2024-12-13 03:26:38,059:INFO:_display_container: 2
2024-12-13 03:26:38,059:INFO:DecisionTreeRegressor(random_state=5444)
2024-12-13 03:26:38,060:INFO:create_model() successfully completed......................................
2024-12-13 03:26:38,124:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:38,124:INFO:Creating metrics dataframe
2024-12-13 03:26:38,132:INFO:Initializing Random Forest Regressor
2024-12-13 03:26:38,132:INFO:Total runtime is 0.32508123318354293 minutes
2024-12-13 03:26:38,134:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:38,134:INFO:Initializing create_model()
2024-12-13 03:26:38,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:38,134:INFO:Checking exceptions
2024-12-13 03:26:38,135:INFO:Importing libraries
2024-12-13 03:26:38,135:INFO:Copying training dataset
2024-12-13 03:26:38,139:INFO:Defining folds
2024-12-13 03:26:38,139:INFO:Declaring metric variables
2024-12-13 03:26:38,141:INFO:Importing untrained model
2024-12-13 03:26:38,143:INFO:Random Forest Regressor Imported successfully
2024-12-13 03:26:38,148:INFO:Starting cross validation
2024-12-13 03:26:38,150:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:43,515:INFO:Calculating mean and std
2024-12-13 03:26:43,523:INFO:Creating metrics dataframe
2024-12-13 03:26:43,543:INFO:Uploading results into container
2024-12-13 03:26:43,544:INFO:Uploading model into container now
2024-12-13 03:26:43,545:INFO:_master_model_container: 14
2024-12-13 03:26:43,545:INFO:_display_container: 2
2024-12-13 03:26:43,545:INFO:RandomForestRegressor(n_jobs=-1, random_state=5444)
2024-12-13 03:26:43,545:INFO:create_model() successfully completed......................................
2024-12-13 03:26:43,671:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:43,671:INFO:Creating metrics dataframe
2024-12-13 03:26:43,679:INFO:Initializing Extra Trees Regressor
2024-12-13 03:26:43,680:INFO:Total runtime is 0.4175448854764303 minutes
2024-12-13 03:26:43,682:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:43,682:INFO:Initializing create_model()
2024-12-13 03:26:43,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:43,683:INFO:Checking exceptions
2024-12-13 03:26:43,683:INFO:Importing libraries
2024-12-13 03:26:43,683:INFO:Copying training dataset
2024-12-13 03:26:43,692:INFO:Defining folds
2024-12-13 03:26:43,692:INFO:Declaring metric variables
2024-12-13 03:26:43,696:INFO:Importing untrained model
2024-12-13 03:26:43,698:INFO:Extra Trees Regressor Imported successfully
2024-12-13 03:26:43,703:INFO:Starting cross validation
2024-12-13 03:26:43,705:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:48,980:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2024-12-13 03:26:49,002:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2024-12-13 03:26:49,813:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2024-12-13 03:26:50,615:INFO:Calculating mean and std
2024-12-13 03:26:50,617:INFO:Creating metrics dataframe
2024-12-13 03:26:50,635:INFO:Uploading results into container
2024-12-13 03:26:50,636:INFO:Uploading model into container now
2024-12-13 03:26:50,636:INFO:_master_model_container: 15
2024-12-13 03:26:50,636:INFO:_display_container: 2
2024-12-13 03:26:50,637:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=5444)
2024-12-13 03:26:50,637:INFO:create_model() successfully completed......................................
2024-12-13 03:26:50,780:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:50,780:INFO:Creating metrics dataframe
2024-12-13 03:26:50,788:INFO:Initializing AdaBoost Regressor
2024-12-13 03:26:50,789:INFO:Total runtime is 0.5360283017158509 minutes
2024-12-13 03:26:50,791:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:50,791:INFO:Initializing create_model()
2024-12-13 03:26:50,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:50,791:INFO:Checking exceptions
2024-12-13 03:26:50,791:INFO:Importing libraries
2024-12-13 03:26:50,791:INFO:Copying training dataset
2024-12-13 03:26:50,797:INFO:Defining folds
2024-12-13 03:26:50,797:INFO:Declaring metric variables
2024-12-13 03:26:50,799:INFO:Importing untrained model
2024-12-13 03:26:50,801:INFO:AdaBoost Regressor Imported successfully
2024-12-13 03:26:50,806:INFO:Starting cross validation
2024-12-13 03:26:50,808:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:53,102:INFO:Calculating mean and std
2024-12-13 03:26:53,103:INFO:Creating metrics dataframe
2024-12-13 03:26:53,121:INFO:Uploading results into container
2024-12-13 03:26:53,122:INFO:Uploading model into container now
2024-12-13 03:26:53,122:INFO:_master_model_container: 16
2024-12-13 03:26:53,122:INFO:_display_container: 2
2024-12-13 03:26:53,122:INFO:AdaBoostRegressor(random_state=5444)
2024-12-13 03:26:53,122:INFO:create_model() successfully completed......................................
2024-12-13 03:26:53,194:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:53,194:INFO:Creating metrics dataframe
2024-12-13 03:26:53,204:INFO:Initializing Gradient Boosting Regressor
2024-12-13 03:26:53,204:INFO:Total runtime is 0.5762880166371664 minutes
2024-12-13 03:26:53,207:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:53,207:INFO:Initializing create_model()
2024-12-13 03:26:53,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:53,207:INFO:Checking exceptions
2024-12-13 03:26:53,207:INFO:Importing libraries
2024-12-13 03:26:53,208:INFO:Copying training dataset
2024-12-13 03:26:53,213:INFO:Defining folds
2024-12-13 03:26:53,214:INFO:Declaring metric variables
2024-12-13 03:26:53,217:INFO:Importing untrained model
2024-12-13 03:26:53,220:INFO:Gradient Boosting Regressor Imported successfully
2024-12-13 03:26:53,224:INFO:Starting cross validation
2024-12-13 03:26:53,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:56,125:INFO:Calculating mean and std
2024-12-13 03:26:56,127:INFO:Creating metrics dataframe
2024-12-13 03:26:56,143:INFO:Uploading results into container
2024-12-13 03:26:56,143:INFO:Uploading model into container now
2024-12-13 03:26:56,144:INFO:_master_model_container: 17
2024-12-13 03:26:56,144:INFO:_display_container: 2
2024-12-13 03:26:56,144:INFO:GradientBoostingRegressor(random_state=5444)
2024-12-13 03:26:56,144:INFO:create_model() successfully completed......................................
2024-12-13 03:26:56,204:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:56,204:INFO:Creating metrics dataframe
2024-12-13 03:26:56,212:INFO:Initializing Extreme Gradient Boosting
2024-12-13 03:26:56,212:INFO:Total runtime is 0.6264222343762716 minutes
2024-12-13 03:26:56,215:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:56,215:INFO:Initializing create_model()
2024-12-13 03:26:56,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:56,215:INFO:Checking exceptions
2024-12-13 03:26:56,215:INFO:Importing libraries
2024-12-13 03:26:56,215:INFO:Copying training dataset
2024-12-13 03:26:56,219:INFO:Defining folds
2024-12-13 03:26:56,219:INFO:Declaring metric variables
2024-12-13 03:26:56,221:INFO:Importing untrained model
2024-12-13 03:26:56,223:INFO:Extreme Gradient Boosting Imported successfully
2024-12-13 03:26:56,228:INFO:Starting cross validation
2024-12-13 03:26:56,230:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:26:59,646:INFO:Calculating mean and std
2024-12-13 03:26:59,649:INFO:Creating metrics dataframe
2024-12-13 03:26:59,675:INFO:Uploading results into container
2024-12-13 03:26:59,676:INFO:Uploading model into container now
2024-12-13 03:26:59,676:INFO:_master_model_container: 18
2024-12-13 03:26:59,676:INFO:_display_container: 2
2024-12-13 03:26:59,678:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=5444, ...)
2024-12-13 03:26:59,678:INFO:create_model() successfully completed......................................
2024-12-13 03:26:59,821:INFO:SubProcess create_model() end ==================================
2024-12-13 03:26:59,821:INFO:Creating metrics dataframe
2024-12-13 03:26:59,830:INFO:Initializing Light Gradient Boosting Machine
2024-12-13 03:26:59,830:INFO:Total runtime is 0.686725668112437 minutes
2024-12-13 03:26:59,832:INFO:SubProcess create_model() called ==================================
2024-12-13 03:26:59,833:INFO:Initializing create_model()
2024-12-13 03:26:59,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:26:59,833:INFO:Checking exceptions
2024-12-13 03:26:59,833:INFO:Importing libraries
2024-12-13 03:26:59,833:INFO:Copying training dataset
2024-12-13 03:26:59,844:INFO:Defining folds
2024-12-13 03:26:59,845:INFO:Declaring metric variables
2024-12-13 03:26:59,848:INFO:Importing untrained model
2024-12-13 03:26:59,850:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-13 03:26:59,854:INFO:Starting cross validation
2024-12-13 03:26:59,857:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:27:04,929:INFO:Calculating mean and std
2024-12-13 03:27:04,937:INFO:Creating metrics dataframe
2024-12-13 03:27:04,968:INFO:Uploading results into container
2024-12-13 03:27:04,969:INFO:Uploading model into container now
2024-12-13 03:27:04,970:INFO:_master_model_container: 19
2024-12-13 03:27:04,970:INFO:_display_container: 2
2024-12-13 03:27:04,970:INFO:LGBMRegressor(n_jobs=-1, random_state=5444)
2024-12-13 03:27:04,970:INFO:create_model() successfully completed......................................
2024-12-13 03:27:05,081:INFO:SubProcess create_model() end ==================================
2024-12-13 03:27:05,081:INFO:Creating metrics dataframe
2024-12-13 03:27:05,090:INFO:Initializing CatBoost Regressor
2024-12-13 03:27:05,090:INFO:Total runtime is 0.7743844350179037 minutes
2024-12-13 03:27:05,092:INFO:SubProcess create_model() called ==================================
2024-12-13 03:27:05,092:INFO:Initializing create_model()
2024-12-13 03:27:05,092:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:27:05,093:INFO:Checking exceptions
2024-12-13 03:27:05,093:INFO:Importing libraries
2024-12-13 03:27:05,093:INFO:Copying training dataset
2024-12-13 03:27:05,098:INFO:Defining folds
2024-12-13 03:27:05,098:INFO:Declaring metric variables
2024-12-13 03:27:05,101:INFO:Importing untrained model
2024-12-13 03:27:05,106:INFO:CatBoost Regressor Imported successfully
2024-12-13 03:27:05,110:INFO:Starting cross validation
2024-12-13 03:27:05,112:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:27:27,010:INFO:Calculating mean and std
2024-12-13 03:27:27,014:INFO:Creating metrics dataframe
2024-12-13 03:27:27,046:INFO:Uploading results into container
2024-12-13 03:27:27,047:INFO:Uploading model into container now
2024-12-13 03:27:27,047:INFO:_master_model_container: 20
2024-12-13 03:27:27,047:INFO:_display_container: 2
2024-12-13 03:27:27,047:INFO:<catboost.core.CatBoostRegressor object at 0x30c111310>
2024-12-13 03:27:27,047:INFO:create_model() successfully completed......................................
2024-12-13 03:27:27,181:INFO:SubProcess create_model() end ==================================
2024-12-13 03:27:27,181:INFO:Creating metrics dataframe
2024-12-13 03:27:27,192:INFO:Initializing Dummy Regressor
2024-12-13 03:27:27,192:INFO:Total runtime is 1.1427613178888958 minutes
2024-12-13 03:27:27,196:INFO:SubProcess create_model() called ==================================
2024-12-13 03:27:27,196:INFO:Initializing create_model()
2024-12-13 03:27:27,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3068f5a60>, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:27:27,196:INFO:Checking exceptions
2024-12-13 03:27:27,196:INFO:Importing libraries
2024-12-13 03:27:27,196:INFO:Copying training dataset
2024-12-13 03:27:27,203:INFO:Defining folds
2024-12-13 03:27:27,203:INFO:Declaring metric variables
2024-12-13 03:27:27,205:INFO:Importing untrained model
2024-12-13 03:27:27,208:INFO:Dummy Regressor Imported successfully
2024-12-13 03:27:27,215:INFO:Starting cross validation
2024-12-13 03:27:27,219:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-13 03:27:27,707:INFO:Calculating mean and std
2024-12-13 03:27:27,713:INFO:Creating metrics dataframe
2024-12-13 03:27:27,740:INFO:Uploading results into container
2024-12-13 03:27:27,741:INFO:Uploading model into container now
2024-12-13 03:27:27,741:INFO:_master_model_container: 21
2024-12-13 03:27:27,741:INFO:_display_container: 2
2024-12-13 03:27:27,741:INFO:DummyRegressor()
2024-12-13 03:27:27,741:INFO:create_model() successfully completed......................................
2024-12-13 03:27:27,808:INFO:SubProcess create_model() end ==================================
2024-12-13 03:27:27,808:INFO:Creating metrics dataframe
2024-12-13 03:27:27,823:INFO:Initializing create_model()
2024-12-13 03:27:27,823:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x306bc6640>, estimator=<catboost.core.CatBoostRegressor object at 0x30c111310>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-12-13 03:27:27,823:INFO:Checking exceptions
2024-12-13 03:27:27,824:INFO:Importing libraries
2024-12-13 03:27:27,824:INFO:Copying training dataset
2024-12-13 03:27:27,829:INFO:Defining folds
2024-12-13 03:27:27,829:INFO:Declaring metric variables
2024-12-13 03:27:27,829:INFO:Importing untrained model
2024-12-13 03:27:27,829:INFO:Declaring custom model
2024-12-13 03:27:27,829:INFO:CatBoost Regressor Imported successfully
2024-12-13 03:27:27,831:INFO:Cross validation set to False
2024-12-13 03:27:27,831:INFO:Fitting Model
2024-12-13 03:27:30,764:INFO:<catboost.core.CatBoostRegressor object at 0x3101f3ac0>
2024-12-13 03:27:30,764:INFO:create_model() successfully completed......................................
2024-12-13 03:27:30,845:INFO:_master_model_container: 21
2024-12-13 03:27:30,846:INFO:_display_container: 2
2024-12-13 03:27:30,846:INFO:<catboost.core.CatBoostRegressor object at 0x3101f3ac0>
2024-12-13 03:27:30,846:INFO:compare_models() successfully completed......................................
2024-12-15 21:06:51,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-15 21:06:51,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-15 21:06:51,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-15 21:06:51,223:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-15 21:06:51,685:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-15 21:10:00,962:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2009102042.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:10:00,963:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2009102042.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:10:00,964:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2009102042.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:10:00,964:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2009102042.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:10:00,965:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2009102042.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:21:20,083:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:21:20,085:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:21:20,086:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:21:20,086:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:21:20,086:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:23:53,145:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:23:53,146:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:23:53,146:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:23:53,146:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:23:53,147:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:24:00,162:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:24:00,162:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:24:00,162:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:24:00,162:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:24:00,163:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:24:08,904:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:24:08,909:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:24:08,909:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:24:08,910:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:24:08,910:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:24:24,850:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:24:24,851:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:24:24,852:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:24:24,852:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:24:24,852:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:24:36,781:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:24:36,785:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:24:36,788:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:24:36,789:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:24:36,789:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:24:46,684:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:24:46,686:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:24:46,688:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:24:46,688:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:24:46,688:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:24:55,051:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:24:55,052:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:24:55,053:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:24:55,053:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:24:55,053:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:25:02,904:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:25:02,905:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:25:02,905:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:25:02,905:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:25:02,906:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:25:16,221:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:25:16,222:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:25:16,222:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:25:16,222:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:25:16,223:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:25:29,969:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:25:29,970:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:25:29,971:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:25:29,971:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:25:29,971:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:25:40,079:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:25:40,083:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:25:40,087:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:25:40,091:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:25:40,096:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:25:48,002:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:25:48,006:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:25:48,010:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:25:48,014:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:25:48,020:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:25:54,267:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:25:54,272:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:25:54,277:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:25:54,281:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:25:54,299:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:26:01,245:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:26:01,251:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:26:01,255:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:26:01,276:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:26:01,281:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:26:07,793:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:26:07,797:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:26:07,806:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:26:07,810:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:26:07,814:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:26:14,146:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:26:14,151:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:26:14,155:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:26:14,159:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:26:14,164:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:26:21,003:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:26:21,012:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:26:21,016:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:26:21,020:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:26:21,023:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:26:34,896:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:26:34,904:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:26:34,908:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:26:34,912:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:26:34,916:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:26:45,732:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:26:45,737:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:26:45,741:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:26:45,785:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:26:45,788:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:27:00,120:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:27:00,125:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:27:00,129:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:27:00,139:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:27:00,143:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:27:21,028:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:27:21,045:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:27:21,068:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:27:21,074:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:27:21,091:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:27:31,777:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:27:31,783:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:27:31,786:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:27:31,806:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:27:31,809:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:27:43,318:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:27:43,325:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:27:43,329:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:27:43,340:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:27:43,345:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:27:51,654:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:27:51,658:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:27:51,680:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:27:51,736:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:27:51,741:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:28:00,928:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:28:00,934:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:28:00,939:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:28:00,961:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:28:00,973:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:28:08,491:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:28:08,497:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:28:08,501:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:28:08,510:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:28:08,525:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:28:16,611:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:28:16,683:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:28:16,691:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:28:16,743:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:28:16,747:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:28:33,174:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:28:33,181:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:28:33,189:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:28:33,194:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:28:33,200:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:28:41,424:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:28:41,428:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:28:41,431:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:28:41,435:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:28:41,441:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:28:50,206:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:28:50,252:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:28:50,277:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:28:50,282:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:28:50,286:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:28:58,376:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:28:58,383:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:28:58,391:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:28:58,399:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:28:58,442:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:29:06,567:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:29:06,571:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:29:06,575:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:29:06,586:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:29:06,591:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:29:15,975:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:29:15,979:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:29:16,034:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:29:16,051:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:29:16,056:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:29:23,799:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:29:23,806:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:29:23,811:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:29:23,861:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:29:23,878:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:29:31,427:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:29:31,430:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:29:31,434:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:29:31,437:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:29:31,459:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:29:41,382:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:29:41,388:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:29:41,393:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:29:41,397:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:29:41,401:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:29:48,543:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:29:48,551:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:29:48,560:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:29:48,570:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:29:48,575:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:29:58,186:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:29:58,194:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:29:58,198:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:29:58,203:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:29:58,207:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:30:06,887:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:30:06,891:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:30:06,895:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:30:06,900:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:30:06,904:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:30:13,839:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:30:13,844:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:30:13,848:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:30:13,852:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:30:13,857:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:30:20,881:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:30:20,886:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:30:20,889:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:30:20,900:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:30:20,905:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:30:27,668:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:30:27,673:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:30:27,677:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:30:27,699:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:30:27,703:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:30:33,969:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:30:33,974:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:30:33,978:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:30:33,982:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:30:33,992:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:30:40,004:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:30:40,008:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:30:40,016:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:30:40,020:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:30:40,042:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:30:47,024:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:30:47,029:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:30:47,033:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:30:47,042:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:30:47,064:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:31:04,516:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:31:04,521:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:31:04,525:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:31:04,567:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:31:04,572:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:31:10,945:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:31:10,950:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:31:10,954:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:31:10,963:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:31:10,968:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:31:17,403:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:31:17,408:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:31:17,412:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:31:17,417:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:31:17,431:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:31:23,155:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:31:23,178:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:31:23,185:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:31:23,189:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:31:23,193:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:31:29,708:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:31:29,713:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:31:29,717:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:31:29,722:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:31:29,745:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:31:36,183:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:31:36,187:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:31:36,218:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:31:36,231:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:31:36,236:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:31:43,000:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:31:43,005:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:31:43,009:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:31:43,014:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:31:43,018:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:31:49,208:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:31:49,214:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:31:49,219:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:31:49,257:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:31:49,261:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:32:02,502:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:32:02,508:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:32:02,513:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:32:02,527:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:32:02,545:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:32:08,856:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:32:08,860:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:32:08,865:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:32:08,870:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:32:08,875:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:32:15,265:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:32:15,270:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:32:15,307:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:32:15,311:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:32:15,316:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:32:21,184:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:32:21,189:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:32:21,193:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:32:21,200:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:32:21,205:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:32:26,941:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:32:26,948:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:32:26,952:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:32:26,966:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:32:26,971:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:32:33,232:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:32:33,238:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:32:33,242:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:32:33,247:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:32:33,252:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:32:39,459:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:32:39,463:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:32:39,470:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:32:39,476:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:32:39,480:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:32:48,850:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:32:48,855:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:32:48,859:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:32:48,864:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:32:48,868:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:33:01,388:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:33:01,393:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:33:01,397:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:33:01,418:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:33:01,425:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:33:07,903:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:33:07,908:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:33:07,912:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:33:07,925:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:33:07,930:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:33:14,287:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:33:14,293:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:33:14,298:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:33:14,303:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:33:14,307:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:33:20,031:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:33:20,037:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:33:20,041:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:33:20,106:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:33:20,162:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:33:28,588:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:33:28,594:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:33:28,599:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:33:28,617:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:33:28,625:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:33:35,631:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:33:35,639:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:33:35,644:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:33:35,653:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:33:35,658:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:33:42,653:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:33:42,667:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:33:42,686:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:33:42,694:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:33:42,703:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:33:48,726:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:33:48,733:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:33:48,745:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:33:48,752:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:33:48,756:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:34:01,435:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:34:01,440:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:34:01,445:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:34:01,450:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:34:01,456:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:34:07,097:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:34:07,104:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:34:07,109:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:34:07,113:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:34:07,133:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:34:13,426:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:34:13,432:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:34:13,437:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:34:13,442:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:34:13,446:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:34:19,815:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:34:19,821:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:34:19,826:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:34:19,847:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:34:19,851:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:34:26,922:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:34:26,927:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:34:26,932:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:34:26,936:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:34:26,964:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:34:33,707:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:34:33,712:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:34:33,717:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:34:33,722:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:34:33,727:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:34:39,954:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:34:39,965:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:34:39,970:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:34:39,975:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:34:39,980:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:34:46,476:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:34:46,483:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:34:46,487:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:34:46,510:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:34:46,516:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:34:52,874:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:34:52,879:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:34:52,883:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:34:52,887:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:34:52,891:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:34:59,761:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:34:59,766:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:34:59,771:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:34:59,784:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:34:59,789:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:35:05,521:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:35:05,526:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:35:05,531:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:35:05,551:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:35:05,580:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:35:11,322:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:35:11,327:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:35:11,347:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:35:11,351:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:35:11,355:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:35:17,859:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:35:17,864:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:35:17,875:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:35:17,891:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:35:17,896:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:35:23,592:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:35:23,597:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:35:23,602:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:35:23,619:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:35:23,623:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:35:29,103:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:35:29,108:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:35:29,113:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:35:29,118:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:35:29,123:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:35:35,148:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:35:35,153:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:35:35,157:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:35:35,181:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:35:35,186:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:35:40,601:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:35:40,606:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:35:40,611:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:35:40,627:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:35:40,656:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:35:46,819:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:35:46,828:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:35:46,835:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:35:46,840:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:35:46,866:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:35:53,271:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:35:53,281:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:35:53,285:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:35:53,290:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:35:53,318:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:35:59,381:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:35:59,386:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:35:59,391:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:35:59,395:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:35:59,400:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:36:05,667:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:36:05,682:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:36:05,688:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:36:05,701:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:36:05,706:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:36:11,584:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:36:11,591:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:36:11,596:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:36:11,600:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:36:11,604:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:36:17,418:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:36:17,425:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:36:17,431:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:36:17,437:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:36:17,441:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:36:23,601:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:36:23,606:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:36:23,611:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:36:23,616:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:36:23,620:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:36:29,817:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:36:29,823:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:36:29,828:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:36:29,833:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:36:29,839:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:36:35,641:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:36:35,659:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:36:35,673:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:36:35,682:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:36:35,686:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:36:41,595:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:36:41,618:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:36:41,625:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:36:41,659:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:36:41,664:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:36:48,258:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:36:48,265:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:36:48,270:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:36:48,276:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:36:48,310:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:36:54,567:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:36:54,575:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:36:54,579:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:36:54,583:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:36:54,587:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:37:00,084:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:37:00,091:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:37:00,096:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:37:00,102:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:37:00,107:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-15 21:37:05,872:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-15 21:37:05,877:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-15 21:37:05,887:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-15 21:37:05,892:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-15 21:37:05,896:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3859350905.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 03:28:13,195:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2260839701.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:28:13,198:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2260839701.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:28:19,572:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2260839701.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:28:19,573:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2260839701.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:28:22,101:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2260839701.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:28:22,102:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2260839701.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:28:39,061:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2260839701.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:28:39,061:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2260839701.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:28:56,299:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/17039915.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:28:56,301:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/17039915.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:29:58,361:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/17039915.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:29:58,363:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/17039915.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:30:04,486:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/17039915.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:30:04,487:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/17039915.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:30:17,407:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:30:17,409:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:30:59,488:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:30:59,490:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:31:07,315:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:31:07,316:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:31:22,960:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:31:22,961:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:31:30,569:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:31:30,570:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:31:34,187:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:31:34,187:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:31:48,038:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:31:48,039:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:31:52,820:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:31:52,821:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:32:31,471:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:32:31,472:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:33:37,106:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:33:37,107:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:35:06,547:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:35:06,554:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:35:07,345:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:35:07,354:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:35:15,325:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:35:15,334:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:35:21,772:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:35:21,780:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:35:24,696:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:35:24,738:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:35:28,932:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:35:28,943:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:35:32,194:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:35:32,202:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:35:52,488:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:35:52,497:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:35:55,741:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:35:55,751:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:36:05,946:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:36:05,954:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:36:12,312:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:36:12,327:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:36:24,774:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:36:24,783:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:36:31,132:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:36:31,141:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:36:35,555:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:36:35,568:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:36:39,718:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:36:39,729:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:36:56,429:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:36:56,437:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:37:03,439:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:37:03,451:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:37:07,028:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:37:07,037:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:37:10,588:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:37:10,596:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:37:14,350:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:37:14,361:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:37:42,936:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:37:42,948:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:37:46,012:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:37:46,020:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:37:52,442:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:37:52,451:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:37:59,857:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:37:59,866:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:38:09,593:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:38:09,602:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:38:24,507:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:38:24,515:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:38:27,784:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:38:27,792:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:38:46,952:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:38:46,962:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:38:50,301:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:38:50,310:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:39:02,765:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:39:02,775:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:39:11,371:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:39:11,382:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:40:05,057:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:40:05,065:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:40:10,594:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:40:10,603:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:40:16,972:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:40:16,985:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:40:19,292:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:40:19,301:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:40:24,505:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:40:24,513:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:40:37,289:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:40:37,299:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:40:44,277:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:40:44,285:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 03:40:55,274:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 03:40:55,282:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:53:55,805:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:53:55,807:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:54:07,909:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:54:07,910:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:55:14,033:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:55:14,033:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:55:22,069:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:55:22,070:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:55:45,612:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:55:45,612:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:57:29,040:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:57:29,042:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:57:55,180:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:57:55,181:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:57:57,161:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:57:57,161:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:58:03,511:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:58:03,512:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:59:05,108:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:59:05,110:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:59:23,090:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:59:23,098:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:59:38,034:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:59:38,042:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 19:59:53,752:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 19:59:53,760:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 20:19:31,163:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 20:19:31,170:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:07:56,158:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:07:56,172:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:08:04,895:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:08:04,902:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:08:16,547:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:08:16,556:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:08:25,315:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:08:25,322:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:08:27,835:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:08:27,845:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:08:43,040:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:08:43,049:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:08:48,308:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:08:48,315:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:08:50,911:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:08:50,918:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:08:59,652:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:08:59,664:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:09:12,690:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:09:12,698:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:09:20,796:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:09:20,803:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:09:31,700:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:09:31,708:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:09:37,969:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:09:37,977:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:09:44,181:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:09:44,189:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:09:56,548:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:09:56,560:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:10:04,777:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:10:04,785:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:10:22,916:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:10:22,924:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:10:28,533:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:10:28,540:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:10:36,305:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:10:36,313:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:10:44,422:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:10:44,429:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:10:55,775:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:10:55,867:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:11:04,886:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:11:04,895:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:11:09,644:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:11:09,652:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:11:21,948:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:11:21,957:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:11:34,521:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:11:34,528:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:11:44,098:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:11:44,106:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:12:12,700:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:12:12,712:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:12:21,606:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:12:21,616:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:12:33,611:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:12:33,619:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:12:49,337:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:12:49,346:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:13:01,330:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:13:01,340:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:13:13,988:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:13:13,996:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:43:34,236:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:43:34,246:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:43:52,764:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:43:52,773:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:44:01,213:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:44:01,221:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:44:14,226:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:44:14,233:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:44:30,447:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:44:30,455:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:45:08,914:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:45:08,922:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:45:20,262:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:45:20,271:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:45:31,792:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:45:31,800:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:45:45,655:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:45:45,671:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:45:57,817:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:45:57,825:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:46:15,379:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:46:15,387:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:46:21,639:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:46:21,648:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:46:32,158:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:46:32,168:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:46:36,994:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:46:37,002:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:46:50,467:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:46:50,475:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:47:08,525:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:47:08,533:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:47:20,924:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:47:20,934:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:47:33,088:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:47:33,097:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:47:47,543:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:47:47,560:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:47:56,506:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:47:56,515:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:48:09,229:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:48:09,238:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:48:16,937:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:48:16,947:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 21:48:40,374:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 21:48:40,389:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:00:40,799:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:00:40,808:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:00:48,303:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:00:48,312:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:00:52,029:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:00:52,040:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:01:03,611:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:01:03,620:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:01:14,573:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:01:14,582:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:01:29,511:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:01:29,520:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:01:39,214:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:01:39,222:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:01:49,125:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:01:49,134:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:01:56,418:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:01:56,428:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:02:12,248:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:02:12,257:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:02:18,329:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:02:18,341:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:02:28,196:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:02:28,205:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:02:38,648:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:02:38,658:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:02:50,542:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:02:50,551:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:03:01,941:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:03:01,950:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:03:13,417:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:03:13,427:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:03:26,817:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:03:26,826:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:03:36,477:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:03:36,486:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:03:54,506:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:03:54,514:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:04:07,608:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:04:07,619:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:04:28,234:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:04:28,243:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:19:45,190:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:19:45,199:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:19:57,593:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:19:57,602:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:20:08,752:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:20:08,761:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:20:19,887:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:20:19,897:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:20:31,843:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:20:31,851:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:20:44,064:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:20:44,073:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:20:57,003:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:20:57,011:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:21:10,491:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:21:10,500:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:21:19,310:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:21:19,318:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:21:39,935:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.3),  # Learning rate

2024-12-16 22:21:39,945:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/940745214.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),  # L2 regularization

2024-12-16 22:21:51,684:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:21:51,685:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:21:51,685:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:22:25,994:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:22:25,997:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:22:25,997:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:23:08,000:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:23:08,002:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:23:08,002:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:23:20,619:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:23:20,620:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:23:20,621:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:28:26,212:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:28:26,215:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:28:26,215:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:28:38,845:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:28:38,846:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:28:38,846:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:29:02,531:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:29:02,533:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:29:02,533:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:29:12,542:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:29:12,543:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:29:12,544:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:29:14,462:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:29:14,463:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:29:14,463:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:29:29,370:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:29:29,371:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:29:29,371:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:29:37,565:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:29:37,577:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:29:37,580:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:29:44,321:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:29:44,335:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:29:44,338:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:29:50,704:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:29:50,716:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:29:50,718:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:29:54,840:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:29:54,853:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:29:54,855:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:30:01,063:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:30:01,075:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:30:01,078:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:30:02,657:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:30:02,670:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:30:02,672:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:30:14,094:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:30:14,107:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:30:14,110:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:30:29,747:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:30:29,761:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:30:29,763:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:30:36,664:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:30:36,678:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:30:36,681:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:30:43,208:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:30:43,220:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:30:43,222:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:31:08,057:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:31:08,073:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:31:08,075:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:31:26,332:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:31:26,345:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:31:26,348:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:31:30,668:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:31:30,681:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:31:30,684:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:31:34,430:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:31:34,446:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:31:34,449:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:31:37,728:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:31:37,740:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:31:37,743:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:31:42,872:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:31:42,886:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:31:42,890:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:31:45,854:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:31:45,867:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:31:45,870:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:31:52,251:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:31:52,264:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:31:52,267:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:31:56,657:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:31:56,703:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:31:56,707:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:32:00,412:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:32:00,426:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:32:00,429:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:32:14,617:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:32:14,633:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:32:14,636:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:32:28,237:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:32:28,251:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:32:28,254:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:32:39,486:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:32:39,502:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:32:39,520:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:32:49,875:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:32:49,890:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:32:49,893:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:32:58,314:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:32:58,327:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:32:58,330:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:33:04,702:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:33:04,720:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:33:04,723:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:33:12,278:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:33:12,293:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:33:12,296:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:33:18,548:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:33:18,562:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:33:18,565:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:35:28,469:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:35:28,485:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:35:28,489:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:35:46,390:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:35:46,404:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:35:46,407:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:35:55,417:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:35:55,432:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:35:55,435:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:36:00,507:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:36:00,521:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:36:00,524:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:36:08,313:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:36:08,329:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:36:08,332:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:36:18,381:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:36:18,395:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:36:18,399:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:36:29,875:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:36:29,891:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:36:29,895:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:36:36,934:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:36:36,949:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:36:36,952:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:36:42,304:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:36:42,320:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:36:42,323:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:36:46,937:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:36:46,952:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:36:46,955:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:36:52,686:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:36:52,701:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:36:52,704:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:36:58,331:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:36:58,346:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:36:58,349:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:37:33,183:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:37:33,199:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:37:33,202:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:37:45,394:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:37:45,408:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:37:45,413:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:37:54,459:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:37:54,474:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:37:54,495:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:38:01,234:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:38:01,249:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:38:01,252:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:38:09,085:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:38:09,102:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:38:09,105:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:38:25,460:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:38:25,476:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:38:25,479:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:38:35,668:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:38:35,683:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:38:35,686:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:38:40,906:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:38:40,921:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:38:40,924:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:39:06,312:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:39:06,328:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:39:06,331:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:39:11,509:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:39:11,524:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:39:11,527:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:39:24,737:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:39:24,756:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:39:24,760:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:39:34,193:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:39:34,209:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:39:34,213:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:39:39,800:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:39:39,816:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:39:39,819:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:39:44,935:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:39:44,950:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:39:44,953:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:39:54,093:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:39:54,108:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:39:54,112:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:40:06,376:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:40:06,391:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:40:06,394:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:40:13,316:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:40:13,332:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:40:13,335:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:40:24,885:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:40:24,902:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:40:24,905:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:44:13,492:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:44:13,508:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:44:13,511:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:44:20,923:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:44:20,940:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:44:20,944:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:44:25,688:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:44:25,705:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:44:25,710:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:44:36,028:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:44:36,090:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:44:36,094:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:44:41,640:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:44:41,655:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:44:41,658:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:44:45,656:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:44:45,672:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:44:45,675:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:44:56,501:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:44:56,524:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:44:56,527:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:45:05,377:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:45:05,393:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:45:05,397:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:45:11,320:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:45:11,337:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:45:11,340:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:45:23,051:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:45:23,072:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:45:23,076:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:46:30,895:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:46:30,913:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:46:30,916:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:46:44,076:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:46:44,091:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:46:44,094:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:46:54,716:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:46:54,734:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:46:54,737:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:47:05,994:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:47:06,011:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:47:06,014:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:47:16,597:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:47:16,613:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:47:16,616:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:47:22,545:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:47:22,570:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:47:22,573:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:47:29,398:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:47:29,444:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:47:29,448:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:47:39,013:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:47:39,032:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:47:39,091:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:47:48,126:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:47:48,143:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:47:48,150:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:47:52,742:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:47:52,759:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:47:52,762:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:48:07,128:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:48:07,148:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:48:07,152:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:48:17,218:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:48:17,234:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:48:17,237:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:48:35,203:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:48:35,220:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:48:35,223:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:48:47,694:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:48:47,711:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:48:47,714:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:48:56,681:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:48:56,698:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:48:56,701:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:49:08,172:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:49:08,189:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:49:08,192:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:49:13,520:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:49:13,536:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:49:13,539:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:49:24,961:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:49:24,979:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:49:24,982:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:49:50,512:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:49:50,530:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:49:50,533:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:50:16,793:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:50:16,812:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:50:16,815:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:51:47,823:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:51:47,845:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:51:47,848:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:51:55,297:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 22:51:55,315:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  subsample = trial.suggest_uniform("subsample", 0.5, 1.0)

2024-12-16 22:51:55,318:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/3332004918.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  max_features = trial.suggest_uniform("max_features", 0.1, 1.0)

2024-12-16 22:52:07,624:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:52:07,624:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:52:07,625:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:52:07,625:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:52:07,625:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:52:14,850:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:52:14,850:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:52:14,850:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:52:14,851:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:52:14,851:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:52:22,480:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:52:22,481:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:52:22,481:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:52:22,481:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:52:22,481:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:52:29,470:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:52:29,471:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:52:29,471:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:52:29,471:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:52:29,471:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:52:36,176:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:52:36,176:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:52:36,178:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:52:36,178:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:52:36,179:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:52:43,432:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:52:43,433:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:52:43,433:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:52:43,433:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:52:43,434:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:52:49,731:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:52:49,732:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:52:49,732:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:52:49,733:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:52:49,733:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:52:58,075:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:52:58,076:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:52:58,076:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:52:58,076:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:52:58,076:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:53:04,861:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:53:04,862:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:53:04,862:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:53:04,862:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:53:04,862:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:53:13,781:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:53:13,782:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:53:13,782:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:53:13,783:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:53:13,783:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:53:20,504:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:53:20,509:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:53:20,512:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:53:20,515:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:53:20,519:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:53:26,743:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:53:26,751:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:53:26,754:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:53:26,756:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:53:26,759:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:53:33,552:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:53:33,557:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:53:33,561:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:53:33,565:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:53:33,568:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:53:40,375:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:53:40,380:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:53:40,383:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:53:40,387:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:53:40,390:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:53:47,022:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:53:47,026:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:53:47,029:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:53:47,033:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:53:47,038:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:53:53,670:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:53:53,675:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:53:53,679:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:53:53,683:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:53:53,687:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:54:01,580:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:54:01,584:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:54:01,587:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:54:01,590:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:54:01,593:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:54:07,902:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:54:07,907:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:54:07,912:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:54:07,917:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:54:07,940:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:54:13,773:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:54:13,778:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:54:13,782:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:54:13,785:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:54:13,788:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:54:20,251:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:54:20,256:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:54:20,261:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:54:20,264:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:54:20,267:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:54:26,789:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:54:26,794:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:54:26,798:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:54:26,819:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:54:26,823:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:54:34,738:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:54:34,743:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:54:34,748:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:54:34,753:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:54:34,759:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:54:41,540:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:54:41,544:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:54:41,548:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:54:41,552:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:54:41,555:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:54:47,935:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:54:47,939:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:54:47,942:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:54:47,945:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:54:47,948:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:54:55,861:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:54:55,865:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:54:55,868:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:54:55,872:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:54:55,877:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:55:02,499:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:55:02,504:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:55:02,507:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:55:02,515:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:55:02,519:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:55:08,714:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:55:08,740:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:55:08,745:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:55:08,749:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:55:08,753:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:55:15,221:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:55:15,226:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:55:15,230:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:55:15,235:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:55:15,241:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:55:21,777:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:55:21,795:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:55:21,809:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:55:21,820:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:55:21,836:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:55:28,422:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:55:28,427:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:55:28,432:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:55:28,436:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:55:28,471:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:55:35,753:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:55:35,757:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:55:35,761:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:55:35,766:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:55:35,770:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:55:43,211:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:55:43,215:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:55:43,219:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:55:43,223:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:55:43,227:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:55:50,168:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:55:50,173:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:55:50,176:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:55:50,181:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:55:50,186:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:55:56,933:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:55:56,938:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:55:56,942:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:55:56,965:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:55:56,970:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:56:03,770:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:56:03,774:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:56:03,779:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:56:03,782:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:56:03,786:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:56:11,561:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:56:11,567:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:56:11,572:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:56:11,575:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:56:11,579:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:56:18,154:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:56:18,159:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:56:18,170:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:56:18,173:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:56:18,176:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:56:24,890:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:56:24,896:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:56:24,901:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:56:24,943:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:56:24,947:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:56:31,879:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:56:31,886:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:56:31,890:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:56:31,894:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:56:31,899:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:56:37,911:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:56:37,942:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:56:37,947:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:56:37,951:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:56:37,956:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:56:45,549:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:56:45,555:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:56:45,568:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:56:45,572:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:56:45,577:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:56:54,017:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:56:54,027:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:56:54,156:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:56:54,161:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:56:54,168:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:57:01,442:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:57:01,447:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:57:01,450:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:57:01,455:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:57:01,460:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:57:08,756:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:57:08,765:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:57:08,770:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:57:08,781:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:57:08,785:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:57:15,315:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:57:15,329:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:57:15,356:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:57:15,369:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:57:15,378:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:57:22,675:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:57:22,680:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:57:22,684:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:57:22,688:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:57:22,691:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:57:32,166:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:57:32,173:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:57:32,179:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:57:32,185:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:57:32,193:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:57:40,145:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:57:40,150:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:57:40,155:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:57:40,160:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:57:40,166:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:57:48,507:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:57:48,511:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:57:48,515:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:57:48,518:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:57:48,522:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:57:56,572:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:57:56,576:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:57:56,580:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:57:56,584:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:57:56,588:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:58:03,639:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:58:03,644:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:58:03,647:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:58:03,694:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:58:03,713:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:58:11,926:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:58:11,932:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:58:11,935:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:58:11,940:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:58:11,963:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:58:19,359:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:58:19,364:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:58:19,369:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:58:19,374:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:58:19,378:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:58:26,883:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:58:26,888:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:58:26,893:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:58:26,899:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:58:26,930:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:58:34,116:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:58:34,128:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:58:34,142:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:58:34,157:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:58:34,163:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:58:43,716:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:58:43,721:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:58:43,726:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:58:43,730:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:58:43,734:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:58:52,407:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:58:52,413:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:58:52,422:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:58:52,426:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:58:52,431:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:58:59,498:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:58:59,503:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:58:59,507:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:58:59,519:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:58:59,524:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:59:07,051:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:59:07,057:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:59:07,063:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:59:07,069:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:59:07,084:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:59:13,719:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:59:13,725:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:59:13,730:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:59:13,750:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:59:13,755:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:59:20,763:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:59:20,768:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:59:20,771:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:59:20,785:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:59:20,821:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:59:28,555:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:59:28,572:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:59:28,579:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:59:28,586:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:59:28,593:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:59:39,437:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:59:39,444:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:59:39,451:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:59:39,461:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:59:39,466:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:59:48,016:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:59:48,023:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:59:48,028:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:59:48,033:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:59:48,045:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 22:59:55,364:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 22:59:55,385:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 22:59:55,406:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 22:59:55,415:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 22:59:55,422:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:00:02,151:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:00:02,156:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:00:02,160:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:00:02,164:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:00:02,168:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:00:09,720:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:00:09,726:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:00:09,731:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:00:09,737:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:00:09,746:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:00:17,932:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:00:17,937:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:00:17,942:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:00:17,956:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:00:17,962:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:00:23,798:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:00:23,810:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:00:23,862:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:00:23,867:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:00:23,880:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:00:31,213:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:00:31,218:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:00:31,222:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:00:31,226:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:00:31,229:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:00:37,579:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:00:37,583:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:00:37,588:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:00:37,592:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:00:37,596:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:00:44,269:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:00:44,274:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:00:44,279:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:00:44,284:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:00:44,288:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:00:51,060:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:00:51,067:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:00:51,095:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:00:51,133:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:00:51,157:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:00:58,933:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:00:58,939:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:00:58,974:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:00:58,979:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:00:58,982:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:01:05,447:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:01:05,452:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:01:05,456:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:01:05,460:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:01:05,465:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:01:14,245:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:01:14,252:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:01:14,257:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:01:14,262:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:01:14,268:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:01:21,005:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:01:21,010:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:01:21,015:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:01:21,019:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:01:21,024:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:01:28,288:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:01:28,308:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:01:28,349:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:01:28,360:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:01:28,367:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:01:35,246:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:01:35,253:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:01:35,258:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:01:35,263:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:01:35,269:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:01:42,097:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:01:42,108:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:01:42,114:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:01:42,122:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:01:42,129:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:01:48,719:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:01:48,730:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:01:48,735:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:01:48,742:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:01:48,747:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:01:55,741:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:01:55,746:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:01:55,749:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:01:55,753:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:01:55,757:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:02:02,295:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:02:02,301:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:02:02,306:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:02:02,310:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:02:02,315:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:02:08,539:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:02:08,543:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:02:08,548:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:02:08,553:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:02:08,558:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:02:14,417:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:02:14,424:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:02:14,429:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:02:14,434:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:02:14,440:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:02:21,111:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:02:21,116:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:02:21,120:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:02:21,124:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:02:21,128:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:02:28,127:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:02:28,133:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:02:28,138:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:02:28,143:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:02:28,148:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:02:35,234:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:02:35,240:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:02:35,246:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:02:35,251:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:02:35,257:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:02:42,118:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:02:42,124:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:02:42,155:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:02:42,160:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:02:42,190:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:02:48,944:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:02:48,948:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:02:48,953:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:02:48,958:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:02:48,963:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:02:56,253:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:02:56,259:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:02:56,264:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:02:56,273:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:02:56,278:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:03:03,439:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:03:03,445:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:03:03,452:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:03:03,457:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:03:03,461:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:03:11,021:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:03:11,027:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:03:11,031:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:03:11,036:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:03:11,042:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:03:17,280:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:03:17,286:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:03:17,307:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:03:17,313:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:03:17,319:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:03:24,027:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:03:24,034:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:03:24,047:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:03:24,053:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:03:24,059:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:03:32,311:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:03:32,316:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:03:32,321:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:03:32,325:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:03:32,329:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:03:39,464:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:03:39,470:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:03:39,475:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:03:39,481:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:03:39,484:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:03:45,541:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:03:45,546:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:03:45,551:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:03:45,555:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:03:45,559:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:03:52,117:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:03:52,122:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:03:52,126:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:03:52,130:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:03:52,134:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:03:58,137:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 10.0)

2024-12-16 23:03:58,142:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_1 = trial.suggest_loguniform("alpha_1", 1e-8, 10.0)

2024-12-16 23:03:58,148:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  alpha_2 = trial.suggest_loguniform("alpha_2", 1e-8, 10.0)

2024-12-16 23:03:58,153:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_1 = trial.suggest_loguniform("lambda_1", 1e-8, 10.0)

2024-12-16 23:03:58,157:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/1893396942.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_2 = trial.suggest_loguniform("lambda_2", 1e-8, 10.0)

2024-12-16 23:04:05,096:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:04:05,097:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:04:05,098:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:04:05,098:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:04:05,098:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:04:15,832:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:04:15,833:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:04:15,833:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:04:15,833:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:04:15,833:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:04:19,136:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:04:19,136:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:04:19,136:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:04:19,137:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:04:19,137:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:04:22,591:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:04:22,591:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:04:22,592:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:04:22,592:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:04:22,592:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:04:26,218:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:04:26,219:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:04:26,219:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:04:26,219:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:04:26,219:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:04:41,298:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:04:41,300:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:04:41,301:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:04:41,301:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:04:41,301:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:04:47,231:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:04:47,232:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:04:47,232:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:04:47,232:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:04:47,232:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:04:50,211:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:04:50,211:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:04:50,212:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:04:50,212:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:04:50,212:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:04:53,833:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:04:53,834:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:04:53,835:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:04:53,835:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:04:53,835:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:04:59,258:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:04:59,258:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:04:59,259:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:04:59,259:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:04:59,259:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:01,667:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:01,678:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:01,681:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:01,683:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:01,692:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:02,413:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:02,424:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:02,427:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:02,429:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:02,432:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:03,186:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:03,197:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:03,200:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:03,202:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:03,205:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:04,217:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:04,228:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:04,231:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:04,234:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:04,236:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:05,404:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:05,416:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:05,419:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:05,422:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:05,425:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:06,813:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:06,825:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:06,827:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:06,830:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:06,832:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:07,853:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:07,865:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:07,868:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:07,870:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:07,873:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:12,405:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:12,418:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:12,420:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:12,423:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:12,425:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:22,495:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:22,507:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:22,510:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:22,512:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:22,515:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:23,618:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:23,631:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:23,633:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:23,636:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:23,638:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:25,288:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:25,300:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:25,303:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:25,306:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:25,309:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:33,372:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:33,386:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:33,388:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:33,391:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:33,394:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:34,772:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:34,785:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:34,788:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:34,791:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:34,794:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:35,973:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:35,986:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:35,989:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:35,992:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:35,995:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:38,600:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:38,613:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:38,616:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:38,618:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:38,621:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:39,856:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:39,870:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:39,872:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:39,875:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:39,878:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:46,438:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:46,451:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:46,454:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:46,457:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:46,459:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:47,665:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:47,678:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:47,681:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:47,684:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:47,687:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:48,492:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:48,506:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:48,509:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:48,511:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:48,515:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:52,576:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:52,590:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:52,593:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:52,595:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:52,598:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:05:56,563:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:05:56,576:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:05:56,589:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:05:56,610:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:05:56,627:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:02,353:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:02,368:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:02,371:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:02,374:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:02,376:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:03,726:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:03,741:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:03,743:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:03,746:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:03,749:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:05,162:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:05,176:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:05,179:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:05,184:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:05,187:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:07,241:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:07,255:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:07,258:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:07,260:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:07,263:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:08,863:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:08,879:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:08,882:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:08,885:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:08,889:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:39,154:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:39,170:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:39,173:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:39,182:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:39,209:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:42,716:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:42,730:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:42,733:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:42,736:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:42,739:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:44,759:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:44,774:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:44,777:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:44,782:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:44,785:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:46,224:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:46,238:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:46,241:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:46,243:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:46,246:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:49,195:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:49,210:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:49,213:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:49,215:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:49,218:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:50,942:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:50,957:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:50,963:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:50,966:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:50,969:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:51,796:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:51,812:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:51,815:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:51,818:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:51,821:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:52,681:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:52,696:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:52,699:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:52,703:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:52,706:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:54,124:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:54,139:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:54,142:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:54,145:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:54,148:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:54,860:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:54,876:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:54,885:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:54,890:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:54,930:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:56,607:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:56,621:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:56,624:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:56,627:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:56,630:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:06:58,074:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:06:58,089:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:06:58,092:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:06:58,095:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:06:58,099:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:12,946:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:12,963:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:12,967:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:13,017:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:13,024:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:15,309:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:15,324:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:15,327:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:15,362:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:15,366:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:17,143:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:17,158:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:17,161:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:17,201:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:17,205:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:18,583:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:18,598:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:18,601:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:18,639:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:18,644:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:19,658:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:19,673:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:19,676:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:19,693:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:19,717:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:21,231:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:21,246:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:21,249:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:21,281:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:21,286:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:22,106:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:22,121:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:22,124:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:22,164:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:22,170:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:23,391:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:23,408:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:23,454:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:23,459:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:23,467:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:24,927:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:24,942:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:24,978:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:24,985:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:24,990:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:25,831:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:25,847:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:25,850:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:25,879:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:25,888:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:28,116:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:28,131:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:28,134:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:28,173:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:28,178:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:29,847:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:29,863:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:29,866:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:29,902:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:29,906:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:32,373:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:32,405:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:32,430:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:32,433:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:32,442:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:33,310:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:33,325:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:33,328:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:33,348:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:33,365:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:34,156:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:34,172:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:34,179:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:34,199:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:34,210:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:35,152:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:35,168:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:35,170:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:35,185:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:35,214:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:36,071:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:36,086:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:36,090:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:36,132:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:36,137:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:37,292:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:37,307:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:37,326:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:37,348:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:37,359:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:38,251:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:38,267:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:38,270:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:38,273:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:38,313:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:39,074:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:39,093:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:39,114:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:39,133:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:39,138:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:40,022:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:40,058:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:40,071:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:40,076:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:40,082:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:41,163:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:41,187:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:41,202:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:41,216:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:41,221:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:42,170:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:42,186:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:42,189:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:42,196:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:42,220:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:43,473:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:43,491:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:43,525:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:43,537:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:43,545:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:44,214:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:44,230:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:44,232:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:44,268:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:44,272:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:45,090:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:45,106:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:45,141:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:45,145:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:45,152:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:45,914:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:45,936:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:45,964:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:45,968:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:45,973:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:48,980:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:48,997:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:49,000:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:49,047:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:49,057:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:50,058:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:50,074:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:50,077:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:50,080:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:50,119:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:50,960:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:50,977:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:50,997:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:51,015:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:51,019:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:07:52,044:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:07:52,060:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:07:52,063:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:07:52,099:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:07:52,103:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:05,301:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:05,318:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:05,321:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:05,323:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:05,362:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:08,910:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:08,926:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:08,929:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:09,015:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:09,030:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:10,003:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:10,019:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:10,022:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:10,025:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:10,044:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:11,800:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:11,820:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:11,856:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:11,859:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:11,864:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:12,854:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:12,870:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:12,873:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:12,887:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:12,910:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:14,171:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:14,187:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:14,190:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:14,193:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:14,199:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:15,109:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:15,128:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:15,152:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:15,168:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:15,173:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:15,990:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:16,066:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:16,078:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:16,082:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:16,085:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:18,410:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:18,467:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:18,471:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:18,476:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:18,480:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:19,498:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:19,552:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:19,559:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:19,564:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:19,567:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:20,407:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:20,459:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:20,466:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:20,471:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:20,474:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:21,685:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:21,701:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:21,704:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:21,707:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:21,723:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:22,560:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:22,577:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:22,580:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:22,626:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:22,631:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:23,469:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:23,486:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:23,523:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:23,528:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:23,533:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:24,324:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:24,344:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:24,368:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:24,383:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:24,387:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:25,469:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:25,505:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:25,525:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:25,531:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:25,537:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:26,771:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:26,790:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:26,822:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:26,834:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:26,839:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:27,517:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:27,534:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:27,553:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:27,573:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:27,578:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:28,537:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:28,599:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:28,603:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:28,609:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:28,614:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:29,534:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:29,555:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:29,558:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:29,599:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:29,605:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-16 23:08:30,448:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-16 23:08:30,467:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-16 23:08:30,471:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-16 23:08:30,477:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-16 23:08:30,510:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:02:12,416:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:02:12,418:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:02:12,418:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:02:12,418:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:02:12,418:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:02:17,805:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:02:17,806:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:02:17,806:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:02:17,806:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:02:17,806:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:02:21,624:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:02:21,625:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:02:21,625:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:02:21,625:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:02:21,625:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:02:25,301:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:02:25,302:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:02:25,302:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:02:25,302:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:02:25,302:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:02:31,415:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:02:31,416:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:02:31,416:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:02:31,416:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:02:31,417:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:02:43,719:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:02:43,721:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:02:43,721:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:02:43,721:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:02:43,721:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:02:45,255:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:02:45,256:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:02:45,256:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:02:45,256:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:02:45,257:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:02:48,385:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:02:48,386:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:02:48,386:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:02:48,387:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:02:48,387:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:02:51,707:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:02:51,708:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:02:51,708:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:02:51,709:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:02:51,709:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:12,182:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:12,182:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:12,183:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:12,183:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:12,183:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:15,725:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:15,740:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:15,743:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:15,746:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:15,748:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:18,320:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:18,341:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:18,347:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:18,352:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:18,358:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:21,062:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:21,079:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:21,083:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:21,086:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:21,089:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:22,998:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:23,012:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:23,015:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:23,018:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:23,022:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:30,612:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:30,625:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:30,628:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:30,630:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:30,633:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:31,161:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:31,173:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:31,176:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:31,179:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:31,181:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:33,949:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:33,962:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:33,964:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:33,967:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:33,970:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:40,038:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:40,052:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:40,055:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:40,058:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:40,061:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:48,005:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:48,021:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:48,024:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:48,027:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:48,030:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:49,598:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:49,615:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:49,619:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:49,622:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:49,625:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:53,045:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:53,059:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:53,061:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:53,064:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:53,067:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:03:59,590:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:03:59,605:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:03:59,608:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:03:59,610:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:03:59,613:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:00,823:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:00,836:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:00,839:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:00,842:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:00,845:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:01,913:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:01,926:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:01,928:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:01,931:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:01,934:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:03,699:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:03,714:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:03,717:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:03,719:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:03,722:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:06,600:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:06,613:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:06,616:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:06,619:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:06,621:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:07,632:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:07,645:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:07,648:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:07,650:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:07,654:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:09,980:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:09,993:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:09,995:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:09,998:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:10,001:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:11,283:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:11,298:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:11,300:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:11,303:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:11,306:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:14,579:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:14,592:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:14,595:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:14,598:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:14,600:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:15,930:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:15,943:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:15,946:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:15,949:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:15,951:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:17,663:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:17,676:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:17,679:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:17,682:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:17,685:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:19,730:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:19,743:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:19,746:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:19,749:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:19,751:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:21,513:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:21,527:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:21,530:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:21,533:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:21,536:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:22,692:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:22,705:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:22,708:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:22,711:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:22,713:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:23,892:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:23,906:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:23,909:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:23,912:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:23,914:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:25,139:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:25,157:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:25,161:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:25,163:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:25,166:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:27,246:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:27,261:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:27,264:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:27,266:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:27,269:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:28,470:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:28,485:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:28,487:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:28,490:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:28,493:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:30,745:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:30,759:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:30,762:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:30,764:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:30,767:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:31,897:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:31,912:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:31,915:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:31,917:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:31,920:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:52,341:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:52,355:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:52,358:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:52,361:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:52,364:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:53,765:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:53,780:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:53,783:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:53,785:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:53,788:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:55,059:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:55,078:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:55,081:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:55,083:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:55,086:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:56,184:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:56,198:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:56,201:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:56,203:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:56,206:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:04:58,268:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:04:58,284:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:04:58,287:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:04:58,290:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:04:58,293:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:00,407:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:00,422:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:00,425:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:00,427:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:00,430:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:02,197:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:02,212:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:02,215:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:02,218:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:02,221:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:07,651:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:07,666:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:07,669:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:07,671:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:07,674:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:09,154:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:09,169:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:09,171:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:09,174:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:09,177:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:12,217:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:12,233:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:12,235:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:12,238:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:12,241:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:14,804:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:14,820:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:14,823:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:14,825:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:14,828:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:16,255:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:16,269:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:16,272:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:16,275:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:16,278:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:17,605:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:17,637:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:17,640:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:17,643:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:17,645:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:19,638:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:19,653:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:19,656:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:19,659:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:19,662:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:21,457:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:21,472:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:21,475:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:21,478:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:21,481:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:23,235:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:23,250:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:23,253:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:23,256:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:23,259:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:24,722:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:24,737:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:24,740:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:24,743:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:24,746:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:28,659:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:28,674:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:28,677:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:28,680:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:28,683:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:30,844:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:30,860:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:30,863:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:30,865:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:30,868:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:33,203:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:33,218:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:33,221:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:33,224:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:33,227:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:39,946:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:39,962:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:39,965:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:39,967:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:39,970:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:41,315:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:41,331:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:41,334:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:41,337:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:41,340:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:42,981:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:42,996:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:42,999:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:43,002:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:43,005:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:44,806:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:44,822:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:44,825:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:44,828:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:44,831:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:49,635:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:49,651:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:49,654:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:49,657:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:49,660:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:54,361:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:54,377:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:54,380:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:54,383:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:54,386:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:55,805:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:55,820:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:55,823:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:55,826:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:55,829:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:57,492:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:57,508:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:57,511:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:57,513:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:57,516:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:05:59,100:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:05:59,116:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:05:59,119:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:05:59,122:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:05:59,125:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:00,985:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:01,001:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:01,004:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:01,007:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:01,009:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:05,108:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:05,124:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:05,127:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:05,130:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:05,133:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:06,590:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:06,606:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:06,609:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:06,612:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:06,614:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:08,103:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:08,119:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:08,122:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:08,125:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:08,128:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:10,124:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:10,141:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:10,144:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:10,146:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:10,149:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:11,669:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:11,685:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:11,687:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:11,690:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:11,693:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:13,541:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:13,557:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:13,560:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:13,562:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:13,565:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:15,206:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:15,223:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:15,226:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:15,231:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:15,234:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:16,792:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:16,808:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:16,811:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:16,814:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:16,817:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:23,111:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:23,132:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:23,137:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:23,141:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:23,144:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:25,991:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:26,008:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:26,011:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:26,014:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:26,017:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:27,758:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:27,774:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:27,777:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:27,780:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:27,783:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:29,127:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:29,144:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:29,146:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:29,149:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:29,152:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:30,399:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:30,415:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:30,418:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:30,420:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:30,423:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:31,728:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:31,744:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:31,747:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:31,750:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:31,753:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:33,781:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:33,797:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:33,800:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:33,803:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:33,806:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:35,710:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:35,726:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:35,730:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:35,733:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:35,736:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:37,075:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:37,092:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:37,095:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:37,098:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:37,101:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:39,549:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:39,567:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:39,569:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:39,572:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:39,575:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:41,333:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:41,350:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:41,353:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:41,355:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:41,358:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:42,981:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:42,997:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:43,000:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:43,003:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:43,006:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:45,397:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:45,413:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:45,416:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:45,419:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:45,422:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:46,878:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:46,895:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:46,897:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:46,900:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:46,903:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:48,467:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:48,491:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:48,495:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:48,499:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:48,504:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:50,246:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:50,263:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:50,266:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:50,268:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:50,271:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:51,921:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:51,938:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:51,941:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:51,943:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:51,946:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:53,792:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:53,809:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:53,812:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:53,815:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:53,818:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:55,285:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:55,303:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:55,306:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:55,309:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:55,312:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:57,297:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:57,314:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:57,317:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:57,320:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:57,323:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:06:58,936:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:06:58,953:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:06:58,956:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:06:58,959:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:06:58,961:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:07:00,236:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:07:00,237:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:07:00,237:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:07:00,237:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:07:00,237:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:07:10,145:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:07:10,146:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:07:10,147:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:07:10,147:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:07:10,147:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:07:17,109:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:07:17,110:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:07:17,110:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:07:17,110:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:07:17,110:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:07:22,832:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:07:22,832:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:07:22,833:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:07:22,833:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:07:22,833:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:07:26,375:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:07:26,376:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:07:26,376:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:07:26,376:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:07:26,377:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:07:27,411:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:07:27,412:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:07:27,412:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:07:27,413:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:07:27,413:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:07:29,605:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:07:29,605:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:07:29,605:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:07:29,606:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:07:29,606:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:07:38,633:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:07:38,635:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:07:38,635:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:07:38,635:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:07:38,635:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:07:39,521:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:07:39,522:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:07:39,522:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:07:39,522:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:07:39,522:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:07:46,093:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:07:46,094:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:07:46,094:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:07:46,094:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:07:46,094:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:07:56,061:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:07:56,074:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:07:56,077:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:07:56,080:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:07:56,111:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:08:03,866:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:08:03,879:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:08:03,882:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:08:03,884:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:08:03,887:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:08:07,312:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:08:07,325:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:08:07,328:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:08:07,330:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:08:07,333:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:08:09,479:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:08:09,528:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:08:09,532:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:08:09,538:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:08:09,542:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:08:12,222:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:08:12,234:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:08:12,236:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:08:12,239:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:08:12,242:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:08:14,001:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:08:14,016:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:08:14,019:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:08:14,021:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:08:14,024:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:08:17,593:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:08:17,606:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:08:17,608:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:08:17,611:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:08:17,614:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:08:30,947:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:08:30,960:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:08:30,985:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:08:30,999:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:08:31,005:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:08:34,112:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:08:34,124:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:08:34,127:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:08:34,129:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:08:34,132:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:08:35,659:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:08:35,672:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:08:35,675:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:08:35,678:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:08:35,689:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:08:39,042:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:08:39,055:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:08:39,057:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:08:39,060:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:08:39,063:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:08:49,869:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:08:49,881:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:08:49,884:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:08:49,887:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:08:49,890:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:09:01,071:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:09:01,084:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:09:01,087:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:09:01,090:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:09:01,125:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:09:09,861:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:09:09,876:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:09:09,879:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:09:09,882:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:09:09,885:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:09:14,146:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:09:14,163:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:09:14,195:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:09:14,199:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:09:14,205:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:09:17,364:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:09:17,378:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:09:17,381:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:09:17,397:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:09:17,419:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:09:20,661:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:09:20,674:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:09:20,677:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:09:20,680:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:09:20,683:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:09:24,540:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:09:24,554:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:09:24,557:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:09:24,559:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:09:24,562:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:09:27,512:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:09:27,525:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:09:27,528:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:09:27,531:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:09:27,533:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:09:30,098:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:09:30,112:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:09:30,115:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:09:30,120:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:09:30,139:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:09:34,070:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:09:34,085:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:09:34,088:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:09:34,090:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:09:34,102:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:09:38,167:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:09:38,202:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:09:38,218:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:09:38,223:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:09:38,227:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:09:48,258:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:09:48,272:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:09:48,310:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:09:48,315:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:09:48,320:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:02,117:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:02,168:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:02,174:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:02,179:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:02,182:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:09,838:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:09,852:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:09,855:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:09,896:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:09,900:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:23,841:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:23,855:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:23,858:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:23,893:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:23,896:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:28,829:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:28,882:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:28,885:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:28,892:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:28,896:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:35,207:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:35,247:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:35,260:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:35,264:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:35,270:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:38,262:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:38,277:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:38,280:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:38,287:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:38,319:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:41,715:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:41,731:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:41,742:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:41,767:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:41,772:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:45,059:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:45,074:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:45,077:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:45,092:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:45,117:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:46,601:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:46,648:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:46,656:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:46,664:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:46,667:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:48,136:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:48,150:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:48,153:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:48,156:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:48,159:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:49,697:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:49,712:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:49,715:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:49,727:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:49,752:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:51,466:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:51,486:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:51,512:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:51,518:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:51,527:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:52,835:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:52,850:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:52,861:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:52,887:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:52,891:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:54,928:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:54,945:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:54,951:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:54,979:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:54,987:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:56,845:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:56,870:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:56,894:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:56,898:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:56,905:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:10:58,679:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:10:58,694:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:10:58,698:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:10:58,708:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:10:58,717:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:00,239:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:00,254:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:00,264:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:00,287:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:00,293:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:01,513:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:01,543:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:01,561:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:01,565:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:01,573:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:03,606:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:03,624:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:03,638:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:03,658:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:03,664:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:05,001:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:05,016:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:05,021:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:05,044:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:05,055:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:06,374:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:06,392:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:06,412:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:06,428:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:06,432:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:07,786:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:07,802:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:07,818:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:07,839:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:07,843:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:09,486:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:09,509:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:09,527:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:09,540:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:09,546:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:12,097:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:12,114:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:12,117:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:12,129:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:12,154:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:13,553:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:13,588:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:13,603:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:13,608:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:13,613:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:14,409:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:14,424:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:14,427:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:14,463:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:14,474:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:16,893:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:16,909:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:16,911:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:16,943:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:16,950:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:20,427:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:20,446:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:20,455:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:20,484:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:20,488:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:23,829:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:23,845:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:23,848:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:23,873:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:23,887:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:24,749:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:24,765:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:24,768:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:24,804:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:24,808:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:26,035:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:26,057:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:26,072:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:26,097:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:26,112:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:27,681:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:27,697:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:27,700:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:27,703:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:27,730:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:28,602:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:28,618:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:28,621:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:28,625:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:28,660:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:30,648:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:30,664:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:30,671:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:30,674:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:30,708:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:32,594:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:32,610:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:32,613:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:32,633:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:32,651:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:34,274:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:34,341:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:34,344:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:34,348:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:34,351:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:35,431:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:35,490:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:35,494:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:35,497:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:35,500:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:36,410:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:36,427:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:36,445:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:36,471:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:36,476:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:37,432:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:37,448:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:37,451:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:37,490:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:37,494:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:38,426:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:38,480:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:38,484:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:38,491:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:38,495:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:39,486:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:39,503:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:39,506:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:39,523:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:39,543:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:40,914:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:40,930:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:40,933:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:40,970:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:40,974:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:42,021:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:42,041:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:42,054:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:42,080:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:42,089:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:43,318:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:43,336:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:43,362:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:43,374:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:43,381:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:44,737:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:44,753:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:44,756:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:44,779:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:44,794:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:45,785:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:45,805:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:45,822:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:45,849:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:45,858:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:46,964:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:46,979:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:46,983:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:46,987:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:47,006:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:47,772:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:47,806:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:47,824:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:47,829:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:47,834:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:48,807:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:48,835:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:48,854:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:48,866:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:48,873:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:49,712:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:49,733:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:49,747:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:49,778:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:49,782:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:50,692:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:50,711:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:50,740:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:50,747:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:50,753:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:51,877:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:51,936:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:51,941:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:51,945:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:51,947:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:52,960:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:52,976:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:53,000:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:53,016:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:53,022:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:53,830:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:53,856:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:53,886:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:53,904:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:53,908:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:54,678:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:54,695:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:54,698:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:54,736:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:54,742:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:55,585:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:55,610:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:55,638:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:55,644:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:55,691:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:56,549:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:56,602:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:56,610:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:56,615:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:56,619:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:57,579:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:57,596:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:57,599:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:57,602:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:57,642:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:11:59,013:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:11:59,145:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:11:59,153:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:11:59,164:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:11:59,171:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:12:00,341:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:12:00,410:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:12:00,414:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:12:00,419:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:12:00,423:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:12:01,782:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:12:01,843:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:12:01,853:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:12:01,856:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:12:01,859:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:12:02,891:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:12:02,951:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:12:02,955:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:12:02,960:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:12:02,964:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:12:03,842:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:12:03,900:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:12:03,904:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:12:03,910:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:12:03,914:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:12:04,961:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:12:05,015:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:12:05,025:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:12:05,030:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:12:05,034:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:12:05,992:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:12:06,021:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:12:06,049:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:12:06,067:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:12:06,071:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:12:07,172:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:12:07,233:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:12:07,237:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:12:07,240:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:12:07,243:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:12:08,370:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform("learning_rate", 1e-4, 1.0)

2024-12-17 02:12:08,438:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l1 = trial.suggest_loguniform("lambda_l1", 1e-4, 10.0)

2024-12-17 02:12:08,442:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  lambda_l2 = trial.suggest_loguniform("lambda_l2", 1e-4, 10.0)

2024-12-17 02:12:08,445:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  feature_fraction = trial.suggest_uniform("feature_fraction", 0.1, 1.0)

2024-12-17 02:12:08,449:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_58100/2042666991.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.
  bagging_fraction = trial.suggest_uniform("bagging_fraction", 0.1, 1.0)

2024-12-17 02:31:12,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-17 02:31:12,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-17 02:31:12,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-17 02:31:12,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-12-17 02:31:13,147:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-12-17 02:31:16,065:INFO:PyCaret RegressionExperiment
2024-12-17 02:31:16,065:INFO:Logging name: reg-default-name
2024-12-17 02:31:16,065:INFO:ML Usecase: MLUsecase.REGRESSION
2024-12-17 02:31:16,065:INFO:version 3.0.0
2024-12-17 02:31:16,065:INFO:Initializing setup()
2024-12-17 02:31:16,065:INFO:self.USI: 2a03
2024-12-17 02:31:16,065:INFO:self._variable_keys: {'fold_groups_param', 'memory', 'n_jobs_param', 'html_param', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'y_test', 'pipeline', 'exp_name_log', 'X', 'X_train', '_ml_usecase', 'fold_generator', 'logging_param', 'idx', 'y', 'transform_target_param', 'log_plots_param', 'X_test', 'y_train', 'exp_id', 'fold_shuffle_param', 'seed', '_available_plots', 'target_param', 'data'}
2024-12-17 02:31:16,065:INFO:Checking environment
2024-12-17 02:31:16,065:INFO:python_version: 3.9.20
2024-12-17 02:31:16,065:INFO:python_build: ('main', 'Sep  6 2024 19:03:56')
2024-12-17 02:31:16,065:INFO:machine: arm64
2024-12-17 02:31:16,065:INFO:platform: macOS-15.1.1-arm64-arm-64bit
2024-12-17 02:31:16,065:INFO:Memory: svmem(total=8589934592, available=1641463808, percent=80.9, used=2979938304, free=67731456, active=1593622528, inactive=1466417152, wired=1386315776)
2024-12-17 02:31:16,065:INFO:Physical Core: 8
2024-12-17 02:31:16,066:INFO:Logical Core: 8
2024-12-17 02:31:16,066:INFO:Checking libraries
2024-12-17 02:31:16,066:INFO:System:
2024-12-17 02:31:16,066:INFO:    python: 3.9.20 (main, Sep  6 2024, 19:03:56)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-12-17 02:31:16,066:INFO:executable: /Users/abhishek/tensorflow-test/env/bin/python
2024-12-17 02:31:16,066:INFO:   machine: macOS-15.1.1-arm64-arm-64bit
2024-12-17 02:31:16,066:INFO:PyCaret required dependencies:
2024-12-17 02:31:16,066:INFO:                 pip: 24.3.1
2024-12-17 02:31:16,066:INFO:          setuptools: 75.1.0
2024-12-17 02:31:16,066:INFO:             pycaret: 3.0.0
2024-12-17 02:31:16,066:INFO:             IPython: 8.12.3
2024-12-17 02:31:16,066:INFO:          ipywidgets: 8.1.5
2024-12-17 02:31:16,066:INFO:                tqdm: 4.66.5
2024-12-17 02:31:16,066:INFO:               numpy: 1.24.4
2024-12-17 02:31:16,066:INFO:              pandas: 1.5.3
2024-12-17 02:31:16,066:INFO:              jinja2: 3.1.4
2024-12-17 02:31:16,066:INFO:               scipy: 1.11.4
2024-12-17 02:31:16,066:INFO:              joblib: 1.3.2
2024-12-17 02:31:16,066:INFO:             sklearn: 1.0.2
2024-12-17 02:31:16,066:INFO:                pyod: 2.0.2
2024-12-17 02:31:16,066:INFO:            imblearn: 0.12.4
2024-12-17 02:31:16,066:INFO:   category_encoders: 2.6.4
2024-12-17 02:31:16,066:INFO:            lightgbm: 4.5.0
2024-12-17 02:31:16,066:INFO:               numba: 0.60.0
2024-12-17 02:31:16,066:INFO:            requests: 2.32.3
2024-12-17 02:31:16,066:INFO:          matplotlib: 3.7.5
2024-12-17 02:31:16,066:INFO:          scikitplot: 0.3.7
2024-12-17 02:31:16,066:INFO:         yellowbrick: 1.5
2024-12-17 02:31:16,066:INFO:              plotly: 5.24.1
2024-12-17 02:31:16,066:INFO:             kaleido: 0.2.1
2024-12-17 02:31:16,066:INFO:         statsmodels: 0.14.3
2024-12-17 02:31:16,066:INFO:              sktime: 0.26.0
2024-12-17 02:31:16,066:INFO:               tbats: 1.1.3
2024-12-17 02:31:16,066:INFO:            pmdarima: 2.0.4
2024-12-17 02:31:16,066:INFO:              psutil: 6.0.0
2024-12-17 02:31:16,066:INFO:PyCaret optional dependencies:
2024-12-17 02:31:16,521:INFO:                shap: Not installed
2024-12-17 02:31:16,521:INFO:           interpret: Not installed
2024-12-17 02:31:16,521:INFO:                umap: Not installed
2024-12-17 02:31:16,521:INFO:    pandas_profiling: Not installed
2024-12-17 02:31:16,521:INFO:  explainerdashboard: Not installed
2024-12-17 02:31:16,521:INFO:             autoviz: Not installed
2024-12-17 02:31:16,521:INFO:           fairlearn: Not installed
2024-12-17 02:31:16,521:INFO:             xgboost: 2.1.2
2024-12-17 02:31:16,521:INFO:            catboost: 1.2.7
2024-12-17 02:31:16,521:INFO:              kmodes: Not installed
2024-12-17 02:31:16,521:INFO:             mlxtend: Not installed
2024-12-17 02:31:16,521:INFO:       statsforecast: Not installed
2024-12-17 02:31:16,521:INFO:        tune_sklearn: Not installed
2024-12-17 02:31:16,521:INFO:                 ray: Not installed
2024-12-17 02:31:16,521:INFO:            hyperopt: Not installed
2024-12-17 02:31:16,521:INFO:              optuna: 4.1.0
2024-12-17 02:31:16,521:INFO:               skopt: Not installed
2024-12-17 02:31:16,521:INFO:              mlflow: Not installed
2024-12-17 02:31:16,521:INFO:              gradio: Not installed
2024-12-17 02:31:16,521:INFO:             fastapi: 0.115.2
2024-12-17 02:31:16,521:INFO:             uvicorn: 0.32.0
2024-12-17 02:31:16,521:INFO:              m2cgen: Not installed
2024-12-17 02:31:16,521:INFO:           evidently: Not installed
2024-12-17 02:31:16,521:INFO:               fugue: Not installed
2024-12-17 02:31:16,521:INFO:           streamlit: 1.39.0
2024-12-17 02:31:16,521:INFO:             prophet: Not installed
2024-12-17 02:31:16,521:INFO:None
2024-12-17 02:31:16,521:INFO:Set up data.
2024-12-17 02:31:16,569:INFO:Set up train/test split.
2024-12-17 02:31:16,575:INFO:Set up index.
2024-12-17 02:31:16,575:INFO:Set up folding strategy.
2024-12-17 02:31:16,575:INFO:Assigning column types.
2024-12-17 02:31:16,579:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-12-17 02:31:16,579:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,582:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,585:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,623:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,652:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,653:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:16,655:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:16,655:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,658:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,661:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,700:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,734:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,734:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:16,736:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:16,736:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-12-17 02:31:16,740:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,783:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,812:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,812:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:16,814:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:16,817:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,820:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,860:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,889:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,890:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:16,892:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:16,892:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-12-17 02:31:16,898:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,936:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,965:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-17 02:31:16,966:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:16,967:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:16,973:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-12-17 02:31:17,011:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-17 02:31:17,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-17 02:31:17,041:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:17,042:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:17,042:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-12-17 02:31:17,087:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-17 02:31:17,116:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-17 02:31:17,116:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:17,117:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:17,162:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-17 02:31:17,191:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-12-17 02:31:17,191:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:17,193:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:17,193:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-12-17 02:31:17,238:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-17 02:31:17,268:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:17,269:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:17,314:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-12-17 02:31:17,346:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:17,348:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:17,348:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-12-17 02:31:17,423:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:17,424:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:17,498:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:17,499:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:17,502:INFO:Preparing preprocessing pipeline...
2024-12-17 02:31:17,502:INFO:Set up simple imputation.
2024-12-17 02:31:17,503:INFO:Set up column name cleaning.
2024-12-17 02:31:17,532:INFO:Finished creating preprocessing pipeline.
2024-12-17 02:31:17,538:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['LotFrontage', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'MasVnrArea', 'BsmtFinSF1',
                                             'BsmtFinSF2', 'BsmtUnfSF',
                                             'TotalBsmtSF', '1stFlrSF',
                                             '2ndFlrSF', 'LowQualFinSF',
                                             'GrLivArea', 'BsmtFul...
                                             'KitchenAbvGr', 'TotRmsAbvGrd',
                                             'Fireplaces', 'GarageYrBlt',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-12-17 02:31:17,538:INFO:Creating final display dataframe.
2024-12-17 02:31:17,661:INFO:Setup _display_container:                     Description             Value
0                    Session id              1096
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 322)
4        Transformed data shape       (1460, 322)
5   Transformed train set shape       (1021, 322)
6    Transformed test set shape        (439, 322)
7              Numeric features               321
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              2a03
2024-12-17 02:31:17,741:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:17,743:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:17,817:INFO:Soft dependency imported: xgboost: 2.1.2
2024-12-17 02:31:17,818:INFO:Soft dependency imported: catboost: 1.2.7
2024-12-17 02:31:17,819:INFO:setup() successfully completed in 1.76s...............
2024-12-17 02:31:17,824:INFO:Initializing compare_models()
2024-12-17 02:31:17,824:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-12-17 02:31:17,824:INFO:Checking exceptions
2024-12-17 02:31:17,826:INFO:Preparing display monitor
2024-12-17 02:31:17,870:INFO:Initializing Linear Regression
2024-12-17 02:31:17,870:INFO:Total runtime is 3.627936045328776e-06 minutes
2024-12-17 02:31:17,872:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:17,873:INFO:Initializing create_model()
2024-12-17 02:31:17,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:17,873:INFO:Checking exceptions
2024-12-17 02:31:17,873:INFO:Importing libraries
2024-12-17 02:31:17,873:INFO:Copying training dataset
2024-12-17 02:31:17,879:INFO:Defining folds
2024-12-17 02:31:17,879:INFO:Declaring metric variables
2024-12-17 02:31:17,881:INFO:Importing untrained model
2024-12-17 02:31:17,883:INFO:Linear Regression Imported successfully
2024-12-17 02:31:17,887:INFO:Starting cross validation
2024-12-17 02:31:17,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:24,028:INFO:Calculating mean and std
2024-12-17 02:31:24,036:INFO:Creating metrics dataframe
2024-12-17 02:31:24,046:INFO:Uploading results into container
2024-12-17 02:31:24,047:INFO:Uploading model into container now
2024-12-17 02:31:24,048:INFO:_master_model_container: 1
2024-12-17 02:31:24,048:INFO:_display_container: 2
2024-12-17 02:31:24,049:INFO:LinearRegression(n_jobs=-1)
2024-12-17 02:31:24,049:INFO:create_model() successfully completed......................................
2024-12-17 02:31:24,202:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:24,202:INFO:Creating metrics dataframe
2024-12-17 02:31:24,208:INFO:Initializing Lasso Regression
2024-12-17 02:31:24,208:INFO:Total runtime is 0.10563824574152629 minutes
2024-12-17 02:31:24,211:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:24,211:INFO:Initializing create_model()
2024-12-17 02:31:24,211:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:24,211:INFO:Checking exceptions
2024-12-17 02:31:24,212:INFO:Importing libraries
2024-12-17 02:31:24,214:INFO:Copying training dataset
2024-12-17 02:31:24,220:INFO:Defining folds
2024-12-17 02:31:24,220:INFO:Declaring metric variables
2024-12-17 02:31:24,222:INFO:Importing untrained model
2024-12-17 02:31:24,225:INFO:Lasso Regression Imported successfully
2024-12-17 02:31:24,231:INFO:Starting cross validation
2024-12-17 02:31:24,233:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:24,556:INFO:Calculating mean and std
2024-12-17 02:31:24,557:INFO:Creating metrics dataframe
2024-12-17 02:31:24,560:INFO:Uploading results into container
2024-12-17 02:31:24,561:INFO:Uploading model into container now
2024-12-17 02:31:24,561:INFO:_master_model_container: 2
2024-12-17 02:31:24,561:INFO:_display_container: 2
2024-12-17 02:31:24,562:INFO:Lasso(random_state=1096)
2024-12-17 02:31:24,562:INFO:create_model() successfully completed......................................
2024-12-17 02:31:24,622:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:24,622:INFO:Creating metrics dataframe
2024-12-17 02:31:24,628:INFO:Initializing Ridge Regression
2024-12-17 02:31:24,628:INFO:Total runtime is 0.11263909737269084 minutes
2024-12-17 02:31:24,631:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:24,631:INFO:Initializing create_model()
2024-12-17 02:31:24,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:24,631:INFO:Checking exceptions
2024-12-17 02:31:24,631:INFO:Importing libraries
2024-12-17 02:31:24,631:INFO:Copying training dataset
2024-12-17 02:31:24,636:INFO:Defining folds
2024-12-17 02:31:24,636:INFO:Declaring metric variables
2024-12-17 02:31:24,638:INFO:Importing untrained model
2024-12-17 02:31:24,640:INFO:Ridge Regression Imported successfully
2024-12-17 02:31:24,644:INFO:Starting cross validation
2024-12-17 02:31:24,646:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:24,872:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: 
10 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/joblib/memory.py", line 655, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 1011, in fit
    return super().fit(X, y, sample_weight=sample_weight)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 782, in fit
    self.coef_, self.n_iter_ = _ridge_regression(
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 599, in _ridge_regression
    coef = _solve_cholesky(X, y, alpha)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 157, in _solve_cholesky
    return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T
TypeError: solve() got an unexpected keyword argument 'sym_pos'

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-12-17 02:31:24,873:INFO:Calculating mean and std
2024-12-17 02:31:24,873:INFO:Creating metrics dataframe
2024-12-17 02:31:24,877:INFO:Uploading results into container
2024-12-17 02:31:24,877:INFO:Uploading model into container now
2024-12-17 02:31:24,878:INFO:_master_model_container: 3
2024-12-17 02:31:24,878:INFO:_display_container: 2
2024-12-17 02:31:24,878:INFO:Ridge(random_state=1096)
2024-12-17 02:31:24,878:INFO:create_model() successfully completed......................................
2024-12-17 02:31:24,937:WARNING:create_model() for Ridge(random_state=1096) raised an exception or returned all 0.0, trying without fit_kwargs:
2024-12-17 02:31:24,939:WARNING:Traceback (most recent call last):
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2024-12-17 02:31:24,940:INFO:Initializing create_model()
2024-12-17 02:31:24,940:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:24,940:INFO:Checking exceptions
2024-12-17 02:31:24,940:INFO:Importing libraries
2024-12-17 02:31:24,940:INFO:Copying training dataset
2024-12-17 02:31:24,943:INFO:Defining folds
2024-12-17 02:31:24,943:INFO:Declaring metric variables
2024-12-17 02:31:24,945:INFO:Importing untrained model
2024-12-17 02:31:24,948:INFO:Ridge Regression Imported successfully
2024-12-17 02:31:24,952:INFO:Starting cross validation
2024-12-17 02:31:24,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:25,185:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: 
10 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/joblib/memory.py", line 655, in __call__
    return self._cached_call(args, kwargs)[0]
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 1011, in fit
    return super().fit(X, y, sample_weight=sample_weight)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 782, in fit
    self.coef_, self.n_iter_ = _ridge_regression(
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 599, in _ridge_regression
    coef = _solve_cholesky(X, y, alpha)
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py", line 157, in _solve_cholesky
    return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T
TypeError: solve() got an unexpected keyword argument 'sym_pos'

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-12-17 02:31:25,188:INFO:Calculating mean and std
2024-12-17 02:31:25,191:INFO:Creating metrics dataframe
2024-12-17 02:31:25,199:INFO:Uploading results into container
2024-12-17 02:31:25,199:INFO:Uploading model into container now
2024-12-17 02:31:25,199:INFO:_master_model_container: 4
2024-12-17 02:31:25,199:INFO:_display_container: 2
2024-12-17 02:31:25,200:INFO:Ridge(random_state=1096)
2024-12-17 02:31:25,200:INFO:create_model() successfully completed......................................
2024-12-17 02:31:25,324:ERROR:create_model() for Ridge(random_state=1096) raised an exception or returned all 0.0:
2024-12-17 02:31:25,324:ERROR:Traceback (most recent call last):
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 812, in compare_models
    assert (
AssertionError

2024-12-17 02:31:25,324:INFO:Initializing Elastic Net
2024-12-17 02:31:25,324:INFO:Total runtime is 0.12423743009567262 minutes
2024-12-17 02:31:25,327:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:25,327:INFO:Initializing create_model()
2024-12-17 02:31:25,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:25,327:INFO:Checking exceptions
2024-12-17 02:31:25,327:INFO:Importing libraries
2024-12-17 02:31:25,327:INFO:Copying training dataset
2024-12-17 02:31:25,332:INFO:Defining folds
2024-12-17 02:31:25,332:INFO:Declaring metric variables
2024-12-17 02:31:25,334:INFO:Importing untrained model
2024-12-17 02:31:25,337:INFO:Elastic Net Imported successfully
2024-12-17 02:31:25,341:INFO:Starting cross validation
2024-12-17 02:31:25,343:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:25,672:INFO:Calculating mean and std
2024-12-17 02:31:25,673:INFO:Creating metrics dataframe
2024-12-17 02:31:25,676:INFO:Uploading results into container
2024-12-17 02:31:25,676:INFO:Uploading model into container now
2024-12-17 02:31:25,677:INFO:_master_model_container: 5
2024-12-17 02:31:25,677:INFO:_display_container: 2
2024-12-17 02:31:25,677:INFO:ElasticNet(random_state=1096)
2024-12-17 02:31:25,677:INFO:create_model() successfully completed......................................
2024-12-17 02:31:25,736:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:25,736:INFO:Creating metrics dataframe
2024-12-17 02:31:25,742:INFO:Initializing Least Angle Regression
2024-12-17 02:31:25,742:INFO:Total runtime is 0.13119784593582154 minutes
2024-12-17 02:31:25,744:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:25,744:INFO:Initializing create_model()
2024-12-17 02:31:25,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:25,745:INFO:Checking exceptions
2024-12-17 02:31:25,745:INFO:Importing libraries
2024-12-17 02:31:25,745:INFO:Copying training dataset
2024-12-17 02:31:25,750:INFO:Defining folds
2024-12-17 02:31:25,750:INFO:Declaring metric variables
2024-12-17 02:31:25,752:INFO:Importing untrained model
2024-12-17 02:31:25,754:INFO:Least Angle Regression Imported successfully
2024-12-17 02:31:25,758:INFO:Starting cross validation
2024-12-17 02:31:25,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:25,824:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:25,832:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:25,835:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.235e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,835:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:25,837:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=5.474e-04, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,837:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=5.041e-04, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,837:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:25,841:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=3.433e-04, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,843:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.498e-04, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,845:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.407e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,845:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.803e-04, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,846:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.899e-04, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,846:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.712e-04, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,847:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=3.552e-04, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,847:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:25,851:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=1.389e-04, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,851:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=8.639e-04, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,851:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=1.370e-04, with an active set of 113 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,851:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:25,862:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.631e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,863:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=7.362e-04, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,865:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=4.824e-04, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,867:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=1.641e-03, with an active set of 171 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,872:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=5.827e-04, with an active set of 111 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,874:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 137 iterations, i.e. alpha=5.460e-04, with an active set of 123 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,875:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:25,877:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.007e-04, with an active set of 146 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,885:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=6.036e-04, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,886:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:25,895:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=5.860e-04, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,897:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=4.297e-04, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,899:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.272e-04, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,900:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-17 02:31:25,903:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=2.805e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,905:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=2.217e-04, with an active set of 76 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,909:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=8.808e-04, with an active set of 185 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2024-12-17 02:31:25,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2024-12-17 02:31:25,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2024-12-17 02:31:25,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2024-12-17 02:31:25,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:739: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2024-12-17 02:31:25,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:739: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2024-12-17 02:31:25,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: divide by zero encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2024-12-17 02:31:25,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: divide by zero encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2024-12-17 02:31:25,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-17 02:31:25,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-17 02:31:25,935:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2024-12-17 02:31:25,935:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2024-12-17 02:31:25,935:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:739: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2024-12-17 02:31:25,935:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: divide by zero encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2024-12-17 02:31:25,935:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-17 02:31:25,939:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 401 iterations, i.e. alpha=2.665e+01, with an active set of 266 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,950:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-17 02:31:25,952:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2024-12-17 02:31:25,953:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2024-12-17 02:31:25,953:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: divide by zero encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2024-12-17 02:31:25,953:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-17 02:31:25,970:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 453 iterations, i.e. alpha=1.186e+02, with an active set of 308 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,971:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 454 iterations, i.e. alpha=1.031e+02, with an active set of 309 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:25,971:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 455 iterations, i.e. alpha=9.146e+01, with an active set of 310 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:26,144:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-17 02:31:26,145:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-17 02:31:26,145:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2024-12-17 02:31:26,242:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:26,267:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 39 iterations, i.e. alpha=5.209e-04, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:26,368:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce
  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)

2024-12-17 02:31:26,368:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:735: RuntimeWarning: overflow encountered in divide
  g1 = arrayfuncs.min_pos((C - Cov) / (AA - corr_eq_dir + tiny32))

2024-12-17 02:31:26,368:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:739: RuntimeWarning: overflow encountered in divide
  g2 = arrayfuncs.min_pos((C + Cov) / (AA + corr_eq_dir + tiny32))

2024-12-17 02:31:26,368:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:740: RuntimeWarning: divide by zero encountered in scalar divide
  gamma_ = min(g1, g2, C / AA)

2024-12-17 02:31:26,369:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:744: RuntimeWarning: overflow encountered in divide
  z = -coef[active] / (least_squares + tiny32)

2024-12-17 02:31:26,438:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-17 02:31:26,438:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-17 02:31:26,438:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2024-12-17 02:31:26,458:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-17 02:31:26,459:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2024-12-17 02:31:26,459:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-17 02:31:26,459:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)

2024-12-17 02:31:26,460:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2024-12-17 02:31:26,473:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:26,480:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-17 02:31:26,480:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-17 02:31:26,481:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2024-12-17 02:31:26,485:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=7.326e-04, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:26,488:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=4.063e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-12-17 02:31:26,695:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-17 02:31:26,695:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:442: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2024-12-17 02:31:26,696:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/metrics/_regression.py:805: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2024-12-17 02:31:26,802:INFO:Calculating mean and std
2024-12-17 02:31:26,803:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/numpy/core/_methods.py:236: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2024-12-17 02:31:26,805:INFO:Creating metrics dataframe
2024-12-17 02:31:26,817:INFO:Uploading results into container
2024-12-17 02:31:26,817:INFO:Uploading model into container now
2024-12-17 02:31:26,818:INFO:_master_model_container: 6
2024-12-17 02:31:26,818:INFO:_display_container: 2
2024-12-17 02:31:26,818:INFO:Lars(random_state=1096)
2024-12-17 02:31:26,818:INFO:create_model() successfully completed......................................
2024-12-17 02:31:26,927:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:26,927:INFO:Creating metrics dataframe
2024-12-17 02:31:26,934:INFO:Initializing Lasso Least Angle Regression
2024-12-17 02:31:26,934:INFO:Total runtime is 0.15106046199798584 minutes
2024-12-17 02:31:26,936:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:26,936:INFO:Initializing create_model()
2024-12-17 02:31:26,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:26,937:INFO:Checking exceptions
2024-12-17 02:31:26,937:INFO:Importing libraries
2024-12-17 02:31:26,937:INFO:Copying training dataset
2024-12-17 02:31:26,942:INFO:Defining folds
2024-12-17 02:31:26,942:INFO:Declaring metric variables
2024-12-17 02:31:26,944:INFO:Importing untrained model
2024-12-17 02:31:26,947:INFO:Lasso Least Angle Regression Imported successfully
2024-12-17 02:31:26,951:INFO:Starting cross validation
2024-12-17 02:31:26,952:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:27,019:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-17 02:31:27,022:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-17 02:31:27,029:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-17 02:31:27,046:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-17 02:31:27,065:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-17 02:31:27,067:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-17 02:31:27,081:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-17 02:31:27,089:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-17 02:31:27,136:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-17 02:31:27,138:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2024-12-17 02:31:27,284:INFO:Calculating mean and std
2024-12-17 02:31:27,285:INFO:Creating metrics dataframe
2024-12-17 02:31:27,290:INFO:Uploading results into container
2024-12-17 02:31:27,290:INFO:Uploading model into container now
2024-12-17 02:31:27,291:INFO:_master_model_container: 7
2024-12-17 02:31:27,291:INFO:_display_container: 2
2024-12-17 02:31:27,291:INFO:LassoLars(random_state=1096)
2024-12-17 02:31:27,291:INFO:create_model() successfully completed......................................
2024-12-17 02:31:27,363:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:27,363:INFO:Creating metrics dataframe
2024-12-17 02:31:27,370:INFO:Initializing Orthogonal Matching Pursuit
2024-12-17 02:31:27,370:INFO:Total runtime is 0.15832892656326295 minutes
2024-12-17 02:31:27,372:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:27,372:INFO:Initializing create_model()
2024-12-17 02:31:27,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:27,373:INFO:Checking exceptions
2024-12-17 02:31:27,373:INFO:Importing libraries
2024-12-17 02:31:27,373:INFO:Copying training dataset
2024-12-17 02:31:27,377:INFO:Defining folds
2024-12-17 02:31:27,377:INFO:Declaring metric variables
2024-12-17 02:31:27,379:INFO:Importing untrained model
2024-12-17 02:31:27,381:INFO:Orthogonal Matching Pursuit Imported successfully
2024-12-17 02:31:27,385:INFO:Starting cross validation
2024-12-17 02:31:27,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:27,440:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:27,443:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:27,450:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:27,460:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:27,472:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:27,483:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:27,490:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:27,496:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:27,544:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:27,545:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:31:27,703:INFO:Calculating mean and std
2024-12-17 02:31:27,704:INFO:Creating metrics dataframe
2024-12-17 02:31:27,709:INFO:Uploading results into container
2024-12-17 02:31:27,709:INFO:Uploading model into container now
2024-12-17 02:31:27,709:INFO:_master_model_container: 8
2024-12-17 02:31:27,710:INFO:_display_container: 2
2024-12-17 02:31:27,710:INFO:OrthogonalMatchingPursuit()
2024-12-17 02:31:27,710:INFO:create_model() successfully completed......................................
2024-12-17 02:31:27,772:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:27,772:INFO:Creating metrics dataframe
2024-12-17 02:31:27,778:INFO:Initializing Bayesian Ridge
2024-12-17 02:31:27,778:INFO:Total runtime is 0.16513843139012654 minutes
2024-12-17 02:31:27,781:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:27,781:INFO:Initializing create_model()
2024-12-17 02:31:27,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:27,781:INFO:Checking exceptions
2024-12-17 02:31:27,781:INFO:Importing libraries
2024-12-17 02:31:27,781:INFO:Copying training dataset
2024-12-17 02:31:27,786:INFO:Defining folds
2024-12-17 02:31:27,786:INFO:Declaring metric variables
2024-12-17 02:31:27,788:INFO:Importing untrained model
2024-12-17 02:31:27,790:INFO:Bayesian Ridge Imported successfully
2024-12-17 02:31:27,793:INFO:Starting cross validation
2024-12-17 02:31:27,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:28,613:INFO:Calculating mean and std
2024-12-17 02:31:28,614:INFO:Creating metrics dataframe
2024-12-17 02:31:28,620:INFO:Uploading results into container
2024-12-17 02:31:28,620:INFO:Uploading model into container now
2024-12-17 02:31:28,620:INFO:_master_model_container: 9
2024-12-17 02:31:28,620:INFO:_display_container: 2
2024-12-17 02:31:28,621:INFO:BayesianRidge()
2024-12-17 02:31:28,621:INFO:create_model() successfully completed......................................
2024-12-17 02:31:28,683:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:28,683:INFO:Creating metrics dataframe
2024-12-17 02:31:28,690:INFO:Initializing Passive Aggressive Regressor
2024-12-17 02:31:28,690:INFO:Total runtime is 0.18033891121546428 minutes
2024-12-17 02:31:28,693:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:28,693:INFO:Initializing create_model()
2024-12-17 02:31:28,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:28,694:INFO:Checking exceptions
2024-12-17 02:31:28,694:INFO:Importing libraries
2024-12-17 02:31:28,694:INFO:Copying training dataset
2024-12-17 02:31:28,735:INFO:Defining folds
2024-12-17 02:31:28,735:INFO:Declaring metric variables
2024-12-17 02:31:28,745:INFO:Importing untrained model
2024-12-17 02:31:28,748:INFO:Passive Aggressive Regressor Imported successfully
2024-12-17 02:31:28,754:INFO:Starting cross validation
2024-12-17 02:31:28,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:29,162:INFO:Calculating mean and std
2024-12-17 02:31:29,163:INFO:Creating metrics dataframe
2024-12-17 02:31:29,169:INFO:Uploading results into container
2024-12-17 02:31:29,169:INFO:Uploading model into container now
2024-12-17 02:31:29,169:INFO:_master_model_container: 10
2024-12-17 02:31:29,169:INFO:_display_container: 2
2024-12-17 02:31:29,169:INFO:PassiveAggressiveRegressor(random_state=1096)
2024-12-17 02:31:29,169:INFO:create_model() successfully completed......................................
2024-12-17 02:31:29,226:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:29,226:INFO:Creating metrics dataframe
2024-12-17 02:31:29,233:INFO:Initializing Huber Regressor
2024-12-17 02:31:29,233:INFO:Total runtime is 0.189388378461202 minutes
2024-12-17 02:31:29,235:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:29,236:INFO:Initializing create_model()
2024-12-17 02:31:29,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:29,236:INFO:Checking exceptions
2024-12-17 02:31:29,236:INFO:Importing libraries
2024-12-17 02:31:29,236:INFO:Copying training dataset
2024-12-17 02:31:29,241:INFO:Defining folds
2024-12-17 02:31:29,241:INFO:Declaring metric variables
2024-12-17 02:31:29,243:INFO:Importing untrained model
2024-12-17 02:31:29,245:INFO:Huber Regressor Imported successfully
2024-12-17 02:31:29,249:INFO:Starting cross validation
2024-12-17 02:31:29,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:29,890:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-17 02:31:29,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-17 02:31:29,941:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-17 02:31:29,943:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-17 02:31:29,950:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-17 02:31:29,964:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-17 02:31:29,964:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-17 02:31:30,006:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-17 02:31:30,398:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-17 02:31:30,409:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-12-17 02:31:30,602:INFO:Calculating mean and std
2024-12-17 02:31:30,602:INFO:Creating metrics dataframe
2024-12-17 02:31:30,610:INFO:Uploading results into container
2024-12-17 02:31:30,610:INFO:Uploading model into container now
2024-12-17 02:31:30,611:INFO:_master_model_container: 11
2024-12-17 02:31:30,611:INFO:_display_container: 2
2024-12-17 02:31:30,611:INFO:HuberRegressor()
2024-12-17 02:31:30,611:INFO:create_model() successfully completed......................................
2024-12-17 02:31:30,673:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:30,673:INFO:Creating metrics dataframe
2024-12-17 02:31:30,681:INFO:Initializing K Neighbors Regressor
2024-12-17 02:31:30,681:INFO:Total runtime is 0.21351112922032675 minutes
2024-12-17 02:31:30,683:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:30,683:INFO:Initializing create_model()
2024-12-17 02:31:30,683:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:30,683:INFO:Checking exceptions
2024-12-17 02:31:30,683:INFO:Importing libraries
2024-12-17 02:31:30,683:INFO:Copying training dataset
2024-12-17 02:31:30,688:INFO:Defining folds
2024-12-17 02:31:30,688:INFO:Declaring metric variables
2024-12-17 02:31:30,690:INFO:Importing untrained model
2024-12-17 02:31:30,692:INFO:K Neighbors Regressor Imported successfully
2024-12-17 02:31:30,697:INFO:Starting cross validation
2024-12-17 02:31:30,699:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:31,055:INFO:Calculating mean and std
2024-12-17 02:31:31,056:INFO:Creating metrics dataframe
2024-12-17 02:31:31,063:INFO:Uploading results into container
2024-12-17 02:31:31,063:INFO:Uploading model into container now
2024-12-17 02:31:31,063:INFO:_master_model_container: 12
2024-12-17 02:31:31,063:INFO:_display_container: 2
2024-12-17 02:31:31,064:INFO:KNeighborsRegressor(n_jobs=-1)
2024-12-17 02:31:31,064:INFO:create_model() successfully completed......................................
2024-12-17 02:31:31,124:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:31,124:INFO:Creating metrics dataframe
2024-12-17 02:31:31,131:INFO:Initializing Decision Tree Regressor
2024-12-17 02:31:31,131:INFO:Total runtime is 0.2210210124651591 minutes
2024-12-17 02:31:31,134:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:31,134:INFO:Initializing create_model()
2024-12-17 02:31:31,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:31,134:INFO:Checking exceptions
2024-12-17 02:31:31,134:INFO:Importing libraries
2024-12-17 02:31:31,135:INFO:Copying training dataset
2024-12-17 02:31:31,138:INFO:Defining folds
2024-12-17 02:31:31,138:INFO:Declaring metric variables
2024-12-17 02:31:31,140:INFO:Importing untrained model
2024-12-17 02:31:31,142:INFO:Decision Tree Regressor Imported successfully
2024-12-17 02:31:31,146:INFO:Starting cross validation
2024-12-17 02:31:31,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:31,526:INFO:Calculating mean and std
2024-12-17 02:31:31,527:INFO:Creating metrics dataframe
2024-12-17 02:31:31,534:INFO:Uploading results into container
2024-12-17 02:31:31,534:INFO:Uploading model into container now
2024-12-17 02:31:31,535:INFO:_master_model_container: 13
2024-12-17 02:31:31,535:INFO:_display_container: 2
2024-12-17 02:31:31,535:INFO:DecisionTreeRegressor(random_state=1096)
2024-12-17 02:31:31,535:INFO:create_model() successfully completed......................................
2024-12-17 02:31:31,594:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:31,594:INFO:Creating metrics dataframe
2024-12-17 02:31:31,602:INFO:Initializing Random Forest Regressor
2024-12-17 02:31:31,602:INFO:Total runtime is 0.22886314392089843 minutes
2024-12-17 02:31:31,604:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:31,604:INFO:Initializing create_model()
2024-12-17 02:31:31,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:31,605:INFO:Checking exceptions
2024-12-17 02:31:31,605:INFO:Importing libraries
2024-12-17 02:31:31,605:INFO:Copying training dataset
2024-12-17 02:31:31,609:INFO:Defining folds
2024-12-17 02:31:31,609:INFO:Declaring metric variables
2024-12-17 02:31:31,611:INFO:Importing untrained model
2024-12-17 02:31:31,613:INFO:Random Forest Regressor Imported successfully
2024-12-17 02:31:31,617:INFO:Starting cross validation
2024-12-17 02:31:31,619:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:36,324:INFO:Calculating mean and std
2024-12-17 02:31:36,325:INFO:Creating metrics dataframe
2024-12-17 02:31:36,336:INFO:Uploading results into container
2024-12-17 02:31:36,336:INFO:Uploading model into container now
2024-12-17 02:31:36,337:INFO:_master_model_container: 14
2024-12-17 02:31:36,337:INFO:_display_container: 2
2024-12-17 02:31:36,337:INFO:RandomForestRegressor(n_jobs=-1, random_state=1096)
2024-12-17 02:31:36,337:INFO:create_model() successfully completed......................................
2024-12-17 02:31:36,401:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:36,401:INFO:Creating metrics dataframe
2024-12-17 02:31:36,408:INFO:Initializing Extra Trees Regressor
2024-12-17 02:31:36,409:INFO:Total runtime is 0.3089765270551046 minutes
2024-12-17 02:31:36,411:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:36,411:INFO:Initializing create_model()
2024-12-17 02:31:36,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:36,412:INFO:Checking exceptions
2024-12-17 02:31:36,412:INFO:Importing libraries
2024-12-17 02:31:36,412:INFO:Copying training dataset
2024-12-17 02:31:36,416:INFO:Defining folds
2024-12-17 02:31:36,416:INFO:Declaring metric variables
2024-12-17 02:31:36,418:INFO:Importing untrained model
2024-12-17 02:31:36,420:INFO:Extra Trees Regressor Imported successfully
2024-12-17 02:31:36,424:INFO:Starting cross validation
2024-12-17 02:31:36,425:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:37,439:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_transform(

2024-12-17 02:31:40,033:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2024-12-17 02:31:41,613:INFO:Calculating mean and std
2024-12-17 02:31:41,614:INFO:Creating metrics dataframe
2024-12-17 02:31:41,624:INFO:Uploading results into container
2024-12-17 02:31:41,625:INFO:Uploading model into container now
2024-12-17 02:31:41,625:INFO:_master_model_container: 15
2024-12-17 02:31:41,625:INFO:_display_container: 2
2024-12-17 02:31:41,625:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1096)
2024-12-17 02:31:41,625:INFO:create_model() successfully completed......................................
2024-12-17 02:31:41,706:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:41,706:INFO:Creating metrics dataframe
2024-12-17 02:31:41,714:INFO:Initializing AdaBoost Regressor
2024-12-17 02:31:41,714:INFO:Total runtime is 0.39740706284840904 minutes
2024-12-17 02:31:41,720:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:41,721:INFO:Initializing create_model()
2024-12-17 02:31:41,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:41,722:INFO:Checking exceptions
2024-12-17 02:31:41,722:INFO:Importing libraries
2024-12-17 02:31:41,723:INFO:Copying training dataset
2024-12-17 02:31:41,753:INFO:Defining folds
2024-12-17 02:31:41,753:INFO:Declaring metric variables
2024-12-17 02:31:41,758:INFO:Importing untrained model
2024-12-17 02:31:41,761:INFO:AdaBoost Regressor Imported successfully
2024-12-17 02:31:41,765:INFO:Starting cross validation
2024-12-17 02:31:41,767:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:43,771:INFO:Calculating mean and std
2024-12-17 02:31:43,773:INFO:Creating metrics dataframe
2024-12-17 02:31:43,784:INFO:Uploading results into container
2024-12-17 02:31:43,785:INFO:Uploading model into container now
2024-12-17 02:31:43,785:INFO:_master_model_container: 16
2024-12-17 02:31:43,785:INFO:_display_container: 2
2024-12-17 02:31:43,785:INFO:AdaBoostRegressor(random_state=1096)
2024-12-17 02:31:43,785:INFO:create_model() successfully completed......................................
2024-12-17 02:31:43,844:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:43,844:INFO:Creating metrics dataframe
2024-12-17 02:31:43,852:INFO:Initializing Gradient Boosting Regressor
2024-12-17 02:31:43,852:INFO:Total runtime is 0.4330351948738098 minutes
2024-12-17 02:31:43,854:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:43,855:INFO:Initializing create_model()
2024-12-17 02:31:43,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:43,855:INFO:Checking exceptions
2024-12-17 02:31:43,855:INFO:Importing libraries
2024-12-17 02:31:43,855:INFO:Copying training dataset
2024-12-17 02:31:43,859:INFO:Defining folds
2024-12-17 02:31:43,859:INFO:Declaring metric variables
2024-12-17 02:31:43,861:INFO:Importing untrained model
2024-12-17 02:31:43,863:INFO:Gradient Boosting Regressor Imported successfully
2024-12-17 02:31:43,867:INFO:Starting cross validation
2024-12-17 02:31:43,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:46,478:INFO:Calculating mean and std
2024-12-17 02:31:46,480:INFO:Creating metrics dataframe
2024-12-17 02:31:46,497:INFO:Uploading results into container
2024-12-17 02:31:46,498:INFO:Uploading model into container now
2024-12-17 02:31:46,498:INFO:_master_model_container: 17
2024-12-17 02:31:46,498:INFO:_display_container: 2
2024-12-17 02:31:46,498:INFO:GradientBoostingRegressor(random_state=1096)
2024-12-17 02:31:46,498:INFO:create_model() successfully completed......................................
2024-12-17 02:31:46,584:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:46,584:INFO:Creating metrics dataframe
2024-12-17 02:31:46,594:INFO:Initializing Extreme Gradient Boosting
2024-12-17 02:31:46,594:INFO:Total runtime is 0.4787398139635722 minutes
2024-12-17 02:31:46,597:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:46,597:INFO:Initializing create_model()
2024-12-17 02:31:46,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:46,597:INFO:Checking exceptions
2024-12-17 02:31:46,598:INFO:Importing libraries
2024-12-17 02:31:46,598:INFO:Copying training dataset
2024-12-17 02:31:46,603:INFO:Defining folds
2024-12-17 02:31:46,603:INFO:Declaring metric variables
2024-12-17 02:31:46,606:INFO:Importing untrained model
2024-12-17 02:31:46,609:INFO:Extreme Gradient Boosting Imported successfully
2024-12-17 02:31:46,614:INFO:Starting cross validation
2024-12-17 02:31:46,616:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:49,352:INFO:Calculating mean and std
2024-12-17 02:31:49,354:INFO:Creating metrics dataframe
2024-12-17 02:31:49,369:INFO:Uploading results into container
2024-12-17 02:31:49,369:INFO:Uploading model into container now
2024-12-17 02:31:49,369:INFO:_master_model_container: 18
2024-12-17 02:31:49,369:INFO:_display_container: 2
2024-12-17 02:31:49,370:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=1096, ...)
2024-12-17 02:31:49,370:INFO:create_model() successfully completed......................................
2024-12-17 02:31:49,451:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:49,451:INFO:Creating metrics dataframe
2024-12-17 02:31:49,460:INFO:Initializing Light Gradient Boosting Machine
2024-12-17 02:31:49,460:INFO:Total runtime is 0.5265010277430217 minutes
2024-12-17 02:31:49,463:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:49,463:INFO:Initializing create_model()
2024-12-17 02:31:49,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:49,463:INFO:Checking exceptions
2024-12-17 02:31:49,463:INFO:Importing libraries
2024-12-17 02:31:49,464:INFO:Copying training dataset
2024-12-17 02:31:49,469:INFO:Defining folds
2024-12-17 02:31:49,470:INFO:Declaring metric variables
2024-12-17 02:31:49,472:INFO:Importing untrained model
2024-12-17 02:31:49,474:INFO:Light Gradient Boosting Machine Imported successfully
2024-12-17 02:31:49,479:INFO:Starting cross validation
2024-12-17 02:31:49,481:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:31:54,046:INFO:Calculating mean and std
2024-12-17 02:31:54,050:INFO:Creating metrics dataframe
2024-12-17 02:31:54,073:INFO:Uploading results into container
2024-12-17 02:31:54,074:INFO:Uploading model into container now
2024-12-17 02:31:54,074:INFO:_master_model_container: 19
2024-12-17 02:31:54,074:INFO:_display_container: 2
2024-12-17 02:31:54,075:INFO:LGBMRegressor(n_jobs=-1, random_state=1096)
2024-12-17 02:31:54,075:INFO:create_model() successfully completed......................................
2024-12-17 02:31:54,209:INFO:SubProcess create_model() end ==================================
2024-12-17 02:31:54,209:INFO:Creating metrics dataframe
2024-12-17 02:31:54,218:INFO:Initializing CatBoost Regressor
2024-12-17 02:31:54,218:INFO:Total runtime is 0.6058038473129272 minutes
2024-12-17 02:31:54,220:INFO:SubProcess create_model() called ==================================
2024-12-17 02:31:54,221:INFO:Initializing create_model()
2024-12-17 02:31:54,221:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:31:54,221:INFO:Checking exceptions
2024-12-17 02:31:54,221:INFO:Importing libraries
2024-12-17 02:31:54,221:INFO:Copying training dataset
2024-12-17 02:31:54,229:INFO:Defining folds
2024-12-17 02:31:54,229:INFO:Declaring metric variables
2024-12-17 02:31:54,232:INFO:Importing untrained model
2024-12-17 02:31:54,237:INFO:CatBoost Regressor Imported successfully
2024-12-17 02:31:54,241:INFO:Starting cross validation
2024-12-17 02:31:54,243:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:32:15,526:INFO:Calculating mean and std
2024-12-17 02:32:15,531:INFO:Creating metrics dataframe
2024-12-17 02:32:15,558:INFO:Uploading results into container
2024-12-17 02:32:15,559:INFO:Uploading model into container now
2024-12-17 02:32:15,560:INFO:_master_model_container: 20
2024-12-17 02:32:15,560:INFO:_display_container: 2
2024-12-17 02:32:15,560:INFO:<catboost.core.CatBoostRegressor object at 0x30e643970>
2024-12-17 02:32:15,560:INFO:create_model() successfully completed......................................
2024-12-17 02:32:15,696:INFO:SubProcess create_model() end ==================================
2024-12-17 02:32:15,696:INFO:Creating metrics dataframe
2024-12-17 02:32:15,706:INFO:Initializing Dummy Regressor
2024-12-17 02:32:15,706:INFO:Total runtime is 0.9639299472173055 minutes
2024-12-17 02:32:15,709:INFO:SubProcess create_model() called ==================================
2024-12-17 02:32:15,709:INFO:Initializing create_model()
2024-12-17 02:32:15,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3065f4ee0>, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:32:15,709:INFO:Checking exceptions
2024-12-17 02:32:15,709:INFO:Importing libraries
2024-12-17 02:32:15,709:INFO:Copying training dataset
2024-12-17 02:32:15,714:INFO:Defining folds
2024-12-17 02:32:15,714:INFO:Declaring metric variables
2024-12-17 02:32:15,717:INFO:Importing untrained model
2024-12-17 02:32:15,719:INFO:Dummy Regressor Imported successfully
2024-12-17 02:32:15,724:INFO:Starting cross validation
2024-12-17 02:32:15,726:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-12-17 02:32:16,070:INFO:Calculating mean and std
2024-12-17 02:32:16,073:INFO:Creating metrics dataframe
2024-12-17 02:32:16,093:INFO:Uploading results into container
2024-12-17 02:32:16,094:INFO:Uploading model into container now
2024-12-17 02:32:16,094:INFO:_master_model_container: 21
2024-12-17 02:32:16,094:INFO:_display_container: 2
2024-12-17 02:32:16,095:INFO:DummyRegressor()
2024-12-17 02:32:16,095:INFO:create_model() successfully completed......................................
2024-12-17 02:32:16,160:INFO:SubProcess create_model() end ==================================
2024-12-17 02:32:16,160:INFO:Creating metrics dataframe
2024-12-17 02:32:16,175:INFO:Initializing create_model()
2024-12-17 02:32:16,175:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x30653be50>, estimator=<catboost.core.CatBoostRegressor object at 0x30e643970>, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-12-17 02:32:16,175:INFO:Checking exceptions
2024-12-17 02:32:16,176:INFO:Importing libraries
2024-12-17 02:32:16,176:INFO:Copying training dataset
2024-12-17 02:32:16,181:INFO:Defining folds
2024-12-17 02:32:16,181:INFO:Declaring metric variables
2024-12-17 02:32:16,181:INFO:Importing untrained model
2024-12-17 02:32:16,182:INFO:Declaring custom model
2024-12-17 02:32:16,182:INFO:CatBoost Regressor Imported successfully
2024-12-17 02:32:16,183:INFO:Cross validation set to False
2024-12-17 02:32:16,183:INFO:Fitting Model
2024-12-17 02:32:18,793:INFO:<catboost.core.CatBoostRegressor object at 0x30e6e02e0>
2024-12-17 02:32:18,793:INFO:create_model() successfully completed......................................
2024-12-17 02:32:18,874:INFO:_master_model_container: 21
2024-12-17 02:32:18,874:INFO:_display_container: 2
2024-12-17 02:32:18,874:INFO:<catboost.core.CatBoostRegressor object at 0x30e6e02e0>
2024-12-17 02:32:18,874:INFO:compare_models() successfully completed......................................
2024-12-17 02:48:48,028:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/13211995.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-6, 1e-1)

2024-12-17 02:57:06,790:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/1834651818.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:06,795:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:06,935:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:06,942:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:07,005:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:07,013:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:07,088:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:07,104:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:07,252:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:07,259:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:07,461:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:07,472:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:07,671:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:07,681:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:07,829:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:07,839:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:08,006:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:08,019:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:08,158:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:08,164:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:08,312:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:08,319:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:08,449:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:08,468:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/1834651818.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:08,469:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:08,554:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:08,561:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:08,680:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:08,690:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:08,768:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:08,777:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:08,874:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:08,882:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:08,963:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:08,978:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:09,063:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:09,073:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:09,165:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:09,184:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:09,266:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:09,272:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:09,366:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:09,373:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:09,542:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:09,549:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:09,653:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:09,659:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/1834651818.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:09,660:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:09,761:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:09,764:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:09,898:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:09,904:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:10,288:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:10,298:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:10,440:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:10,456:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:10,553:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:10,560:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:10,717:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:10,723:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:10,861:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:10,870:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:11,020:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:11,026:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:11,222:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:11,230:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:11,364:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:11,371:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:11,492:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:11,498:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/1834651818.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:11,498:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:11,584:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:11,587:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:11,753:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:11,768:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:11,860:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:11,869:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:11,953:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:11,960:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:12,096:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:12,102:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:12,225:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:12,233:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:12,375:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:12,383:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:12,481:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:12,488:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:12,572:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:12,585:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:12,681:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:12,692:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:12,784:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:12,790:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/1834651818.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:12,790:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:13,036:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:13,039:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:13,235:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:13,244:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:13,506:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:13,514:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:13,660:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:13,671:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:13,837:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:13,853:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:14,005:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:14,019:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:20,559:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:20,560:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:20,663:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:20,665:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:20,736:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:20,742:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:20,795:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:20,801:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:20,847:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:20,853:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:20,914:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:20,921:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:20,994:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,000:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,051:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,056:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,112:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,119:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,168:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,172:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,221:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,227:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,281:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,285:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:21,286:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,344:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,347:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,389:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,394:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,444:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,448:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,505:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,511:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,559:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,566:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,628:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,632:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,684:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,690:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,772:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,780:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,829:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,833:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,878:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,882:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,922:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,926:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:21,927:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:21,989:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:21,991:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,035:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,039:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,091:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,098:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,170:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,178:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,235:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,240:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,298:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,303:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,374:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,380:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,430:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,438:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,502:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,507:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,557:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,562:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,612:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,620:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:22,620:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,674:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,681:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,726:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,732:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,778:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,783:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,828:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,833:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,879:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,886:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,931:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,935:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:22,977:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:22,982:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,032:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,037:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,080:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,086:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,126:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,131:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,172:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,176:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:23,176:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,231:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,233:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,279:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,283:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,333:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,339:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,407:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,414:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,462:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,470:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,515:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,522:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,563:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,577:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,624:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,629:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,676:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,680:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,722:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,727:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,773:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,779:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:23,779:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,832:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,835:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,882:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,887:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,941:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,946:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:23,990:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:23,995:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,043:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,048:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,091:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,097:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,151:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,154:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,208:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,212:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,285:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,291:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,340:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,350:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,396:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,403:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:24,403:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,469:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,470:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,518:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,525:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,584:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,589:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,639:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,647:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,706:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,713:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,770:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,775:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,818:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,824:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,866:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,871:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,923:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:24,962:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:24,965:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,010:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,014:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:25,014:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,073:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,075:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,116:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,122:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,169:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,173:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,227:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,233:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,287:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,297:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,349:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,356:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,408:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,413:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,460:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,465:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,512:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,515:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,565:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,568:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,627:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,634:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:25,634:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,702:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,706:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,757:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,762:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,805:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,809:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,853:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,857:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:25,988:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:25,993:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:26,043:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:26,047:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:26,090:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:26,095:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:26,147:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:26,152:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:26,194:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:26,197:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:26,290:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:26,298:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:26,504:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:26,554:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:26,555:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:27,061:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:27,067:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:27,239:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:27,297:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:27,600:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:27,605:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:30,968:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:30,988:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:32,093:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:32,102:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:32,590:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:32,602:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:32,862:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:32,877:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:33,525:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:33,548:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:33,988:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:34,006:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:34,207:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:34,222:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:34,385:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:34,419:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:34,423:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:34,519:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:34,529:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:34,779:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:34,791:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:35,176:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:35,186:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:35,637:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:35,672:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:36,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:36,932:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:37,114:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:37,125:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:37,452:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:37,469:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:37,847:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:37,857:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:38,260:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:38,267:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:38,393:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:38,404:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:38,602:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:38,621:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:38,627:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:38,911:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:38,916:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:39,146:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:39,160:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:40,011:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:40,046:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:40,960:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:40,973:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:41,471:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:41,498:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:42,043:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:42,051:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:42,215:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:42,221:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:42,629:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:42,639:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:43,185:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:43,194:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:43,344:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:43,353:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:43,540:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:43,553:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:43,557:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:43,764:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:43,773:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:43,976:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:43,984:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:44,355:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:44,369:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:44,655:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:44,672:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:44,912:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:44,920:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:45,195:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:45,205:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:45,504:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:45,521:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:45,876:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:45,890:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:46,109:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:46,120:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:46,294:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:46,301:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:46,503:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:46,535:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:46,540:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:46,758:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:46,761:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:46,985:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:47,000:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:47,240:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:47,248:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:47,453:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:47,468:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:47,896:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:47,910:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:48,338:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:48,346:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:48,649:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:48,660:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:48,861:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:48,870:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:49,246:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:49,254:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:49,837:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:49,851:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:50,399:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:50,417:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:50,422:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:50,745:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:50,748:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:50,906:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:50,922:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:51,230:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:51,246:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:51,602:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:51,620:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:52,037:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:52,045:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:52,144:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:52,153:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:52,488:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:52,505:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:52,892:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:52,898:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:53,490:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:53,499:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:53,857:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:53,870:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:54,154:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:54,171:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:54,178:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:54,398:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:54,405:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:54,875:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:54,886:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:55,136:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:55,144:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:55,312:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:55,318:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:55,507:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:55,514:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:55,734:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:55,744:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:55,876:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:55,884:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:56,109:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:56,115:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:56,407:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:56,414:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:56,607:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:56,620:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:56,794:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:56,818:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:57:56,824:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:57,055:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:57,059:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:57,155:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:57,163:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:57,454:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:57,462:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:57,645:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:57,657:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:57,833:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:57,839:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:58,085:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:58,101:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:58,522:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:58,530:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:58,693:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:58,701:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:58,981:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:58,995:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:57:59,513:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:57:59,529:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:00,571:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:00,601:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:00,605:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:01,339:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:01,353:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:01,559:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:01,573:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:02,265:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:02,276:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:03,329:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:03,338:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:03,554:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:03,578:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:03,751:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:03,770:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:04,022:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:04,034:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:04,198:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:04,210:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:04,448:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:04,455:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:04,656:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:04,662:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:05,247:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:05,267:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:05,272:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:05,483:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:05,487:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:05,769:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:05,777:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:06,187:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:06,196:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:07,485:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:07,498:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:07,995:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:08,003:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:08,792:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:08,808:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:10,046:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:10,056:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:10,694:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:10,700:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:10,794:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:10,802:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:10,948:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:10,957:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:11,127:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:11,150:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:11,154:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:11,424:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:11,428:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:11,753:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:11,761:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:12,186:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:12,219:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:13,069:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:13,077:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:13,786:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:13,796:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:14,012:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:14,020:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:14,333:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:14,343:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:14,603:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:14,612:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:14,790:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:14,798:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:15,011:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:15,026:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:15,190:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:15,205:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:15,210:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:15,712:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:15,716:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:15,945:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:15,953:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:16,165:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:16,174:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:16,477:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:16,484:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:16,746:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:16,753:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:17,234:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:17,279:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:17,753:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:17,760:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:18,011:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:18,021:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:18,477:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:18,485:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:18,576:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:18,593:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:18,781:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:18,795:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:18,799:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:18,915:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:18,919:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:19,219:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:19,231:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:19,486:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:19,493:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:19,607:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:19,635:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:20,903:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:20,921:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:21,534:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:21,559:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:21,922:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:21,932:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:22,139:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:22,147:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:22,312:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:22,327:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:23,194:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:23,202:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:23,335:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:23,348:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:23,358:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:23,560:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:23,564:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:23,766:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:23,777:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:23,961:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:23,969:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:24,138:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:24,145:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:24,358:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:24,382:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:25,036:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:25,044:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:25,346:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:25,362:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:25,478:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:25,486:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:26,712:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:26,722:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:26,960:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:26,970:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:27,070:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:27,086:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:27,095:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:27,309:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:27,314:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:27,513:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:27,520:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:28,504:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:28,515:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:28,734:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:28,744:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:28,951:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:28,966:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:29,117:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:29,131:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:29,465:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:29,471:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:29,722:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:29,736:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:30,048:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:30,064:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:30,319:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:30,336:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:30,519:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:30,532:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:30,537:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:30,668:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:30,674:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:30,939:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:30,951:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:31,338:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:31,348:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:31,555:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:31,565:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:31,996:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:32,009:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:32,160:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:32,169:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:32,368:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:32,378:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:32,522:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:32,537:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:32,995:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:33,010:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:34,410:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:34,421:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:35,358:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:35,380:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:35,384:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:35,976:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:35,979:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:36,161:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:36,168:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:36,354:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:36,369:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:36,979:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:36,990:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:37,599:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:37,608:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:38,000:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:38,011:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:38,230:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:38,240:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:38,422:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:38,429:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:38,724:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:38,740:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:38,905:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:38,916:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:39,039:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:39,055:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:39,062:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:39,360:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:39,363:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:39,516:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:39,522:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:39,747:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:39,755:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:39,964:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:39,971:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:40,202:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:40,212:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:40,401:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:40,411:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:40,500:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:40,519:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:41,070:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:41,089:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:41,270:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:41,281:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:41,469:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:41,479:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:41,726:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:41,739:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:41,744:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:42,013:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:42,017:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:42,301:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:42,311:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:42,656:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:42,666:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:42,907:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:42,915:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:43,117:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:43,123:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:43,411:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:43,430:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:43,644:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:43,659:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:43,860:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:43,879:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:44,729:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:44,740:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:45,019:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:45,027:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:45,958:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:45,981:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:45,986:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:47,061:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:47,066:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:47,453:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:47,479:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:47,962:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:47,980:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:48,497:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:48,505:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:48,655:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:48,663:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:49,014:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:49,028:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:49,630:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:49,636:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:49,777:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:49,786:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:49,947:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:49,957:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:50,109:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:50,117:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:50,273:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:50,289:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:50,294:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:51,108:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:51,114:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:51,393:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:51,402:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:52,180:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:52,190:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:52,439:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:52,457:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:52,816:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:52,835:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:53,114:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:53,127:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:53,257:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:53,263:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:53,385:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:53,392:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:53,572:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:53,578:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:53,852:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:53,860:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:54,026:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:54,047:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:54,051:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:54,140:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:54,143:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:54,405:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:54,413:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:54,593:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:54,600:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:54,749:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:54,757:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:54,915:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:54,925:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:55,054:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:55,072:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:55,264:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:55,277:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:55,377:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:55,388:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:55,603:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:55,618:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:55,776:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:55,798:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:56,200:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:56,222:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:56,226:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:56,513:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:56,518:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:56,604:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:56,610:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:56,999:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:57,009:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:57,400:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:57,409:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:57,663:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:57,674:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:57,891:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:57,899:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:58,069:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:58,081:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:58,317:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:58,324:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:58,518:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:58,525:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:58,726:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:58,736:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:58,920:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:58,934:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:58:58,939:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:59,037:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:59,040:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:59,124:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:59,136:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:59,200:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:59,223:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:59,393:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:59,401:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:59,572:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:59,586:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:58:59,867:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:58:59,928:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:00,172:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:00,180:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:00,364:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:00,372:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:00,728:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:00,742:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:00,874:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:00,887:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:01,402:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:01,430:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:01,436:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:01,536:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:01,539:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:01,615:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:01,645:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:01,857:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:01,868:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:02,012:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:02,021:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:02,179:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:02,188:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:02,447:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:02,457:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:02,575:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:02,587:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:02,777:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:02,794:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:02,891:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:02,898:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:03,050:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:03,057:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:03,167:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:03,188:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:03,192:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:03,277:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:03,281:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:03,486:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:03,498:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:03,598:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:03,611:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:03,704:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:03,711:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:03,907:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:03,913:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:04,074:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:04,081:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:04,212:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:04,222:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:04,400:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:04,410:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:04,605:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:04,612:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:04,690:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:04,697:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:04,889:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:04,911:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:04,915:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:04,993:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:04,996:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:05,485:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:05,497:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:06,323:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:06,331:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:06,837:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:06,850:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:06,955:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:06,963:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:07,132:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:07,139:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:07,317:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:07,326:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:07,481:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:07,488:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:07,830:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:07,838:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:08,337:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:08,345:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:08,506:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:08,529:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:08,534:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:08,630:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:08,633:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:09,295:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:09,313:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:09,506:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:09,515:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:09,708:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:09,714:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:09,858:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:09,869:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:10,062:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:10,081:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:10,655:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:10,668:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:10,842:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:10,859:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:11,189:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:11,209:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:11,986:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:11,999:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:12,653:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:12,681:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:12,687:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:13,263:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:13,267:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:13,574:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:13,581:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:14,075:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:14,105:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:14,673:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:14,688:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:15,089:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:15,100:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:15,255:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:15,272:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:15,395:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:15,404:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:15,544:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:15,550:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:15,768:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:15,777:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:15,968:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:15,976:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:16,147:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:16,160:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:16,165:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:16,253:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:16,258:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:16,511:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:16,523:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:17,075:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:17,093:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:17,483:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:17,496:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:17,652:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:17,664:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:17,792:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:17,798:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:17,960:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:17,971:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:18,093:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:18,101:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:18,179:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:18,185:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:18,355:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:18,365:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:18,713:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:18,744:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:18,749:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:19,819:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:19,823:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:20,082:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:20,093:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:20,639:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:20,654:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:20,923:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:20,947:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:21,613:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:21,623:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:21,812:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:21,819:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:22,435:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:22,453:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:22,669:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:22,682:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:23,244:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:23,254:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:23,394:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:23,403:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:23,554:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:23,568:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:23,572:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:23,660:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:23,672:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:23,859:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:23,866:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:24,026:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:24,033:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:24,211:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:24,222:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:24,397:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:24,411:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:24,585:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:24,592:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:24,679:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:24,689:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:24,812:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:24,820:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:24,910:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:24,917:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:25,105:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:25,111:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:25,288:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:25,303:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:25,308:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:25,476:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:25,484:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:25,762:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:25,774:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:25,924:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:25,931:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:26,095:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:26,114:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:26,236:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:26,252:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:26,387:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:26,393:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:26,535:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:26,544:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:26,756:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:26,763:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:26,902:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:26,911:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:27,106:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:27,123:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:27,459:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:27,476:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:27,486:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:27,622:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:27,626:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:28,188:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:28,195:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:28,404:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:28,421:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:28,593:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:28,600:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:28,762:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:28,771:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:28,942:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:28,950:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:29,134:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:29,142:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:29,355:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:29,362:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:29,494:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:29,501:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:29,632:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:29,645:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:29,780:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:29,801:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:29,807:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:29,899:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:29,902:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:29,996:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:30,003:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:30,646:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:30,666:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:30,858:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:30,873:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:31,126:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:31,133:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:31,359:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:31,369:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:31,569:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:31,578:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:32,460:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:32,485:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:33,573:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:33,584:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:34,374:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:34,385:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:35,512:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:35,539:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:35,544:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:36,721:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:36,726:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:37,777:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:37,796:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:38,619:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:38,659:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:39,202:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:39,215:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:39,920:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:39,935:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:40,369:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:40,401:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:40,805:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:40,814:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:41,057:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:41,070:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:41,232:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:41,246:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:41,356:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:41,370:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:41,541:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:41,556:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:41,562:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:42,165:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:42,169:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:42,349:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:42,363:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:42,569:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:42,578:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:42,765:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:42,773:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:43,027:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:43,035:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:43,305:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:43,312:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:43,492:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:43,506:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:43,692:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:43,698:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:44,017:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:44,031:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:44,272:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:44,280:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:44,519:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:44,538:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:44,542:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:44,736:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:44,739:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:44,848:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:44,855:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:45,088:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:45,095:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:45,300:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:45,307:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:45,589:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:45,598:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:46,050:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:46,058:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:46,302:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:46,307:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:46,538:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:46,547:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:46,752:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:46,766:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:47,134:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:47,150:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:47,866:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:47,895:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:47,901:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:48,126:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:48,129:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:48,523:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:48,533:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:48,844:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:48,851:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:49,050:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:49,061:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:49,891:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:49,908:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:50,141:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:50,147:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:50,329:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:50,344:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:50,431:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:50,441:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:50,874:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:50,882:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:51,360:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:51,366:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:51,594:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:51,613:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:51,622:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:51,728:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:51,738:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:51,871:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:51,877:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:52,048:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:52,061:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:52,128:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:52,143:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:52,350:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:52,357:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:52,526:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:52,540:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:52,769:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:52,775:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:53,109:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:53,115:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:53,269:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:53,277:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:53,409:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:53,420:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:53,587:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:53,605:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:53,611:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:53,777:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:53,782:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:53,979:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:53,994:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:54,653:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:54,660:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:54,844:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:54,855:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:55,059:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:55,069:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:55,523:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:55,530:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:55,709:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:55,721:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:56,114:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:56,122:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:56,340:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:56,347:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:56,501:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:56,512:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:56,709:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:56,726:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 02:59:56,730:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:57,264:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:57,267:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:57,607:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:57,618:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:57,811:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:57,821:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:58,086:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:58,098:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:58,563:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:58,570:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:58,736:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:58,747:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:58,991:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:59,004:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:59,181:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:59,188:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:59,427:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:59,438:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:59,621:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 02:59:59,630:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 02:59:59,975:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:00,005:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:00,010:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:00,412:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:00,416:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:00,589:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:00,595:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:00,807:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:00,816:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:01,152:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:01,165:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:01,565:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:01,573:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:01,769:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:01,778:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:01,908:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:01,916:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:02,180:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:02,188:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:02,541:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:02,556:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:02,857:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:02,867:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:02,970:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:02,990:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:02,998:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:03,263:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:03,269:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:03,443:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:03,455:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:03,623:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:03,631:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:03,758:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:03,764:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:03,942:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:03,951:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:04,221:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:04,232:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:04,401:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:04,407:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:04,561:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:04,576:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:04,754:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:04,770:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:04,912:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:04,921:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:05,072:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:05,090:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:05,097:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:05,188:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:05,190:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:05,502:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:05,510:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:05,634:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:05,640:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:05,835:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:05,842:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:05,976:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:05,984:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:06,108:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:06,116:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:06,309:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:06,319:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:06,716:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:06,728:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:07,294:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:07,308:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:07,381:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:07,393:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:07,621:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:07,650:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:07,657:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:08,087:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:08,092:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:09,023:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:09,032:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:09,354:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:09,370:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:09,572:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:09,579:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:09,732:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:09,749:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:09,978:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:09,987:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:10,466:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:10,481:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:11,678:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:11,689:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:11,931:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:11,948:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:12,256:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:12,264:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:12,407:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:12,444:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:12,450:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:12,548:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:12,552:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:12,754:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:12,761:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:12,904:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:12,913:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:13,078:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:13,085:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:13,204:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:13,214:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:13,431:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:13,439:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:13,669:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:13,676:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:13,894:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:13,908:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:14,074:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:14,080:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:14,275:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:14,290:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:14,443:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:14,460:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:14,464:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:14,563:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:14,567:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:14,830:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:14,846:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:14,985:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:14,999:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:15,181:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:15,189:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:15,457:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:15,468:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:15,642:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:15,658:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:15,820:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:15,826:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:16,047:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:16,057:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:16,243:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:16,255:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:16,498:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:16,506:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:16,721:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:16,741:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:16,748:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:17,155:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:17,158:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:17,314:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:17,322:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:17,485:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:17,494:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:17,724:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:17,732:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:17,907:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:17,913:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:18,131:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:18,138:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:18,310:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:18,318:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:18,548:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:18,555:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:18,756:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:18,765:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:18,927:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:18,938:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:19,176:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:19,208:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:19,213:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:19,311:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:19,320:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:19,574:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:19,583:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:19,779:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:19,787:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:19,909:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:19,915:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:20,116:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:20,124:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:20,379:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:20,389:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:20,531:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:20,538:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:20,765:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:20,771:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:20,912:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:20,918:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:21,153:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:21,159:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:21,330:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:21,354:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:21,360:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:21,572:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:21,576:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:21,794:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:21,802:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:22,414:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:22,421:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:22,667:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:22,674:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:23,286:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:23,295:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:23,400:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:23,412:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:23,570:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:23,578:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:23,756:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:23,762:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:24,049:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:24,069:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:24,976:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:24,988:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:26,233:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:26,258:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:26,272:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:26,835:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:26,839:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:27,326:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:27,349:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:27,526:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:27,532:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:27,629:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:27,639:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:27,763:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:27,773:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:27,976:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:27,986:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:28,208:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:28,217:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:28,387:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:28,401:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:28,870:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:28,882:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:29,903:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:29,920:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:30,773:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:30,791:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:30,797:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:30,910:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:30,915:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:31,211:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:31,221:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:34,809:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:34,843:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:37,065:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:37,084:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:37,893:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:37,901:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:38,786:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:38,805:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:39,519:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:39,531:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:40,607:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:40,623:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:41,842:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:41,849:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:42,145:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:42,162:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:42,713:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:42,739:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:42,744:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:42,897:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:42,902:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:43,308:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:43,315:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:43,580:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:43,587:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:43,742:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:43,753:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:44,302:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:44,314:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:44,526:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:44,545:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:44,792:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:44,798:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:45,079:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:45,087:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:45,321:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:45,339:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:45,591:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:45,600:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:46,096:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:46,112:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:46,117:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:46,241:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:46,249:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:46,564:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:46,572:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:46,794:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:46,813:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:48,205:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:48,220:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:49,553:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:49,566:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:49,876:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:49,893:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:50,103:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:50,111:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:50,406:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:50,412:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:50,753:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:50,762:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:50,907:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:50,917:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:52,306:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:52,347:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:52,354:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:52,639:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:52,641:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:52,929:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:52,936:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:53,050:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:53,063:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:53,253:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:53,262:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:53,426:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:53,438:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:53,862:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:53,873:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:54,265:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:54,271:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:54,473:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:54,484:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:54,659:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:54,667:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:54,906:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:54,913:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:55,177:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:55,232:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:55,242:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:55,311:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:55,315:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:55,493:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:55,508:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:55,665:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:55,679:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:55,833:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:55,845:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:55,997:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:56,005:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:56,231:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:56,237:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:56,439:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:56,456:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:56,528:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:56,536:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:56,639:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:56,647:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:56,858:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:56,864:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:57,042:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:57,058:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:00:57,062:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:57,157:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:57,161:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:57,299:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:57,304:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:58,051:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:58,061:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:58,611:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:58,624:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:58,795:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:58,803:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:59,263:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:59,272:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:59,478:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:59,485:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:59,633:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:59,639:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:00:59,881:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:00:59,887:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:00,076:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:00,086:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:00,230:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:00,244:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:00,249:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:00,344:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:00,349:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:00,551:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:00,559:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:00,739:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:00,755:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:00,918:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:00,925:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:01,105:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:01,112:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:01,300:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:01,314:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:01,440:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:01,453:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:01,607:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:01,614:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:01,798:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:01,810:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:02,005:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:02,014:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:02,409:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:02,426:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:02,433:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:02,541:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:02,544:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:02,848:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:02,858:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:02,987:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:02,995:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:03,205:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:03,213:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:03,373:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:03,380:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:03,574:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:03,586:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:03,742:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:03,758:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:04,274:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:04,284:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:04,459:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:04,465:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:04,613:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:04,619:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:04,761:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:04,777:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:04,783:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:04,857:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:04,860:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:05,095:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:05,103:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:05,330:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:05,338:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:05,545:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:05,561:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:05,743:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:05,753:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:05,898:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:05,914:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:06,134:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:06,145:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:06,324:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:06,331:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:06,550:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:06,561:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:06,752:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:06,763:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:06,946:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:06,962:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:06,967:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:07,485:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:07,489:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:07,839:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:07,855:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:08,280:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:08,290:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:09,141:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:09,152:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:09,316:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:09,323:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:09,933:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:09,945:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:10,183:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:10,193:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:10,340:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:10,348:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:10,504:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:10,513:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:10,707:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:10,722:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:11,162:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:11,179:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:11,185:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:11,248:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:11,251:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:11,387:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:11,402:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:11,481:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:11,491:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:11,596:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:11,606:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:11,767:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:11,775:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:11,985:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:11,991:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:12,104:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:12,115:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:12,205:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:12,216:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:12,341:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:12,347:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:12,549:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:12,560:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:12,640:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:12,662:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:12,668:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:12,791:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:12,794:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:12,884:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:12,892:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:13,070:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:13,087:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:13,288:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:13,296:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:13,441:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:13,450:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:13,651:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:13,659:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:14,024:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:14,032:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:14,163:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:14,170:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:14,303:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:14,313:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:14,398:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:14,408:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:14,557:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:14,577:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:14,583:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:14,737:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:14,741:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:15,581:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:15,592:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:16,153:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:16,168:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:16,873:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:16,881:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:17,098:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:17,108:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:17,224:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:17,233:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:17,438:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:17,445:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:17,584:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:17,592:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:17,711:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:17,723:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:17,947:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:17,953:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:18,147:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:18,176:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:18,181:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:18,250:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:18,253:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:18,423:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:18,431:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:18,556:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:18,564:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:18,639:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:18,647:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:18,775:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:18,782:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:18,910:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:18,918:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:18,985:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:18,994:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:19,074:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:19,082:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:19,170:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:19,178:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:19,339:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:19,346:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:19,473:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:19,489:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:19,495:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:19,708:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:19,713:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:19,867:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:19,878:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:20,096:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:20,101:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:20,253:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:20,260:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:20,418:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:20,431:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:20,578:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:20,586:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:20,819:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:20,828:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:20,971:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:20,978:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:21,140:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:21,146:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:21,229:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:21,238:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:21,417:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:21,433:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:21,439:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:21,546:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:21,549:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:21,686:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:21,694:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:21,832:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:21,843:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:21,936:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:21,948:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:22,022:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:22,032:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:22,156:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:22,169:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:22,272:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:22,279:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:22,497:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:22,507:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:22,656:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:22,665:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:22,790:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:22,798:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:22,925:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:22,945:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:22,950:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:23,059:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:23,064:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:23,227:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:23,244:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:23,390:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:23,397:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:23,528:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:23,535:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:23,701:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:23,708:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:23,859:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:23,867:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:24,020:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:24,027:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:24,175:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:24,186:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:24,323:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:24,339:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:24,452:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:24,461:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:24,606:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:24,626:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:24,631:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:24,698:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:24,701:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:24,776:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:24,789:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:25,464:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:25,472:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:25,629:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:25,639:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:25,776:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:25,790:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:25,892:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:25,905:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:26,052:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:26,061:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:26,163:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:26,169:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:26,260:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:26,291:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:26,608:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:26,619:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:26,794:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:26,808:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:26,812:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:26,881:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:26,885:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:26,973:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:26,980:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:27,146:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:27,152:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:27,341:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:27,355:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:27,479:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:27,491:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:27,641:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:27,648:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:27,832:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:27,841:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:28,055:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:28,075:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:28,683:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:28,689:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:28,922:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:28,929:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:29,449:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:29,489:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:29,494:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:29,688:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:29,693:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:30,012:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:30,020:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:30,120:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:30,127:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:30,287:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:30,295:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:30,471:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:30,481:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:30,650:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:30,663:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:31,139:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:31,158:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:31,935:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:31,949:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:32,076:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:32,090:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:32,366:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:32,378:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:32,453:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:32,468:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:32,475:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:32,698:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:32,701:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:32,939:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:32,948:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:33,056:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:33,065:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:33,154:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:33,162:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:33,325:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:33,338:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:33,446:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:33,456:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:33,584:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:33,590:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:33,718:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:33,729:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:33,804:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:33,811:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:33,974:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:33,983:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:34,125:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:34,153:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:34,159:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:34,271:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:34,275:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:34,478:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:34,486:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:34,597:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:34,605:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:34,673:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:34,682:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:34,786:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:34,792:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:34,933:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:34,940:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:35,074:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:35,080:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:35,185:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:35,191:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:35,789:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:35,797:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:35,907:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:35,915:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:36,121:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:36,137:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:36,142:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:36,276:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:36,279:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:36,365:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:36,386:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:36,743:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:36,752:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:36,885:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:36,891:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:37,113:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:37,119:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:37,252:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:37,258:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:37,381:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:37,388:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:37,564:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:37,578:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:37,716:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:37,723:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:38,005:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:38,020:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:38,559:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:38,606:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:38,613:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:39,318:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:39,322:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:39,503:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:39,511:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:39,691:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:39,698:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:39,853:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:39,861:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:40,019:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:40,025:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:40,182:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:40,188:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:40,338:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:40,345:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:40,423:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:40,431:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:40,538:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:40,547:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:40,708:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:40,715:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:41,121:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:41,171:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:41,180:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:42,698:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:42,702:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:43,091:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:43,100:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:43,228:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:43,239:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:43,327:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:43,349:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:43,445:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:43,455:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:43,538:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:43,546:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:43,689:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:43,703:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:43,855:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:43,870:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:44,794:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:44,801:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:44,917:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:44,924:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:45,088:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:45,111:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:45,120:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:45,845:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:45,849:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:46,221:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:46,230:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:46,350:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:46,355:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:46,528:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:46,538:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:46,841:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:46,847:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:46,976:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:46,986:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:47,210:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:47,217:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:47,752:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:47,761:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:47,958:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:47,967:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:48,118:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:48,125:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:48,289:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:48,318:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:48,325:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:48,608:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:48,614:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:48,742:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:48,750:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:48,853:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:48,862:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:48,986:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:48,997:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:49,198:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:49,208:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:49,319:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:49,326:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:49,422:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:49,438:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:49,575:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:49,583:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:49,745:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:49,753:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:49,899:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:49,906:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:50,038:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:50,066:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:50,071:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:50,130:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:50,133:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:50,197:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:50,205:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:50,338:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:50,344:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:50,486:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:50,492:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:50,617:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:50,641:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:50,764:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:50,771:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:50,878:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:50,883:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:51,136:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:51,149:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:51,396:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:51,406:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:51,905:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:51,918:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:52,096:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:52,113:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:52,118:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:52,252:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:52,256:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:52,483:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:52,490:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:52,710:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:52,721:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:52,871:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:52,878:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:53,082:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:53,089:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:53,280:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:53,291:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:53,434:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:53,442:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:53,577:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:53,585:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:53,783:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:53,793:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:54,211:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:54,219:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:54,562:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:54,581:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:54,585:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:54,745:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:54,750:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:54,861:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:54,873:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:55,009:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:55,015:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:55,151:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:55,163:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:55,322:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:55,339:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:55,722:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:55,728:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:55,815:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:55,825:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:56,000:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:56,008:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:56,329:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:56,335:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:56,461:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:56,493:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:56,750:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:56,767:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:56,773:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:56,888:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:56,892:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:57,120:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:57,137:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:57,267:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:57,281:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:57,447:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:57,455:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:57,602:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:57,609:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:57,785:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:57,793:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:58,025:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:58,037:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:58,237:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:58,245:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:58,349:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:58,358:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:58,462:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:58,469:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:58,596:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:58,620:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:01:58,625:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:58,712:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:58,715:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:58,837:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:58,849:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:58,946:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:58,965:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:59,188:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:59,201:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:59,324:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:59,331:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:59,510:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:59,522:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:01:59,906:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:01:59,924:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:00,415:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:00,421:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:00,734:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:00,756:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:01,008:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:01,029:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:01,242:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:01,258:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:02:01,265:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:01,409:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:01,413:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:01,590:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:01,602:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:01,749:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:01,762:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:01,848:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:01,856:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:02,075:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:02,083:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:02,438:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:02,450:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:03,281:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:03,296:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:03,669:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:03,678:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:03,858:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:03,864:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:04,169:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:04,175:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:04,404:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:04,422:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:02:04,428:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:04,516:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:04,519:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:04,735:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:04,742:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:04,948:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:04,960:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:05,106:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:05,115:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:05,292:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:05,299:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:05,597:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:05,605:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:05,763:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:05,769:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:05,910:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:05,924:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:06,102:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:06,107:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:06,312:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:06,319:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:06,453:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:06,472:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:02:06,477:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:06,591:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:06,596:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:06,751:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:06,764:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:06,875:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:06,880:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:06,994:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:07,005:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:07,062:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:07,070:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:07,193:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:07,201:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:07,338:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:07,345:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:07,458:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:07,468:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:07,599:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:07,607:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:07,714:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:07,723:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:07,855:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:07,874:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:02:07,878:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:07,939:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:07,942:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:08,099:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:08,106:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:08,865:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:08,872:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:09,106:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:09,117:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:09,581:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:09,588:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:09,777:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:09,788:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:09,982:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:09,989:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:10,129:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:10,136:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:10,288:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:10,299:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:10,383:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:10,389:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:10,562:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:10,581:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:02:10,586:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:10,650:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:10,653:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:10,785:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:10,798:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:10,889:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:10,908:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:11,003:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:11,015:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:11,101:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:11,108:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:11,365:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:11,371:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:11,519:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:11,535:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:11,629:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:11,637:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:11,809:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:11,817:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:12,086:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:12,096:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:12,225:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:12,249:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:02:12,254:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:12,400:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:12,406:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:12,540:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:12,551:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:12,671:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:12,684:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:12,804:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:12,816:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:12,900:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:12,911:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:13,098:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:13,106:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:13,265:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:13,273:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:13,418:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:13,424:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:13,518:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:13,526:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:13,783:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:13,790:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:13,884:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:13,898:WARNING:/var/folders/hy/b8mrcp_x1sxbt1d3f8hfqcmm0000gn/T/ipykernel_2241/3491928342.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  tol = trial.suggest_loguniform("tol", 1e-8, 1e-2)  # Tolerance for stopping criteria

2024-12-17 03:02:13,903:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:13,976:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:13,979:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:14,095:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:14,104:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:14,206:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:14,216:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:14,544:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:14,550:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:14,747:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:14,754:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:14,938:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:14,946:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:15,037:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:15,048:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:15,173:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:15,181:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:15,330:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:15,341:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:16,071:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:02:16,081:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:02:16,210:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2024-12-17 03:16:38,933:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2024-12-17 03:16:38,988:WARNING:/Users/abhishek/tensorflow-test/env/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:758: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

